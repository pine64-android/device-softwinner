diff --git a/common.mk b/common.mk
index 62f9c68..6a29009 100755
--- a/common.mk
+++ b/common.mk
@@ -16,7 +16,7 @@ PRODUCT_PROPERTY_OVERRIDES += \
 endif
 
 # preinstall apk
-PRODUCT_PACKAGES += \
+# PRODUCT_PACKAGES += \
     DragonFire \
     DragonPhone \
     DragonAging
diff --git a/hardware/camera/Android.mk b/hardware/camera/Android.mk
index afd4917..c39f737 100755
--- a/hardware/camera/Android.mk
+++ b/hardware/camera/Android.mk
@@ -1,109 +1,7 @@
 
 LOCAL_PATH := $(call my-dir)
-
 $(warning $(TARGET_BOARD_PLATFORM))
-############################################################################
-#####---A64---
-ifneq ($(filter tulip%,$(TARGET_BOARD_PLATFORM)),)
-include $(CLEAR_VARS)
-LOCAL_MODULE := libfacedetection
-LOCAL_MODULE_SUFFIX := .so
-LOCAL_MODULE_CLASS := SHARED_LIBRARIES
-LOCAL_SRC_FILES_32 := lib32/facedetection/libfacedetection.so
-LOCAL_SRC_FILES_64 := lib64/facedetection/libfacedetection.so
-LOCAL_MULTILIB:= both
-LOCAL_MODULE_TAGS := optional
-include $(BUILD_PREBUILT)
-include $(CLEAR_VARS)
-LOCAL_MODULE := libSmileEyeBlink
-LOCAL_MODULE_SUFFIX := .so
-LOCAL_MODULE_CLASS := SHARED_LIBRARIES
-LOCAL_SRC_FILES_32 := lib32/facedetection/libSmileEyeBlink.so
-LOCAL_SRC_FILES_64 := lib64/facedetection/libSmileEyeBlink.so
-LOCAL_MULTILIB:= both
-LOCAL_MODULE_TAGS := optional
-include $(BUILD_PREBUILT)
-include $(CLEAR_VARS)
-LOCAL_MODULE := libapperceivepeople
-LOCAL_MODULE_SUFFIX := .so
-LOCAL_MODULE_CLASS := SHARED_LIBRARIES
-LOCAL_SRC_FILES_32 := lib32/facedetection/libapperceivepeople.so
-LOCAL_SRC_FILES_64 := lib64/facedetection/libapperceivepeople.so
-LOCAL_MULTILIB:= both
-LOCAL_MODULE_TAGS := optional
-include $(BUILD_PREBUILT)
-endif
-############################################################################
-
-############################################################################
-#####---A83---
-ifneq ($(filter octopus%,$(TARGET_BOARD_PLATFORM)),)
-include $(CLEAR_VARS)
-LOCAL_MODULE := libfacedetection
-LOCAL_MODULE_SUFFIX := .so
-LOCAL_MODULE_CLASS := SHARED_LIBRARIES
-LOCAL_SRC_FILES_32 := lib32/facedetection/libfacedetection.so
-LOCAL_SRC_FILES_64 := lib64/facedetection/libfacedetection.so
-LOCAL_MULTILIB:= both
-LOCAL_MODULE_TAGS := optional
-include $(BUILD_PREBUILT)
-include $(CLEAR_VARS)
-LOCAL_MODULE := libSmileEyeBlink
-LOCAL_MODULE_SUFFIX := .so
-LOCAL_MODULE_CLASS := SHARED_LIBRARIES
-LOCAL_SRC_FILES_32 := lib32/facedetection/libSmileEyeBlink.so
-LOCAL_SRC_FILES_64 := lib64/facedetection/libSmileEyeBlink.so
-LOCAL_MULTILIB:= both
-LOCAL_MODULE_TAGS := optional
-include $(BUILD_PREBUILT)
-include $(CLEAR_VARS)
-LOCAL_MODULE := libapperceivepeople
-LOCAL_MODULE_SUFFIX := .so
-LOCAL_MODULE_CLASS := SHARED_LIBRARIES
-LOCAL_SRC_FILES_32 := lib32/facedetection/libapperceivepeople.so
-LOCAL_SRC_FILES_64 := lib64/facedetection/libapperceivepeople.so
-LOCAL_MULTILIB:= both
-LOCAL_MODULE_TAGS := optional
-include $(BUILD_PREBUILT)
-endif
-############################################################################
-
-############################################################################
-#####---A33---
-ifneq ($(filter astar%,$(TARGET_BOARD_PLATFORM)),)
-include $(CLEAR_VARS)
-LOCAL_MODULE := libfacedetection
-LOCAL_MODULE_SUFFIX := .so
-LOCAL_MODULE_CLASS := SHARED_LIBRARIES
-LOCAL_SRC_FILES_32 := lib32/facedetection/libfacedetection.so
-LOCAL_SRC_FILES_64 := lib64/facedetection/libfacedetection.so
-LOCAL_MULTILIB:= both
-LOCAL_MODULE_TAGS := optional
-include $(BUILD_PREBUILT)
-include $(CLEAR_VARS)
-LOCAL_MODULE := libSmileEyeBlink
-LOCAL_MODULE_SUFFIX := .so
-LOCAL_MODULE_CLASS := SHARED_LIBRARIES
-LOCAL_SRC_FILES_32 := lib32/facedetection/libSmileEyeBlink.so
-LOCAL_SRC_FILES_64 := lib64/facedetection/libSmileEyeBlink.so
-LOCAL_MULTILIB:= both
-LOCAL_MODULE_TAGS := optional
-include $(BUILD_PREBUILT)
-include $(CLEAR_VARS)
-LOCAL_MODULE := libapperceivepeople
-LOCAL_MODULE_SUFFIX := .so
-LOCAL_MODULE_CLASS := SHARED_LIBRARIES
-LOCAL_SRC_FILES_32 := lib32/facedetection/libapperceivepeople.so
-LOCAL_SRC_FILES_64 := lib64/facedetection/libapperceivepeople.so
-LOCAL_MULTILIB:= both
-LOCAL_MODULE_TAGS := optional
-include $(BUILD_PREBUILT)
-endif
-############################################################################
 
-############################################################################
-#####---A80---
-ifneq ($(filter kylin%,$(TARGET_BOARD_PLATFORM)),)
 include $(CLEAR_VARS)
 LOCAL_MODULE := libfacedetection
 LOCAL_MODULE_SUFFIX := .so
@@ -131,51 +29,46 @@ LOCAL_SRC_FILES_64 := lib64/facedetection/libapperceivepeople.so
 LOCAL_MULTILIB:= both
 LOCAL_MODULE_TAGS := optional
 include $(BUILD_PREBUILT)
-endif
-############################################################################
-
-include $(CLEAR_VARS)
-LOCAL_MODULE := libproc
-LOCAL_MODULE_SUFFIX := .so
-LOCAL_MODULE_CLASS := SHARED_LIBRARIES
-LOCAL_SRC_FILES_32 := lib32/proc/libproc.so
-LOCAL_SRC_FILES_64 := lib64/proc/libproc.so
-LOCAL_MULTILIB:= both
-LOCAL_MODULE_TAGS := optional
-include $(BUILD_PREBUILT)
 include $(CLEAR_VARS)
-LOCAL_MODULE := libhdr
-LOCAL_MODULE_SUFFIX := .so
-LOCAL_MODULE_CLASS := SHARED_LIBRARIES
-LOCAL_SRC_FILES_32 := lib32/hdr/libhdr.so
-LOCAL_SRC_FILES_64 := lib64/hdr/libhdr.so
-LOCAL_MULTILIB:= both
-LOCAL_MODULE_TAGS := optional
-include $(BUILD_PREBUILT)
 
-include $(CLEAR_VARS)
-# LOCAL_MODULE_RELATIVE_PATH := $(TARGET_OUT_SHARED_LIBRARIES)/hw
+#LOCAL_MODULE_PATH := $(TARGET_OUT_SHARED_LIBRARIES)/hw
 LOCAL_MODULE_RELATIVE_PATH := hw
 
+LOCAL_LDLIBS := -llog
+
 LOCAL_SHARED_LIBRARIES:= \
     libbinder \
     libutils \
     libcutils \
     libcamera_client \
-    libui	
-	
+    libui
+
+# cedarx libraries
 LOCAL_SHARED_LIBRARIES += \
-	libhdr \
-	libproc
-	
-LOCAL_C_INCLUDES += 								\
+	libMemAdapter    \
+	libvencoder \
+	libvdecoder \
+	libfacedetection \
+	libSmileEyeBlink \
+	libapperceivepeople
+
+#	libcnr
+#	libfacedetection
+#	libsmileeyeblink
+
+LOCAL_C_INCLUDES += \
 	frameworks/base/core/jni/android/graphics 		\
 	frameworks/native/include/media/openmax			\
 	hardware/libhardware/include/hardware			\
 	frameworks/native/include						\
-	frameworks/native/include/media/hardware 		\
-	system/media/camera/include/				\
+	frameworks/av/media/liballwinner/LIBRARY/CODEC/VIDEO/ENCODER/include \
+	frameworks/av/media/liballwinner/LIBRARY/CODEC/VIDEO/DECODER/include \
+	frameworks/native/include/media/hardware \
+	system/core/include/camera \
+	device/softwinner/common/hardware/camera/libfacedetection \
 	device/softwinner/common/hardware/include		\
+	system/media/camera/include/system \
+	system/media/camera/include \
 	$(TARGET_HARDWARE_INCLUDE)
 
 LOCAL_SRC_FILES := \
@@ -187,10 +80,8 @@ LOCAL_SRC_FILES := \
 	OSAL_Mutex.c \
 	OSAL_Queue.c \
 	scaler.c \
-	CameraDebug.cpp \
-	SceneFactory/HDRSceneMode.cpp \
-	SceneFactory/NightSceneMode.cpp \
-	SceneFactory/SceneModeFactory.cpp
+	Libve_Decoder2.c \
+	CameraList.cpp
 
 # choose hal for new driver or old
 SUPPORT_NEW_DRIVER := Y
@@ -206,77 +97,25 @@ LOCAL_SRC_FILES += \
 	V4L2CameraDevice.cpp
 endif
 
-############################################################################
-#####---A64---
-ifneq ($(filter tulip%,$(TARGET_BOARD_PLATFORM)),)
-LOCAL_CFLAGS += -D__A64__
-LOCAL_C_INCLUDES += \
-	frameworks/av/media/liballwinner/LIBRARY/CODEC/VIDEO/ENCODER/include \
-	device/softwinner/common/hardware/camera/libfacedetection \
-	device/softwinner/common/hardware/camera/SceneFactory
-
-LOCAL_SHARED_LIBRARIES += \
-	libMemAdapter    \
-	libvencoder \
-	libfacedetection \
-	libSmileEyeBlink \
-	libapperceivepeople
+ifneq ($(filter nuclear%,$(TARGET_DEVICE)),)
+LOCAL_CFLAGS += -D__SUN5I__
 endif
 
-############################################################################
-
-############################################################################
-#####---A33---
-ifneq ($(filter astar%,$(TARGET_BOARD_PLATFORM)),)
-LOCAL_CFLAGS += -D__A33__
-LOCAL_C_INCLUDES += \
-       frameworks/av/media/liballwinner/LIBRARY/CODEC/VIDEO/ENCODER/include \
-	device/softwinner/common/hardware/camera/libfacedetection \
-	device/softwinner/common/hardware/camera/SceneFactory
-
-LOCAL_SHARED_LIBRARIES += \
-	libMemAdapter    \
-	libvencoder \
-	libfacedetection \
-	libSmileEyeBlink \
-	libapperceivepeople
+ifneq ($(filter crane%,$(TARGET_DEVICE)),)
+LOCAL_CFLAGS += -D__SUN4I__
 endif
 
-############################################################################
-#####---A83---
-ifneq ($(filter octopus%,$(TARGET_BOARD_PLATFORM)),)
-LOCAL_CFLAGS += -D__A83__
-LOCAL_C_INCLUDES += \
-       frameworks/av/media/liballwinner/LIBRARY/CODEC/VIDEO/ENCODER/include \
-	device/softwinner/common/hardware/camera/libfacedetection \
-	device/softwinner/common/hardware/camera/SceneFactory
-
-LOCAL_SHARED_LIBRARIES += \
-	libMemAdapter    \
-	libvencoder \
-	libfacedetection \
-	libSmileEyeBlink \
-	libapperceivepeople
+ifneq ($(filter fiber%,$(TARGET_DEVICE)),)
+LOCAL_CFLAGS += -D__SUN6I__
 endif
 
-############################################################################
-#####---A80---
-ifneq ($(filter kylin%,$(TARGET_BOARD_PLATFORM)),)
-LOCAL_CFLAGS += -D__A80__
-LOCAL_C_INCLUDES += \
-       frameworks/av/media/liballwinner/LIBRARY/CODEC/VIDEO/ENCODER/include \
-	device/softwinner/common/hardware/camera/libfacedetection \
-	device/softwinner/common/hardware/camera/SceneFactory
-
-LOCAL_SHARED_LIBRARIES += \
-	libMemAdapter    \
-	libvencoder \
-	libfacedetection \
-	libSmileEyeBlink \
-	libapperceivepeople
+ifneq ($(filter wing%,$(TARGET_DEVICE)),)
+LOCAL_CFLAGS += -D__SUN7I__
 endif
 
-############################################################################
+ifneq ($(filter jaws%,$(TARGET_DEVICE)),)
+LOCAL_CFLAGS += -D__SUN9I__
+endif
 
 LOCAL_MODULE := camera.$(TARGET_BOARD_PLATFORM)
 $(warning $(LOCAL_MODULE))
diff --git a/hardware/camera/BufferListManager.cpp b/hardware/camera/BufferListManager.cpp
index 2ffee76..43172a8 100755
--- a/hardware/camera/BufferListManager.cpp
+++ b/hardware/camera/BufferListManager.cpp
@@ -1,152 +1,155 @@
-
-#include "CameraDebug.h"
-#if DBG_BUFFER_LIST
-#define LOG_NDEBUG 0
-#endif
-#define LOG_TAG "BufferListManager"
-#include <cutils/log.h>
-
-#include "BufferListManager.h"
-
-namespace android {
-
-BufferListManager::BufferListManager()
-	: mItemCnt(0)
-{
-	F_LOG;
-	list_init(&mList);
-}
-
-BufferListManager::~BufferListManager()
-{
-	F_LOG;
-	
-	struct listnode *node;
-	buffer_node * alloc_buffer;
-
-	/*
-	list_for_each(node, &mList) 
-	{
-		alloc_buffer = node_to_item(node, buffer_node, i_list);
-		if (alloc_buffer != NULL)
-		{
-			if (alloc_buffer->data != NULL)
-			{
-				LOGD("~BufferListManager free: %p", alloc_buffer->data);
-				free(alloc_buffer->data);
-				alloc_buffer->data = NULL;
-			}
-
-			free(alloc_buffer);
-			alloc_buffer = NULL;
-		}
-	}*/
-
-	while((alloc_buffer = pop()) != NULL)
-	{
-		releaseBuffer(alloc_buffer);
-	}
-}
-
-buffer_node * BufferListManager::allocBuffer(uint32_t id, uint32_t min_size)
-{
-	Mutex::Autolock locker(&mLock);
-	
-	F_LOG;
-	
-	buffer_node * alloc_buffer = NULL;
-	alloc_buffer = (buffer_node *)malloc(sizeof(buffer_node));
-	if (alloc_buffer == NULL)
-	{
-		goto ALLOC_BUFFER_ERROR;
-	}
-
-	memset(alloc_buffer, 0, sizeof(buffer_node));
-	alloc_buffer->data = (void*)malloc(min_size);
-	if (alloc_buffer->data == NULL)
-	{
-		goto ALLOC_BUFFER_ERROR;
-	}
-	alloc_buffer->size = min_size;
-	
-	LOGV("allocBuffer: %p", alloc_buffer->data);
-	
-	return alloc_buffer;
-	
-ALLOC_BUFFER_ERROR:
-	if (alloc_buffer != NULL)
-	{
-		if (alloc_buffer->data != NULL)
-		{
-			free(alloc_buffer->data);
-			alloc_buffer->data = NULL;
-		}
-
-		free(alloc_buffer);
-		alloc_buffer = NULL;
-	}
-	return NULL;
-}
-
-void BufferListManager::releaseBuffer(buffer_node * node)
-{
-	Mutex::Autolock locker(&mLock);
-
-	F_LOG;
-	
-	if (node != NULL)
-	{
-		if (node->data != NULL)
-		{
-			LOGV("releaseBuffer: %p", node->data);
-			free(node->data);
-			node->data = NULL;
-		}
-
-		free(node);
-	}
-}
-
-bool BufferListManager::isListEmpty()
-{
-	Mutex::Autolock locker(&mLock);
-	
-	return list_empty(&mList);
-}
-
-int BufferListManager::getItemCnt()
-{
-	Mutex::Autolock locker(&mLock);
-	return mItemCnt;
-}
-buffer_node * BufferListManager::pop()
-{
-	Mutex::Autolock locker(&mLock);
-	
-	F_LOG;
-
-	if(mItemCnt <= 0)
-	{
-		return NULL;
-	}
-	
-	buffer_node * node = node_to_item(list_head(&mList), buffer_node, i_list);
-	
-	list_remove(&node->i_list);
-
-	mItemCnt--;
-	
-	return node;
-}
-
-void BufferListManager::push(buffer_node * node)
-{
-	Mutex::Autolock locker(&mLock);
-	
-	F_LOG;
-	
-	list_add_tail(&mList, &node->i_list);
-	mItemCnt++;
-}
-
-}
+
+#include "CameraDebug.h"
+#if DBG_BUFFER_LIST
+#define LOG_NDEBUG 0
+#endif
+#define LOG_TAG "BufferListManager"
+#include <cutils/log.h>
+
+#include "BufferListManager.h"
+
+namespace android {
+
+BufferListManager::BufferListManager()
+	: mItemCnt(0)
+{
+	F_LOG;
+	list_init(&mList);
+}
+
+BufferListManager::~BufferListManager()
+{
+	F_LOG;
+	
+	struct listnode *node;
+	buffer_node * alloc_buffer;
+
+	/*
+	list_for_each(node, &mList) 
+	{
+		alloc_buffer = node_to_item(node, buffer_node, i_list);
+		if (alloc_buffer != NULL)
+		{
+			if (alloc_buffer->data != NULL)
+			{
+				LOGD("~BufferListManager free: %p", alloc_buffer->data);
+				free(alloc_buffer->data);
+				alloc_buffer->data = NULL;
+			}
+
+			free(alloc_buffer);
+			alloc_buffer = NULL;
+		}
+	}*/
+
+	while((alloc_buffer = pop()) != NULL)
+	{
+		releaseBuffer(alloc_buffer);
+	}
+}
+
+buffer_node * BufferListManager::allocBuffer(uint32_t id, uint32_t min_size)
+{
+	Mutex::Autolock locker(&mLock);
+	
+	F_LOG;
+	
+	buffer_node * alloc_buffer = NULL;
+	alloc_buffer = (buffer_node *)malloc(sizeof(buffer_node));
+	if (alloc_buffer == NULL)
+	{
+		goto ALLOC_BUFFER_ERROR;
+	}
+
+	memset(alloc_buffer, 0, sizeof(buffer_node));
+	alloc_buffer->data = (void*)malloc(min_size);
+	if (alloc_buffer->data == NULL)
+	{
+		goto ALLOC_BUFFER_ERROR;
+	}
+	alloc_buffer->size = min_size;
+	
+	LOGV("allocBuffer: %p", alloc_buffer->data);
+	
+	return alloc_buffer;
+	
+ALLOC_BUFFER_ERROR:
+	if (alloc_buffer != NULL)
+	{
+		if (alloc_buffer->data != NULL)
+		{
+			free(alloc_buffer->data);
+			alloc_buffer->data = NULL;
+		}
+
+		free(alloc_buffer);
+		alloc_buffer = NULL;
+	}
+	return NULL;
+}
+
+void BufferListManager::releaseBuffer(buffer_node * node)
+{
+	Mutex::Autolock locker(&mLock);
+
+	F_LOG;
+	
+	if (node != NULL)
+	{
+		if (node->data != NULL)
+		{
+			LOGV("releaseBuffer: %p", node->data);
+			free(node->data);
+			node->data = NULL;
+		}
+
+		free(node);
+		node = NULL;
+	}
+}
+
+bool BufferListManager::isListEmpty()
+{
+	Mutex::Autolock locker(&mLock);
+	
+	return list_empty(&mList);
+}
+
+int BufferListManager::getItemCnt()
+{
+	Mutex::Autolock locker(&mLock);
+	
+	return mItemCnt;
+}
+
+buffer_node * BufferListManager::pop()
+{
+	Mutex::Autolock locker(&mLock);
+	
+	F_LOG;
+
+	if(mItemCnt <= 0)
+	{
+		return NULL;
+	}
+	
+	buffer_node * node = node_to_item(list_head(&mList), buffer_node, i_list);
+	
+	list_remove(&node->i_list);
+
+	mItemCnt--;
+	
+	return node;
+}
+
+void BufferListManager::push(buffer_node * node)
+{
+	Mutex::Autolock locker(&mLock);
+	
+	F_LOG;
+	
+	list_add_tail(&mList, &node->i_list);
+	mItemCnt++;
+}
+
+}
diff --git a/hardware/camera/BufferListManager.h b/hardware/camera/BufferListManager.h
index 6cfbf61..6b8df31 100755
--- a/hardware/camera/BufferListManager.h
+++ b/hardware/camera/BufferListManager.h
@@ -1,47 +1,48 @@
-
-#ifndef __HAL_BUFFER_LIST_H__
-#define __HAL_BUFFER_LIST_H__
-
-#include <fcntl.h> 
-#include <cutils/list.h>
-#include <utils/Mutex.h>
-
-namespace android {
-
-typedef struct BUFFER_NODE_t
-{
-	struct listnode	i_list; 
-	int				id;
-	void *			data;
-	int				size;
-	char			priv[128];
-	int             fd;
-}buffer_node;
-
-class BufferListManager {
-public:
-	BufferListManager();
-	~BufferListManager();
-
-	// return buffer start address
-	buffer_node * allocBuffer(uint32_t id, uint32_t min_size);
-	void releaseBuffer(buffer_node * node);
-	
-	bool isListEmpty();
-
-	buffer_node * pop();
-	void push(buffer_node * node);
-	int getItemCnt();
-	
-private:
-	Mutex				mLock;
-
-	struct listnode		mList;
-
-	int					mItemCnt;
-};
-
-}; /* namespace android */
-
-#endif  /* __HAL_BUFFER_LIST_H__ */
-
+
+#ifndef __HAL_BUFFER_LIST_H__
+#define __HAL_BUFFER_LIST_H__
+
+#include <fcntl.h> 
+#include <cutils/list.h>
+#include <utils/Mutex.h>
+
+namespace android {
+
+typedef struct BUFFER_NODE_t
+{
+	struct listnode	i_list; 
+	int				id;
+	void *			data;
+	int				size;
+	char			priv[128];
+	int             fd;
+}buffer_node;
+
+class BufferListManager {
+public:
+	BufferListManager();
+	~BufferListManager();
+
+	// return buffer start address
+	buffer_node * allocBuffer(uint32_t id, uint32_t min_size);
+	void releaseBuffer(buffer_node * node);
+	
+	bool isListEmpty();
+
+	buffer_node * pop();
+	void push(buffer_node * node);
+
+	int getItemCnt();
+	
+private:
+	Mutex				mLock;
+
+	struct listnode		mList;
+
+	int					mItemCnt;
+};
+
+}; /* namespace android */
+
+#endif  /* __HAL_BUFFER_LIST_H__ */
+
diff --git a/hardware/camera/CCameraConfig.cpp b/hardware/camera/CCameraConfig.cpp
index 6648ba5..4561e95 100755
--- a/hardware/camera/CCameraConfig.cpp
+++ b/hardware/camera/CCameraConfig.cpp
@@ -88,6 +88,28 @@ CCameraConfig::CCameraConfig(int id)
 	,mDeviceID(0)
 	,mFastPictureMode(false)
 {
+	INIT_PARAMETER(PREVIEW_SIZE, PreviewSize)
+	INIT_PARAMETER(PICTURE_SIZE, PictureSize)
+	INIT_PARAMETER(FLASH_MODE, FlashMode)
+	INIT_PARAMETER(COLOR_EFFECT, ColorEffect)
+	INIT_PARAMETER(FRAME_RATE, FrameRate)
+	INIT_PARAMETER(FOCUS_MODE, FocusMode)
+	INIT_PARAMETER(SCENE_MODE, SceneMode)
+	INIT_PARAMETER(WHITE_BALANCE, WhiteBalance)
+
+	memcpy(mUsedExposureCompensation, "0\0", 2);
+	memset(mMaxExposureCompensation, 0, 4);
+	memset(mMinExposureCompensation, 0, 4);
+	memset(mStepExposureCompensation, 0, 4);
+	memset(mDefaultExposureCompensation, 0, 4);
+
+	memcpy(mUsedZoom, "0\0", 2);
+	memset(mZoomSupported, 0, 8);
+	memset(mSmoothZoomSupported, 0, 4);
+	memset(mZoomRatios, 0, KEY_LENGTH);
+	memset(mMaxZoom, 0, 4);
+	memset(mDefaultZoom, 0, 4);
+
 	mhKeyFile = ::fopen(CAMERA_KEY_CONFIG_PATH, "rb");
 	if (mhKeyFile <= 0)
 	{
@@ -149,9 +171,6 @@ CCameraConfig::CCameraConfig(int id)
 		// LOGV("camera orientation %d", mOrientation);
 	}
 	
-	//init other parameters
-        initParameters();
-	
 	mConstructOk = true;
 }
 
@@ -192,7 +211,7 @@ void CCameraConfig::initParameters()
 	}
 
 	// fast picture mode
-	char str[10];
+	char str[4];
 	if(readKey(kFAST_PICTURE_MODE, str))
 	{
 		mFastPictureMode = (atoi(str) == 1) ? true : false;
@@ -255,10 +274,6 @@ void CCameraConfig::initParameters()
 			// LOGV("\"%s\" not support", kUSED_ZOOM);
 		}
  	}
-	readKey(KHORIZONTAL_VIEW_ANGLE, str);
-	mHorizonalViewAngle = atof(str);
-	readKey(KVERTICAL_VIEW_ANGLE, str);
-	mVerticalViewAngle = atof(str);
 }
 
 void CCameraConfig::dumpParameters()
diff --git a/hardware/camera/CCameraConfig.h b/hardware/camera/CCameraConfig.h
index 80c2d7c..ac140ad 100755
--- a/hardware/camera/CCameraConfig.h
+++ b/hardware/camera/CCameraConfig.h
@@ -64,8 +64,6 @@
 #define kZOOM_RATIOS          				"key_zoom_ratios"
 #define kMAX_ZOOM             				"key_max_zoom"
 #define kDEFAULT_ZOOM         				"key_default_zoom"	
-#define KHORIZONTAL_VIEW_ANGLE "key_horizonal_view_angle"
-#define KVERTICAL_VIEW_ANGLE "key_vertical_view_angle"
 
 #define MEMBER_DEF(mem)				\
 	char mUsed##mem[2];				\
@@ -122,14 +120,6 @@ public:
 	{
 		return mCameraModel;
 	}
-	float getHorizonalViewAngle()
-	{
-		return mHorizonalViewAngle;
-	}
-	float getVerticalViewAngle()
-	{
-		return mVerticalViewAngle;
-	}
 
 	bool supportPreviewSize();
 	char * supportPreviewSizeValue();
@@ -263,8 +253,6 @@ private:
 	char mZoomRatios[KEY_LENGTH];
 	char mMaxZoom[4];
 	char mDefaultZoom[4];
-	float mHorizonalViewAngle;
-	float mVerticalViewAngle;
 };
 
 #endif // __CAMERA_CONFIG_H__
diff --git a/hardware/camera/CallbackNotifier.cpp b/hardware/camera/CallbackNotifier.cpp
index 6ec051c..f47d404 100755
--- a/hardware/camera/CallbackNotifier.cpp
+++ b/hardware/camera/CallbackNotifier.cpp
@@ -8,9 +8,10 @@
 
 #include <cutils/properties.h>
 
-#include "V4L2CameraDevice2.h"
+#include "V4L2CameraDevice.h"
 #include "CallbackNotifier.h"
-
+#include "vencoder.h"
+#include "MetadataBufferType.h"
 
 extern "C" int scaler(unsigned char * psrc, unsigned char * pdst, int src_w, int src_h, int dst_w, int dst_h, int fmt, int align);
 
@@ -33,8 +34,7 @@ static const char* lCameraMessages[] =
     "CAMERA_MSG_CONTINUOUSSNAP",
     "CAMERA_MSG_SNAP"
     "CAMERA_MSG_SNAP_THUMB"
-    "CAMERA_MSG_SNAP_FD",
-	"CAMERA_SMART_MSG_STATUS"
+    "CAMERA_MSG_SNAP_FD"
 };
 static const int lCameraMessagesNum = sizeof(lCameraMessages) / sizeof(char*);
 
@@ -95,9 +95,9 @@ static void PrintMessages(uint32_t msg)
     unsigned char *bufferDstEnd, *bufferSrcEnd;
     uint16_t *bufferSrc_UV;
 
-    unsigned long y_uv[2];
-    y_uv[0] = (unsigned long)src;
-	y_uv[1] = (unsigned long)src + width*height;
+    unsigned int y_uv[2];
+    y_uv[0] = (unsigned int)src;
+	y_uv[1] = (unsigned int)src + width*height;
 
 	// NV12 -> NV21
     if (pixelFormat == V4L2_PIX_FMT_NV12) {
@@ -343,17 +343,13 @@ CallbackNotifier::CallbackNotifier()
 	  mFd(0),
 	  mCBWidth(0),
 	  mCBHeight(0),
+	  mContinuousFdIndex(0),
 	  mBufferList(NULL),
 	  mSaveThreadExited(false),
-	  mIsSinglePicture(true),
-	  mContinuousFdIndex(0),
-	  mISOSpeed(0),
-	  mMeteringMode(0),
-	  mFlashUsed(0),
-	  mExposureMode(0)
+	  mIsSinglePicture(true)
 {
 	LOGV("CallbackNotifier construct");
-	memset(mContinuousFd,0,sizeof(mContinuousFd));
+	
 	memset(mGpsMethod, 0, sizeof(mGpsMethod));
 	memset(mCallingProcessName, 0, sizeof(mCallingProcessName));
 	
@@ -364,6 +360,7 @@ CallbackNotifier::CallbackNotifier()
 
 	memset(mFolderPath, 0, sizeof(mFolderPath));
 	memset(mSnapPath, 0, sizeof(mSnapPath));
+	memset(mContinuousFd, 0, sizeof(mContinuousFd));
 }
 
 CallbackNotifier::~CallbackNotifier()
@@ -404,6 +401,7 @@ void CallbackNotifier::setCallbacks(camera_notify_callback notify_cb,
 	pthread_mutex_init(&mSavePictureMutex, NULL);
 	pthread_cond_init(&mSavePictureCond, NULL);
 	mSavePictureThread->startThread();
+
 	pthread_mutex_init(&mPictureFdMutex, NULL);
 	pthread_cond_init(&mPictureFdCond, NULL);
 }
@@ -430,28 +428,6 @@ void CallbackNotifier::disableMessage(uint msg_type)
     PrintMessages(mMessageEnabler);
 }
 
-void CallbackNotifier::enableSmartMessage(uint msg_type)
-{
-    LOGV("%s: msg_type = 0x%x", __FUNCTION__, msg_type);
-    PrintMessages(msg_type);
-
-    Mutex::Autolock locker(&mObjectLock);
-    mSmartMessageEnabler |= msg_type;
-    LOGV("**** Currently enabled smart detection messages:");
-    PrintMessages(mSmartMessageEnabler);
-}
-
-void CallbackNotifier::disableSmartMessage(uint msg_type)
-{
-    LOGV("%s: msg_type = 0x%x", __FUNCTION__, msg_type);
-    PrintMessages(msg_type);
-
-    Mutex::Autolock locker(&mObjectLock);
-    mSmartMessageEnabler &= ~msg_type;
-    LOGV("**** Currently disabled smart detection messages:");
-    PrintMessages(mSmartMessageEnabler);
-}
-
 status_t CallbackNotifier::enableVideoRecording()
 {
     F_LOG;
@@ -503,6 +479,9 @@ void CallbackNotifier::cleanupCBNotifier()
 		pthread_mutex_destroy(&mSavePictureMutex);
 		pthread_cond_destroy(&mSavePictureCond);
 	}
+
+	
+	
 	pthread_mutex_destroy(&mPictureFdMutex);
 	pthread_cond_destroy(&mPictureFdCond);
 	
@@ -546,244 +525,12 @@ void CallbackNotifier::onNextFrameAvailable(const void* frame,
     	onNextFrameSW(frame);
 	}
 }
-#ifdef __CEDARX_FRAMEWORK_1__
-void CallbackNotifier::onNextFrameHW(const void* frame)
-{
-	V4L2BUF_t * pbuf = (V4L2BUF_t*)frame;
-	
-	if (isMessageEnabled(CAMERA_MSG_VIDEO_FRAME) && isVideoRecordingEnabled()) 
-	{
-        camera_memory_t* cam_buff = mGetMemoryCB(-1, sizeof(V4L2BUF_t), 1, NULL);
-        if (NULL != cam_buff && NULL != cam_buff->data) 
-		{
-			pbuf->refCnt++;
-            memcpy(cam_buff->data, frame, sizeof(V4L2BUF_t));
-            mDataCBTimestamp(pbuf->timeStamp, CAMERA_MSG_VIDEO_FRAME,
-                               cam_buff, 0, mCallbackCookie);
-			cam_buff->release(cam_buff);
-        } 
-		else 
-		{
-            LOGE("%s: Memory failure in CAMERA_MSG_VIDEO_FRAME", __FUNCTION__);
-        }
-    }
-
-    if (isMessageEnabled(CAMERA_MSG_PREVIEW_FRAME)) 
-	{
-        camera_memory_t* cam_buff = mGetMemoryCB(-1, sizeof(V4L2BUF_t), 1, NULL);
-        if (NULL != cam_buff && NULL != cam_buff->data) 
-		{
-            memcpy(cam_buff->data, frame, sizeof(V4L2BUF_t));
-			mDataCB(CAMERA_MSG_PREVIEW_FRAME, cam_buff, 0, NULL, mCallbackCookie);
-			cam_buff->release(cam_buff);
-        } 
-		else 
-		{
-            LOGE("%s: Memory failure in CAMERA_MSG_PREVIEW_FRAME", __FUNCTION__);
-        }
-    }
-}
-
-bool CallbackNotifier::takePicture(const void* frame, bool is_continuous)
-{
-	buffer_node * pNode = NULL;
-	V4L2BUF_t * pbuf = (V4L2BUF_t *)frame;
-	void * pOutBuf = NULL;
-	int bufSize = 0;
-
-	int src_format = 0;
-	unsigned long src_addr_phy = 0;
-	unsigned long src_addr_vir = 0;
-	int src_width = 0;
-	int src_height = 0;
-	RECT_t src_crop;
-
-	DBG_TIME_BEGIN("CallbackNotifier taking picture", 0);
-
-	if ((pbuf->isThumbAvailable == 1)
-		&& (pbuf->thumbUsedForPhoto == 1))
-	{
-		src_format			= pbuf->thumbFormat;
-		src_addr_phy		= pbuf->thumbAddrPhyY;
-		src_addr_vir		= pbuf->thumbAddrVirY;
-		src_width			= pbuf->thumbWidth;
-		src_height			= pbuf->thumbHeight;
-		memcpy((void*)&src_crop, (void*)&pbuf->thumb_crop_rect, sizeof(RECT_t));
-	}
-	else
-	{
-		src_format			= pbuf->format;
-		src_addr_phy		= pbuf->addrPhyY;
-		src_addr_vir		= pbuf->addrVirY;
-		src_width			= pbuf->width;
-		src_height			= pbuf->height;
-		memcpy((void*)&src_crop, (void*)&pbuf->crop_rect, sizeof(RECT_t));
-	}
-
-	JPEG_ENC_t jpeg_enc;
-	memset(&jpeg_enc, 0, sizeof(jpeg_enc));
-	jpeg_enc.addrY			= src_addr_phy;
-	jpeg_enc.addrC			= src_addr_phy + ALIGN_16B(src_width) * src_height;
-	jpeg_enc.src_w			= src_width;
-	jpeg_enc.src_h			= src_height;
-	jpeg_enc.pic_w			= mPictureWidth;
-	jpeg_enc.pic_h			= mPictureHeight;
-	jpeg_enc.colorFormat	= (src_format == V4L2_PIX_FMT_NV21) ? JPEG_COLOR_YUV420_NV21 : JPEG_COLOR_YUV420_NV12;
-	jpeg_enc.quality		= mJpegQuality;
-	jpeg_enc.rotate			= mJpegRotate;
-
-	getCurrentDateTime();
-
-	// 
-	strcpy(jpeg_enc.CameraMake, mExifMake);
-	strcpy(jpeg_enc.CameraModel, mExifModel);
-	strcpy(jpeg_enc.DateTime, mDateTime);
-	
-	jpeg_enc.thumbWidth		= mThumbWidth;
-	jpeg_enc.thumbHeight	= mThumbHeight;
-	jpeg_enc.whitebalance   = mWhiteBalance;
-	jpeg_enc.focal_length	= mFocalLength;	//unused
-
-	//some inportant exif info  --by henrisk
-	jpeg_enc.ExposureTime.num       = mExposureTime.num;
-	jpeg_enc.ExposureTime.den       = mExposureTime.den;
-	jpeg_enc.FNumber.num            = mFNumber.num;
-	jpeg_enc.FNumber.den            = mFNumber.den;
-	jpeg_enc.ISOSpeed               = mISOSpeed;
-	jpeg_enc.ExposureBiasValue.num  = mExposureBiasValue.num;
-	jpeg_enc.ExposureBiasValue.den  = mExposureBiasValue.den;
-	jpeg_enc.MeteringMode           = mMeteringMode;// 0 unknown, 1, average 2. center 3. spot
-	jpeg_enc.FlashUsed              = mFlashUsed;
-	jpeg_enc.FocalLength.num        = mFocalLength_r.num;
-	jpeg_enc.FocalLength.den        = mFocalLength_r.den;
-	jpeg_enc.DigitalZoomRatio.num   = mDigitalZoomRatio.num;
-	jpeg_enc.DigitalZoomRatio.den   = mDigitalZoomRatio.den;
-	jpeg_enc.ExposureMode           = mExposureMode; // 0 auto, 1, menual
-
-	if (0 != strlen(mGpsMethod))
-	{
-		jpeg_enc.enable_gps			= 1;
-		jpeg_enc.gps_latitude		= mGpsLatitude;
-		jpeg_enc.gps_longitude		= mGpsLongitude;
-		jpeg_enc.gps_altitude		= mGpsAltitude;
-		jpeg_enc.gps_timestamp		= mGpsTimestamp;
-		strcpy(jpeg_enc.gps_processing_method, mGpsMethod);
-		memset(mGpsMethod, 0, sizeof(mGpsMethod));
-	}
-	else
-	{
-		jpeg_enc.enable_gps			= 0;
-	}
 
-	if ((src_crop.width != jpeg_enc.src_w)
-		|| (src_crop.height != jpeg_enc.src_h))
-	{
-		jpeg_enc.enable_crop		= 1;
-		jpeg_enc.crop_x				= src_crop.left;
-		jpeg_enc.crop_y				= src_crop.top;
-		jpeg_enc.crop_w				= src_crop.width;
-		jpeg_enc.crop_h				= src_crop.height;
-	}
-	else
-	{
-		jpeg_enc.enable_crop		= 0;
-	}
-	
-	LOGV("addrY: %x, src: %dx%d, pic: %dx%d, quality: %d, rotate: %d, Gps method: %s, \
-		thumbW: %d, thumbH: %d, thubmFactor: %d, crop: [%d, %d, %d, %d]", 
-		jpeg_enc.addrY, 
-		jpeg_enc.src_w, jpeg_enc.src_h,
-		jpeg_enc.pic_w, jpeg_enc.pic_h,
-		jpeg_enc.quality, jpeg_enc.rotate,
-		jpeg_enc.gps_processing_method,
-		jpeg_enc.thumbWidth,
-		jpeg_enc.thumbHeight,
-		jpeg_enc.scale_factor,
-		jpeg_enc.crop_x,
-		jpeg_enc.crop_y,
-		jpeg_enc.crop_w,
-		jpeg_enc.crop_h);
-	
-	pNode = mBufferList->allocBuffer(-1, mPictureWidth * mPictureHeight);
-	if (pNode == NULL)
-	{
-		LOGE("malloc picture node failed");
-		return false;
-	}
-	pOutBuf = pNode->data;
-	if (pOutBuf == NULL)
-	{
-		LOGE("malloc picture memory failed");
-		return false;
-	}
-
-	//int64_t lasttime = systemTime();
-	int ret = JpegEnc(pOutBuf, &bufSize, &jpeg_enc);
-	if (ret < 0)
-	{
-		LOGE("JpegEnc failed");
-		return false;
-	}
-	//LOGV("hw enc time: %lld(ms), size: %d", (systemTime() - lasttime)/1000000, bufSize);
-
-	DBG_TIME_DIFF("enc");
-
-	if (is_continuous)
-	{
-		pNode->id = mSavePictureCnt;
-		pNode->size = bufSize;
-		mBufferList->push(pNode);
-
-		// cb number of pictures
-		if (isMessageEnabled(CAMERA_MSG_CONTINUOUSSNAP)) 
-		{
-			mNotifyCB(CAMERA_MSG_CONTINUOUSSNAP, mSavePictureCnt, 0, mCallbackCookie);
-	    }
-		
-		pthread_cond_signal(&mSavePictureCond);
-
-		mSavePictureCnt++;
-	}
-	else
-	{
-		if ((strlen(mSnapPath) > 0))
-		{
-			camera_memory_t* cb_buff;
-			strcpy(pNode->priv, mSnapPath);
-			pNode->id = -1;
-			pNode->size = bufSize;
-			mBufferList->push(pNode);
-			mNotifyCB(CAMERA_MSG_SNAP, 0, 0, mCallbackCookie);
-			pthread_cond_signal(&mSavePictureCond);
-		}
-		else
-		{
-			camera_memory_t* jpeg_buff = mGetMemoryCB(-1, bufSize, 1, NULL);
-			if (NULL != jpeg_buff && NULL != jpeg_buff->data) 
-			{
-				memcpy(jpeg_buff->data, (uint8_t *)pOutBuf, bufSize); 
-				mDataCB(CAMERA_MSG_COMPRESSED_IMAGE, jpeg_buff, 0, NULL, mCallbackCookie);
-				jpeg_buff->release(jpeg_buff);
-			} 
-			else 
-			{
-				LOGE("%s: Memory failure in CAMERA_MSG_COMPRESSED_IMAGE", __FUNCTION__);
-			}
-
-			mBufferList->releaseBuffer(pNode);
-		}
-	}
-	
-	DBG_TIME_DIFF("photo end");
-	LOGV("taking photo end");
-	return true;
-}
-#elif defined __CEDARX_FRAMEWORK_2__
 void CallbackNotifier::onNextFrameHW(const void* frame)
 {
 	V4L2BUF_t * pbuf = (V4L2BUF_t*)frame;
 	VencInputBuffer sInputBuffer;
-	
+
 	int buffer_type = kMetadataBufferTypeCameraSource;//matadataType
 	memset(&sInputBuffer, 0, sizeof(VencInputBuffer));
 
@@ -814,8 +561,8 @@ void CallbackNotifier::onNextFrameHW(const void* frame)
 		{
 			pbuf->refCnt++;
 			memcpy(cam_buff->data, &buffer_type, 4);
-            memcpy(cam_buff->data + 4, &sInputBuffer, sizeof(VencInputBuffer));
-			
+			memcpy(cam_buff->data + 4, &sInputBuffer, sizeof(VencInputBuffer));
+
             mDataCBTimestamp(pbuf->timeStamp, CAMERA_MSG_VIDEO_FRAME,
                                cam_buff, 0, mCallbackCookie);
 			cam_buff->release(cam_buff);
@@ -832,7 +579,7 @@ void CallbackNotifier::onNextFrameHW(const void* frame)
         if (NULL != cam_buff && NULL != cam_buff->data) 
 		{
 			memcpy(cam_buff->data, &buffer_type, 4);
-            memcpy(cam_buff->data + 4, &sInputBuffer, sizeof(VencInputBuffer));
+			memcpy(cam_buff->data + 4, &sInputBuffer, sizeof(VencInputBuffer));
 			mDataCB(CAMERA_MSG_PREVIEW_FRAME, cam_buff, 0, NULL, mCallbackCookie);
 			cam_buff->release(cam_buff);
         } 
@@ -842,13 +589,11 @@ void CallbackNotifier::onNextFrameHW(const void* frame)
         }
     }
 }
-bool CallbackNotifier::takePicture(const void* frame, bool is_continuous)
-{
-	buffer_node * pNode = NULL;
-	V4L2BUF_t * pbuf = (V4L2BUF_t *)frame;
-	void * pOutBuf = NULL;
-	int bufSize = 0;
 
+void CallbackNotifier::onNextFrameSW(const void* frame)
+{
+	V4L2BUF_t * pbuf = (V4L2BUF_t*)frame;
+	int framesize =0;
 	int src_format = 0;
 	unsigned long src_addr_phy = 0;
 	unsigned long src_addr_vir = 0;
@@ -856,276 +601,8 @@ bool CallbackNotifier::takePicture(const void* frame, bool is_continuous)
 	int src_height = 0;
 	RECT_t src_crop;
 
-	DBG_TIME_BEGIN("CallbackNotifier taking picture", 0);
-
 	if ((pbuf->isThumbAvailable == 1)
-		&& (pbuf->thumbUsedForPhoto == 1))
-	{
-		src_format			= pbuf->thumbFormat;
-		src_addr_phy		= pbuf->thumbAddrPhyY;
-		src_addr_vir		= pbuf->thumbAddrVirY;
-		src_width			= pbuf->thumbWidth;
-		src_height			= pbuf->thumbHeight;
-		memcpy((void*)&src_crop, (void*)&pbuf->thumb_crop_rect, sizeof(RECT_t));
-	}
-	else
-	{
-		src_format			= pbuf->format;
-		src_addr_phy		= pbuf->addrPhyY;
-		src_addr_vir		= pbuf->addrVirY;
-		src_width			= pbuf->width;
-		src_height			= pbuf->height;
-		memcpy((void*)&src_crop, (void*)&pbuf->crop_rect, sizeof(RECT_t));
-	}
-
-	JPEG_ENC_t jpeg_enc;
-	memset(&jpeg_enc, 0, sizeof(jpeg_enc));
-	jpeg_enc.addrY			= src_addr_phy;
-	jpeg_enc.addrC			= src_addr_phy + ALIGN_16B(src_width) * src_height;
-	jpeg_enc.src_w			= src_width;
-	jpeg_enc.src_h			= src_height;
-	jpeg_enc.pic_w			= mPictureWidth;
-	jpeg_enc.pic_h			= mPictureHeight;
-	jpeg_enc.colorFormat	= (src_format == V4L2_PIX_FMT_NV21) ? JPEG_COLOR_YUV420_NV21 : JPEG_COLOR_YUV420_NV12;
-	jpeg_enc.quality		= mJpegQuality;
-	jpeg_enc.rotate			= mJpegRotate;
-
-	getCurrentDateTime();
-
-	// 
-	strcpy(jpeg_enc.CameraMake, mExifMake);
-	strcpy(jpeg_enc.CameraModel, mExifModel);
-	strcpy(jpeg_enc.DateTime, mDateTime);
-	
-	jpeg_enc.thumbWidth		= mThumbWidth;
-	jpeg_enc.thumbHeight	= mThumbHeight;
-	jpeg_enc.whitebalance   = mWhiteBalance;
-	jpeg_enc.focal_length	= mFocalLength;
-
-	if (0 != strlen(mGpsMethod))
-	{
-		jpeg_enc.enable_gps			= 1;
-		jpeg_enc.gps_latitude		= mGpsLatitude;
-		jpeg_enc.gps_longitude		= mGpsLongitude;
-		jpeg_enc.gps_altitude		= mGpsAltitude;
-		jpeg_enc.gps_timestamp		= mGpsTimestamp;
-		strcpy(jpeg_enc.gps_processing_method, mGpsMethod);
-	}
-	else
-	{
-		jpeg_enc.enable_gps			= 0;
-	}
-
-	if ((src_crop.width != jpeg_enc.src_w)
-		|| (src_crop.height != jpeg_enc.src_h))
-	{
-		jpeg_enc.enable_crop		= 1;
-		jpeg_enc.crop_x				= src_crop.left;
-		jpeg_enc.crop_y				= src_crop.top;
-		jpeg_enc.crop_w				= src_crop.width;
-		jpeg_enc.crop_h				= src_crop.height;
-	}
-	else
-	{
-		jpeg_enc.enable_crop		= 0;
-	}
-	
-	LOGV("addrY: %x, src: %dx%d, pic: %dx%d, quality: %d, rotate: %d, Gps method: %s,\
-		thumbW: %d, thumbH: %d, thubmFactor: %d, crop: [%d, %d, %d, %d]", 
-		jpeg_enc.addrY, 
-		jpeg_enc.src_w, jpeg_enc.src_h,
-		jpeg_enc.pic_w, jpeg_enc.pic_h,
-		jpeg_enc.quality, jpeg_enc.rotate,
-		jpeg_enc.gps_processing_method,
-		jpeg_enc.thumbWidth,
-		jpeg_enc.thumbHeight,
-		jpeg_enc.scale_factor,
-		jpeg_enc.crop_x,
-		jpeg_enc.crop_y,
-		jpeg_enc.crop_w,
-		jpeg_enc.crop_h);
-	
-	pNode = mBufferList->allocBuffer(-1, mPictureWidth * mPictureHeight);
-	if (pNode == NULL)
-	{
-		LOGE("malloc picture node failed");
-		return false;
-	}
-	pOutBuf = pNode->data;
-	if (pOutBuf == NULL)
-	{
-		LOGE("malloc picture memory failed");
-		return false;
-	}
-
-	JpegEncInfo sjpegInfo;
-	EXIFInfo   exifInfo;
-	
-	memset(&sjpegInfo, 0, sizeof(JpegEncInfo));
-	memset(&exifInfo, 0, sizeof(EXIFInfo));
-
-	sjpegInfo.sBaseInfo.nInputWidth = src_width;
-	sjpegInfo.sBaseInfo.nInputHeight = src_height;
-	sjpegInfo.sBaseInfo.nDstWidth = mPictureWidth;
-	sjpegInfo.sBaseInfo.nDstHeight = mPictureHeight;
-	sjpegInfo.pAddrPhyY = (unsigned char*)src_addr_phy;
-	sjpegInfo.pAddrPhyC = (unsigned char*)src_addr_phy + ALIGN_16B(src_width) * src_height;
-	sjpegInfo.sBaseInfo.eInputFormat = (src_format == V4L2_PIX_FMT_NV21) ? VENC_PIXEL_YVU420SP: VENC_PIXEL_YUV420SP;
-	sjpegInfo.quality		= mJpegQuality;
-	exifInfo.Orientation    = mJpegRotate;
-
-	if ((src_crop.width != sjpegInfo.sBaseInfo.nInputWidth)
-		|| (src_crop.height != sjpegInfo.sBaseInfo.nInputHeight))
-	{
-		sjpegInfo.bEnableCorp		= 1;
-		sjpegInfo.sCropInfo.nLeft	= src_crop.left;
-		sjpegInfo.sCropInfo.nTop	= src_crop.top;
-		sjpegInfo.sCropInfo.nWidth	= src_crop.width;
-		sjpegInfo.sCropInfo.nHeight	= src_crop.height;
-	}
-	else
-	{
-		sjpegInfo.bEnableCorp		= 0;
-	}
-
-	exifInfo.ThumbWidth = mThumbWidth;
-	exifInfo.ThumbHeight = mThumbHeight;
-
-	LOGV("addrY: %x, src: %dx%d, pic: %dx%d, quality: %d, rotate: %d,\
-		thumbW: %d, thumbH: %d,EnableCorp: %d,crop: [%d, %d, %d, %d]", 
-		sjpegInfo.pAddrPhyY, 
-		sjpegInfo.sBaseInfo.nInputWidth, sjpegInfo.sBaseInfo.nInputHeight,
-		sjpegInfo.sBaseInfo.nDstWidth, sjpegInfo.sBaseInfo.nDstHeight,
-		sjpegInfo.quality, exifInfo.Orientation,
-		exifInfo.ThumbWidth,
-		exifInfo.ThumbHeight,
-		sjpegInfo.bEnableCorp,
-		sjpegInfo.sCropInfo.nLeft,
-		sjpegInfo.sCropInfo.nTop,
-		sjpegInfo.sCropInfo.nWidth,
-		sjpegInfo.sCropInfo.nHeight);
-
-	strcpy((char*)exifInfo.CameraMake,	mExifMake);
-	strcpy((char*)exifInfo.CameraModel,	mExifModel);
-	strcpy((char*)exifInfo.DateTime, mDateTime);
-	LOGV("mGpsMethod:%s,mGpsLatitude:%lf,mGpsLongitude:%lf,mGpsAltitude:%ld,mGpsTimestamp:%ld", \
-		mGpsMethod,
-		mGpsLatitude,
-		mGpsLongitude,
-		mGpsAltitude,
-		mGpsTimestamp); 
-
-	if (0 != strlen(mGpsMethod)){
-		strcpy((char*)exifInfo.gpsProcessingMethod,mGpsMethod);
-		exifInfo.enableGpsInfo = 1;
-		exifInfo.gps_latitude = mGpsLatitude;
-		exifInfo.gps_longitude = mGpsLongitude;
-		exifInfo.gps_altitude = mGpsAltitude;
-		exifInfo.gps_timestamp = mGpsTimestamp;	
-		memset(mGpsMethod, 0, sizeof(mGpsMethod));
-
-	}
-	else
-		exifInfo.enableGpsInfo = 0;
-	
-	exifInfo.ExposureTime.num = mExposureTime.num;
-	exifInfo.ExposureTime.den = mExposureTime.den;
-
-	exifInfo.FNumber.num = mFNumber.num;
-	exifInfo.FNumber.den = mFNumber.den;
-	exifInfo.ISOSpeed = mISOSpeed;
-
-	exifInfo.ExposureBiasValue.num= mExposureBiasValue.num;
-	exifInfo.ExposureBiasValue.den= mExposureBiasValue.den;
-
-	exifInfo.MeteringMode = mMeteringMode;
-	exifInfo.FlashUsed = mFlashUsed;;
-
-	exifInfo.FocalLength.num = mFocalLength_r.num;
-	exifInfo.FocalLength.den = mFocalLength_r.den;
-
-	exifInfo.DigitalZoomRatio.num = mDigitalZoomRatio.num;
-	exifInfo.DigitalZoomRatio.den = mDigitalZoomRatio.den;
-
-	exifInfo.WhiteBalance = mWhiteBalance;
-	exifInfo.ExposureMode = mExposureMode;
-
-	int ret = AWJpecEnc(&sjpegInfo,&exifInfo,pOutBuf,&bufSize);
-	//int64_t lasttime = systemTime();
-	if (ret < 0)
-	{
-		LOGE("JpegEnc failed");
-		return false;
-	}
-	//LOGV("hw enc time: %lld(ms), size: %d", (systemTime() - lasttime)/1000000, bufSize);
-
-	DBG_TIME_DIFF("enc");
-
-	if (is_continuous)
-	{
-		pNode->id = mSavePictureCnt;
-		pNode->size = bufSize;
-		mBufferList->push(pNode);
-
-		// cb number of pictures
-		if (isMessageEnabled(CAMERA_MSG_CONTINUOUSSNAP)) 
-		{
-			mNotifyCB(CAMERA_MSG_CONTINUOUSSNAP, mSavePictureCnt, 0, mCallbackCookie);
-	    }
-		
-		pthread_cond_signal(&mSavePictureCond);
-
-		mSavePictureCnt++;
-	}
-	else
-	{
-		if ((strlen(mSnapPath) > 0))
-		{
-			camera_memory_t* cb_buff;
-			strcpy(pNode->priv, mSnapPath);
-			pNode->id = -1;
-			pNode->size = bufSize;
-			mBufferList->push(pNode);
-			mNotifyCB(CAMERA_MSG_SNAP, 0, 0, mCallbackCookie);
-			pthread_cond_signal(&mSavePictureCond);
-		}
-		else
-		{
-			camera_memory_t* jpeg_buff = mGetMemoryCB(-1, bufSize, 1, NULL);
-			if (NULL != jpeg_buff && NULL != jpeg_buff->data) 
-			{
-				memcpy(jpeg_buff->data, (uint8_t *)pOutBuf, bufSize); 
-				mDataCB(CAMERA_MSG_COMPRESSED_IMAGE, jpeg_buff, 0, NULL, mCallbackCookie);
-				jpeg_buff->release(jpeg_buff);
-			} 
-			else 
-			{
-				LOGE("%s: Memory failure in CAMERA_MSG_COMPRESSED_IMAGE", __FUNCTION__);
-			}
-
-			mBufferList->releaseBuffer(pNode);
-		}
-	}
-	
-	DBG_TIME_DIFF("photo end");
-	LOGV("taking photo end");
-	return true;
-}
-#endif
-
-void CallbackNotifier::onNextFrameSW(const void* frame)
-{
-	V4L2BUF_t * pbuf = (V4L2BUF_t*)frame;
-	int framesize =0;
-	int src_format = 0;
-	unsigned long src_addr_phy = 0;
-	unsigned long src_addr_vir = 0;
-	int src_width = 0;
-	int src_height = 0;
-	RECT_t src_crop;
-
-	if ((pbuf->isThumbAvailable == 1)
-		&& (pbuf->thumbUsedForPreview == 1))
+		&& (pbuf->thumbUsedForPreview == 1))
 	{
 		src_format			= pbuf->thumbFormat;
 		src_addr_phy		= pbuf->thumbAddrPhyY;
@@ -1145,6 +622,7 @@ void CallbackNotifier::onNextFrameSW(const void* frame)
 	}
 	
 	framesize = ALIGN_16B(src_width) * src_height * 3/2;
+	
 	if (isMessageEnabled(CAMERA_MSG_VIDEO_FRAME) && isVideoRecordingEnabled()) 
 	{
         camera_memory_t* cam_buff = mGetMemoryCB(-1, framesize, 1, NULL);
@@ -1177,6 +655,68 @@ void CallbackNotifier::onNextFrameSW(const void* frame)
 	            LOGE("%s: Memory failure in CAMERA_MSG_PREVIEW_FRAME", __FUNCTION__);
 	        }
 		}
+		#if 0
+		else if(/*(src_width == 1920) || */(src_width == 1280) || (src_width == 960) ||(src_width == 800))
+		{
+			// LOGD("src size: %dx%d, cb size: %dx%d,", src_width, src_height, mCBWidth, mCBHeight);
+			framesize = mCBWidth * mCBHeight * 3/2;
+	        camera_memory_t* cam_buff = mGetMemoryCB(-1, framesize, 1, NULL);
+
+			if (NULL == cam_buff 
+				|| NULL == cam_buff->data) 
+			{
+				LOGE("%s: Memory failure in CAMERA_MSG_PREVIEW_FRAME", __FUNCTION__);
+				return;
+			}
+			if (src_format == V4L2_PIX_FMT_YVU420)
+			{
+				// it will be used in cts
+				scaler((unsigned char*)src_addr_vir, (unsigned char*)cam_buff->data, 
+									ALIGN_16B(src_width), src_height,
+									mCBWidth, mCBHeight, /*src_format*/0, 16);
+			}
+			else
+			{
+		    	framesize = ALIGN_16B(src_width) * src_height * 3/2;
+				camera_memory_t* src_addr_vir_copy = mGetMemoryCB(-1, framesize, 1, NULL);
+				if (NULL == src_addr_vir_copy 
+				|| NULL == src_addr_vir_copy->data) 
+				{
+					LOGE("%s: Memory failure in CAMERA_MSG_PREVIEW_FRAME", __FUNCTION__);
+					return;
+				}
+
+				framesize = mCBWidth * mCBHeight * 3/2;
+	        	camera_memory_t* cam_buff_copy = mGetMemoryCB(-1, framesize, 1, NULL);
+				if (NULL == cam_buff_copy 
+				|| NULL == cam_buff_copy->data) 
+				{
+					LOGE("%s: Memory failure in CAMERA_MSG_PREVIEW_FRAME", __FUNCTION__);
+					return;
+				}
+			
+				if (src_format == V4L2_PIX_FMT_NV12)
+				{
+					NV12ToYVU420((void*)src_addr_vir, (void*)src_addr_vir_copy->data, ALIGN_16B(src_width), src_height);
+				}
+				else if(src_format == V4L2_PIX_FMT_NV21)
+				{
+					NV21ToYVU420((void*)src_addr_vir, (void*)src_addr_vir_copy->data, ALIGN_16B(src_width), src_height);
+				}
+				
+				scaler((unsigned char*)src_addr_vir_copy->data, (unsigned char*)cam_buff_copy->data, 
+									ALIGN_16B(src_width), src_height,
+									mCBWidth, mCBHeight, 0, 16);
+				YVU420ToNV21(cam_buff_copy->data, cam_buff->data, mCBWidth, mCBHeight);
+
+				cam_buff_copy->release(cam_buff_copy);
+				src_addr_vir_copy->release(src_addr_vir_copy);
+			}
+			
+            mDataCB(CAMERA_MSG_PREVIEW_FRAME, cam_buff, 0, NULL, mCallbackCookie);
+            cam_buff->release(cam_buff);
+		}
+		#endif
 		else
 		{
 			camera_memory_t* cam_buff = mGetMemoryCB(-1, mCBWidth * mCBHeight * 3 / 2, 1, NULL);
@@ -1240,16 +780,6 @@ status_t CallbackNotifier::faceDetectionMsg(camera_frame_metadata_t *face)
     return NO_ERROR;
 }
 
-status_t CallbackNotifier::smartDetectionMsg(int32_t type)
-{
-		
-	if (isSmartMessageEnabled(CAMERA_SMART_MSG_STATUS))
-	{
-        mNotifyCB(CAMERA_SMART_MSG_STATUS, type, 0, mCallbackCookie);
-    }
-	return NO_ERROR;
-		
-}
 void CallbackNotifier::notifyPictureMsg(const void* frame)
 {
 	F_LOG;
@@ -1318,6 +848,246 @@ void CallbackNotifier::setContinuousPictureCnt(int cnt)
 	mSavePictureMax = cnt;
 }
 
+bool CallbackNotifier::takePicture(const void* frame, bool is_continuous)
+{
+	buffer_node * pNode = NULL;
+	V4L2BUF_t * pbuf = (V4L2BUF_t *)frame;
+	void * pOutBuf = NULL;
+	int bufSize = 0;
+
+	int src_format = 0;
+	unsigned long src_addr_phy = 0;
+	unsigned long src_addr_vir = 0;
+	//unsigned int src_addr_phy = 0;
+	//unsigned int src_addr_vir = 0;
+	int src_width = 0;
+	int src_height = 0;
+	RECT_t src_crop;
+
+	DBG_TIME_BEGIN("CallbackNotifier taking picture", 0);
+
+	if ((pbuf->isThumbAvailable == 1)
+		&& (pbuf->thumbUsedForPhoto == 1))
+	{
+		src_format			= pbuf->thumbFormat;
+		src_addr_phy		= pbuf->thumbAddrPhyY;
+		src_addr_vir		= pbuf->thumbAddrVirY;
+		src_width			= pbuf->thumbWidth;
+		src_height			= pbuf->thumbHeight;
+		memcpy((void*)&src_crop, (void*)&pbuf->thumb_crop_rect, sizeof(RECT_t));
+	}
+	else
+	{
+		src_format			= pbuf->format;
+		src_addr_phy		= pbuf->addrPhyY;
+		src_addr_vir		= pbuf->addrVirY;
+		src_width			= pbuf->width;
+		src_height			= pbuf->height;
+		memcpy((void*)&src_crop, (void*)&pbuf->crop_rect, sizeof(RECT_t));
+	}
+
+	JPEG_ENC_t jpeg_enc;
+	memset(&jpeg_enc, 0, sizeof(jpeg_enc));
+	jpeg_enc.addrY			= src_addr_phy;
+	jpeg_enc.addrC			= src_addr_phy + ALIGN_16B(src_width) * src_height;
+	jpeg_enc.src_w			= src_width;
+	jpeg_enc.src_h			= src_height;
+	jpeg_enc.pic_w			= mPictureWidth;
+	jpeg_enc.pic_h			= mPictureHeight;
+	jpeg_enc.colorFormat	= (src_format == V4L2_PIX_FMT_NV21) ? JPEG_COLOR_YUV420_NV21 : JPEG_COLOR_YUV420_NV12;
+	jpeg_enc.quality		= mJpegQuality;
+	jpeg_enc.rotate			= mJpegRotate;
+
+	getCurrentDateTime();
+
+	// 
+	strcpy(jpeg_enc.CameraMake, mExifMake);
+	strcpy(jpeg_enc.CameraModel, mExifModel);
+	strcpy(jpeg_enc.DateTime, mDateTime);
+	
+	jpeg_enc.thumbWidth		= mThumbWidth;
+	jpeg_enc.thumbHeight	= mThumbHeight;
+	jpeg_enc.whitebalance   = mWhiteBalance;
+	jpeg_enc.focal_length	= mFocalLength;
+
+	if (0 != strlen(mGpsMethod))
+	{
+		jpeg_enc.enable_gps			= 1;
+		jpeg_enc.gps_latitude		= mGpsLatitude;
+		jpeg_enc.gps_longitude		= mGpsLongitude;
+		jpeg_enc.gps_altitude		= mGpsAltitude;
+		jpeg_enc.gps_timestamp		= mGpsTimestamp;
+		strcpy(jpeg_enc.gps_processing_method, mGpsMethod);
+		memset(mGpsMethod, 0, sizeof(mGpsMethod));
+	}
+	else
+	{
+		jpeg_enc.enable_gps			= 0;
+	}
+
+	if ((src_crop.width != jpeg_enc.src_w)
+		|| (src_crop.height != jpeg_enc.src_h))
+	{
+		jpeg_enc.enable_crop		= 1;
+		jpeg_enc.crop_x				= src_crop.left;
+		jpeg_enc.crop_y				= src_crop.top;
+		jpeg_enc.crop_w				= src_crop.width;
+		jpeg_enc.crop_h				= src_crop.height;
+	}
+	else
+	{
+		jpeg_enc.enable_crop		= 0;
+	}
+	
+	LOGV("addrY: %x, src: %dx%d, pic: %dx%d, quality: %d, rotate: %d, Gps method: %s, \
+		thumbW: %d, thumbH: %d, thubmFactor: %d, crop: [%d, %d, %d, %d]", 
+		jpeg_enc.addrY, 
+		jpeg_enc.src_w, jpeg_enc.src_h,
+		jpeg_enc.pic_w, jpeg_enc.pic_h,
+		jpeg_enc.quality, jpeg_enc.rotate,
+		jpeg_enc.gps_processing_method,
+		jpeg_enc.thumbWidth,
+		jpeg_enc.thumbHeight,
+		jpeg_enc.scale_factor,
+		jpeg_enc.crop_x,
+		jpeg_enc.crop_y,
+		jpeg_enc.crop_w,
+		jpeg_enc.crop_h);
+	
+	pNode = mBufferList->allocBuffer(-1, mPictureWidth * mPictureHeight);
+	if (pNode == NULL)
+	{
+		LOGE("malloc picture node failed");
+		return false;
+	}
+	pOutBuf = pNode->data;
+	if (pOutBuf == NULL)
+	{
+		LOGE("malloc picture memory failed");
+		return false;
+	}
+
+	JpegEncInfo sjpegInfo;
+	EXIFInfo   exifInfo;
+
+	memset(&sjpegInfo, 0, sizeof(JpegEncInfo));
+	memset(&exifInfo, 0, sizeof(EXIFInfo));
+
+	sjpegInfo.sBaseInfo.nInputWidth = src_width;
+	sjpegInfo.sBaseInfo.nInputHeight = src_height;
+	sjpegInfo.sBaseInfo.nDstWidth = mPictureWidth;
+	sjpegInfo.sBaseInfo.nDstHeight = mPictureHeight;
+	sjpegInfo.pAddrPhyY = (unsigned char*)src_addr_phy;
+	sjpegInfo.pAddrPhyC = (unsigned char*)src_addr_phy + ALIGN_16B(src_width) * src_height;
+	sjpegInfo.sBaseInfo.eInputFormat = (src_format == V4L2_PIX_FMT_NV21) ? VENC_PIXEL_YVU420SP: VENC_PIXEL_YUV420SP;
+	sjpegInfo.quality		= mJpegQuality;
+	exifInfo.Orientation    = mJpegRotate;
+	sjpegInfo.bEnableCorp  = 0;
+
+	sjpegInfo.sCropInfo.nLeft = 0;
+	sjpegInfo.sCropInfo.nTop = 0;
+	sjpegInfo.sCropInfo.nWidth = 320;
+	sjpegInfo.sCropInfo.nHeight = 240;
+
+	exifInfo.ThumbWidth = 320;
+	exifInfo.ThumbHeight = 240;
+
+	strcpy((char*)exifInfo.CameraMake,		"allwinner make test");
+	strcpy((char*)exifInfo.CameraModel,		"allwinner model test");
+	strcpy((char*)exifInfo.DateTime, 		"2014:02:21 10:54:05");
+	strcpy((char*)exifInfo.gpsProcessingMethod,  "allwinner gps");
+
+	exifInfo.ExposureTime.num = 2;
+	exifInfo.ExposureTime.den = 1000;
+
+	exifInfo.FNumber.num = 20;
+	exifInfo.FNumber.den = 10;
+	exifInfo.ISOSpeed = 50;
+
+	exifInfo.ExposureBiasValue.num= -4;
+	exifInfo.ExposureBiasValue.den= 1;
+
+	exifInfo.MeteringMode = 1;
+	exifInfo.FlashUsed = 0;
+
+	exifInfo.FocalLength.num = 1400;
+	exifInfo.FocalLength.den = 100;
+
+	exifInfo.DigitalZoomRatio.num = 4;
+	exifInfo.DigitalZoomRatio.den = 1;
+
+	exifInfo.WhiteBalance = 1;
+	exifInfo.ExposureMode = 1;
+
+	exifInfo.enableGpsInfo = 0;
+
+	exifInfo.gps_latitude = 23.2368;
+	exifInfo.gps_longitude = 24.3244;
+	exifInfo.gps_altitude = 1234.5;
+	exifInfo.gps_timestamp = (long)time(NULL);
+
+	int ret = AWJpecEnc(&sjpegInfo,&exifInfo,pOutBuf,&bufSize);
+
+	if (ret < 0)
+	{
+		LOGE("JpegEnc failed");
+		return false;
+	}
+	//LOGV("hw enc time: %lld(ms), size: %d", (systemTime() - lasttime)/1000000, bufSize);
+
+	DBG_TIME_DIFF("enc");
+
+	if (is_continuous)
+	{
+		pNode->id = mSavePictureCnt;
+		pNode->size = bufSize;
+		mBufferList->push(pNode);
+
+		// cb number of pictures
+		if (isMessageEnabled(CAMERA_MSG_CONTINUOUSSNAP)) 
+		{
+			mNotifyCB(CAMERA_MSG_CONTINUOUSSNAP, mSavePictureCnt, 0, mCallbackCookie);
+	    }
+		
+		pthread_cond_signal(&mSavePictureCond);
+
+		mSavePictureCnt++;
+	}
+	else
+	{
+		if ((strlen(mSnapPath) > 0))
+		{
+			camera_memory_t* cb_buff;
+			strcpy(pNode->priv, mSnapPath);
+			pNode->id = -1;
+			pNode->size = bufSize;
+			mBufferList->push(pNode);
+			mNotifyCB(CAMERA_MSG_SNAP, 0, 0, mCallbackCookie);
+			pthread_cond_signal(&mSavePictureCond);
+		}
+		else
+		{
+			camera_memory_t* jpeg_buff = mGetMemoryCB(-1, bufSize, 1, NULL);
+			if (NULL != jpeg_buff && NULL != jpeg_buff->data) 
+			{
+				memcpy(jpeg_buff->data, (uint8_t *)pOutBuf, bufSize); 
+				mDataCB(CAMERA_MSG_COMPRESSED_IMAGE, jpeg_buff, 0, NULL, mCallbackCookie);
+				jpeg_buff->release(jpeg_buff);
+			} 
+			else 
+			{
+				LOGE("%s: Memory failure in CAMERA_MSG_COMPRESSED_IMAGE", __FUNCTION__);
+			}
+
+			mBufferList->releaseBuffer(pNode);
+		}
+	}
+	
+	DBG_TIME_DIFF("photo end");
+	LOGV("taking photo end");
+	return true;
+}
+
 void CallbackNotifier::setFd(int fd)
 {
 	if (mIsSinglePicture)
@@ -1406,7 +1176,7 @@ bool CallbackNotifier::savePictureThread()
 		// callback fd
 		camera_memory_t* cb_buff;
 		if (pNode->id >= 0)
-	{
+		{
 			sprintf(pNode->priv, "%s%03d.jpg", mFolderPath, pNode->id);
 		}
 		cb_buff = mGetMemoryCB(-1, strlen(pNode->priv), 1, NULL);
@@ -1491,6 +1261,7 @@ bool CallbackNotifier::savePictureThread()
 			goto SAVE_PICTURE_END;
 		}
 	}
+
 	// write
 	if (pNode->id >= 0)
 	{		
@@ -1512,17 +1283,17 @@ bool CallbackNotifier::savePictureThread()
 		else
 		{
 			sprintf(fname, "%s%03d.jpg", mFolderPath, pNode->id);
-	pf = fopen(fname, "wb+");
-	if (pf != NULL)
-	{
-		LOGV("open %s ok", fname);
-		fwrite((uint8_t *)pNode->data, pNode->size, 1, pf);
-		fflush(pf);
-		fclose(pf);
-	}
-	else
-	{
-		LOGE("open %s failed, %s", fname, strerror(errno));
+			pf = fopen(fname, "wb+");
+			if (pf != NULL)
+			{
+				LOGV("open %s ok", fname);
+				fwrite((uint8_t *)pNode->data, pNode->size, 1, pf);
+				fflush(pf);
+				fclose(pf);
+			}
+			else
+			{
+				LOGE("open %s failed, %s", fname, strerror(errno));
 				goto SAVE_PICTURE_END;
 			}
 		}
@@ -1561,6 +1332,7 @@ bool CallbackNotifier::savePictureThread()
 	
 	DBG_TIME_DIFF("write file");
 
+	// single snap callback thumb
 	if (pNode->id < 0)
 	{
 		camera_memory_t* cb_buff;
@@ -1604,29 +1376,5 @@ void CallbackNotifier::onCameraDeviceError(int err)
         mNotifyCB(CAMERA_MSG_ERROR, err, 0, mCallbackCookie);
     }
 }
-void CallbackNotifier::setExifInfo(struct isp_exif_attribute exifinfo,int zoom_ratio,int exposure_bias)
-{
-	mExposureTime.num = exifinfo.exposure_time.numerator;
-	mExposureTime.den = exifinfo.exposure_time.denominator;
-	mFNumber.num = exifinfo.fnumber;	//eg:FNum=2.2, aperture = 220, --> num = 220,den = 100
-	mFNumber.den = 100;
-	mISOSpeed = exifinfo.iso_speed;
-	mExposureBiasValue.num = exposure_bias;
-	mExposureBiasValue.den = 1;
-	mMeteringMode = 1;
-	mFlashUsed = exifinfo.flash_fire;
-	mFocalLength_r.num = exifinfo.focal_length;
-	mFocalLength_r.den = 100;
-	mDigitalZoomRatio.num = zoom_ratio;
-	mDigitalZoomRatio.den = 100;
-	mExposureMode = 0;
-	LOGD("exif_attri fnumber: %d",mFNumber.num);
-	LOGD("exif_attri exposure_time: %d  %d",mExposureTime.num,mExposureTime.den);
-	LOGD("exif_attri iso_speed: %d",mISOSpeed);
-	LOGD("exif_attri focal_length: %d",mFocalLength_r.num);
-	LOGD("exif_attri flash_fire: %d",mFlashUsed);
-	LOGD("exif_attri mDigitalZoomRatio: %d",mDigitalZoomRatio);
-	LOGD("exif_attri exposure_bias: %d",mExposureBiasValue.num);
-}
 
 }; /* namespace android */
diff --git a/hardware/camera/CallbackNotifier.h b/hardware/camera/CallbackNotifier.h
index a6f3d82..6756014 100755
--- a/hardware/camera/CallbackNotifier.h
+++ b/hardware/camera/CallbackNotifier.h
@@ -3,18 +3,12 @@
 #define __HAL_CALLBACK_NOTIFIER_H__
 
 #include "BufferListManager.h"
-#include "CameraPlatform.h"
+
 /*
  * Contains declaration of a class CallbackNotifier that manages callbacks set
  * via set_callbacks, enable_msg_type, and disable_msg_type camera HAL API.
  */
-#ifdef __CEDARX_FRAMEWORK_1__
-extern "C" int JpegEnc(void * pBufOut, int * bufSize, JPEG_ENC_t *jpeg_enc);
-
-#elif defined __CEDARX_FRAMEWORK_2__
-#include "vencoder.h"
-#include "MetadataBufferType.h"
-#endif	
+	
 	
 	enum ThreadState {
 		THREAD_STATE_NULL,		// The thread has not been created.
@@ -71,8 +65,6 @@ public:
      */
     void disableMessage(uint msg_type);
 
-    void enableSmartMessage(uint msg_type);
-    void disableSmartMessage(uint msg_type);
     /* Actual handler for camera_device_ops_t::store_meta_data_in_buffers
      * callback. This method is called by the containing V4L2Camera object
      * when it is handing the camera_device_ops_t::store_meta_data_in_buffers
@@ -109,10 +101,6 @@ public:
     {
         return mMessageEnabler & msg_type;
     }
-    inline int isSmartMessageEnabled(uint msg_type)
-    {
-        return (mSmartMessageEnabler & 0x0fff) & msg_type;
-    }
 
     /* Checks id video recording is enabled.
      * This method is called by the containing V4L2Camera object when it is
@@ -196,7 +184,6 @@ protected:
     /* Message enabler. */
     uint32_t                        mMessageEnabler;
 
-    uint32_t                        mSmartMessageEnabler;
     /* Video recording status. */
     bool                            mVideoRecEnabled;
 
@@ -250,7 +237,6 @@ public:
 	inline void setGPSMethod(const char * gpsMethod)
 	{
 		strcpy(mGpsMethod, gpsMethod);
-		LOGV("%s, mGpsMethod = %s", __FUNCTION__, mGpsMethod);
 	}
 
 	inline void setJpegThumbnailSize(int w, int h)
@@ -294,11 +280,13 @@ public:
 	{
 		mIsSinglePicture = single;
 	}
+	
 	void setFd(int fd);
+
 	status_t autoFocusMsg(bool success);
 	status_t autoFocusContinuousMsg(bool success);
 	status_t faceDetectionMsg(camera_frame_metadata_t *face);
-    status_t smartDetectionMsg(int32_t type);
+
 	bool takePicture(const void* frame, bool is_continuous = false);
 	void startContinuousPicture();
 	void stopContinuousPicture();
@@ -309,7 +297,6 @@ public:
 
 	void getCurrentDateTime();
 	
-	void setExifInfo(struct isp_exif_attribute exifinfo,int zoom_ratio,int exposure_bias);
 	// -------------------------------------------------------------------------
 	// continuous picture
 	// -------------------------------------------------------------------------
@@ -353,6 +340,7 @@ protected:
 	
 	pthread_mutex_t 				mPictureFdMutex;
 	pthread_cond_t					mPictureFdCond;
+	
 protected:
 	// calling process name for some app, such as facelock
 	char							mCallingProcessName[128];
@@ -387,23 +375,14 @@ protected:
 	char                            mFolderPath[128];
 	char                            mSnapPath[128];
 	int                             mFd;
-
-	//exif info
-	rational_t		mExposureTime;
-	rational_t		mFNumber;
-	short			mISOSpeed;
-	rational_t 		mExposureBiasValue;
-	short			mMeteringMode;
-	short			mFlashUsed;
-	rational_t		mFocalLength_r;
-	rational_t		mDigitalZoomRatio;
-	short			mExposureMode;
+	
 	// cb size
 	int								mCBWidth;
 	int								mCBHeight;
 
 	BufferListManager *				mBufferList;
 	bool							mSaveThreadExited;
+
 	bool							mIsSinglePicture;
 	int                             mContinuousFd[10];
 	int								mContinuousFdIndex;
diff --git a/hardware/camera/CameraDebug.cpp b/hardware/camera/CameraDebug.cpp
deleted file mode 100755
index 95195ba..0000000
--- a/hardware/camera/CameraDebug.cpp
+++ /dev/null
@@ -1,65 +0,0 @@
-#include "CameraDebug.h"
-
-#define LOG_TAG "CameraDebug"
-#include <cutils/log.h>
-#include <fcntl.h>
-#include <sys/mman.h>
-#include <sys/time.h>
-
-#ifdef __PLATFORM_A64__
-#include <sunxi_camera.h>
-#else
-#include <videodev2_34.h>
-#endif
-
-#define PATH "/data/camera/"
-
-bool saveframe(char *str,void *p, unsigned int length,bool is_oneframe)
-{
-    int fd;
-	LOGD("Debug to save a frame!");
-    if(access(str,0) != -1) {
-		LOGW("File %s is exists!!!\n",str);
-		return true;
-	}
-    if(is_oneframe)
-        fd = open(str,O_CREAT|O_RDWR|O_TRUNC,0777);        //save one frame data
-    else
-        fd = open(str,O_CREAT|O_RDWR|O_APPEND,0777);       //save more frames
-    if(!fd) {
-        LOGE("Open file error");
-        return false;
-    }
-    if(write(fd,p,length)){
-        //LOGD("Write file successfully");
-        close(fd);
-        return true;
-    }
-    else {
-        LOGE("Write file fail");
-        close(fd);
-        return false;
-    }
-}
-
-bool saveSize(int width, int height)
-{
-	int fd;
-	char buf[128];
-	fd = open("/data/camera/size.txt",O_CREAT|O_RDWR|O_APPEND,0777);
-	if(!fd) {
-        LOGE("Open file error");
-        return false;
-    }
-	sprintf(buf,"width:%d height:%d",width,height);
-	if(write(fd,(void*)buf,sizeof(buf))) {
-		close(fd);
-		return true;
-	}
-	else {
-		LOGE("Write file fail");
-        close(fd);
-        return false;
-	}
-}
-
diff --git a/hardware/camera/CameraDebug.h b/hardware/camera/CameraDebug.h
index 71320bf..59912cd 100755
--- a/hardware/camera/CameraDebug.h
+++ b/hardware/camera/CameraDebug.h
@@ -1,118 +1,138 @@
-#ifndef __HAL_CAMERA_DEBUG_H__
-#define __HAL_CAMERA_DEBUG_H__
-
-#define CAMERA_HAL_VERSION		"3000130327_V1.0"
-
-#define CAMERA_HAL_MODE_OLD		1
-#if	(CAMERA_HAL_MODE_OLD == 1)
-#define USE_OLD_MODE
-#else
-#define USE_NEW_MODE
-#endif
-#define USE_ION_MEM_ALLOCATOR
-
-#define ALIGN_4K(x) (((x) + (4095)) & ~(4095))
-#define ALIGN_32B(x) (((x) + (31)) & ~(31))
-#define ALIGN_16B(x) (((x) + (15)) & ~(15))
-#define ALIGN_8B(x) (((x) + (7)) & ~(7))
-
-#define DBG_CAMERA_HARDWARE		  0
-#define DBG_V4L2_CAMERA			  0
-#define DBG_PREVIEW				  0
-#define DBG_CALLBACK			  0
-#define DBG_CAMERA_FACTORY		  0
-#define DBG_CAMERA_CONFIG		  0
-#define DBG_BUFFER_LIST			  0
-#define DBG_BUFFER_SAVE			  0
-
-/* Defines whether we should trace parameter changes. */
-#define DEBUG_PARAM 0
-
-#define DEBUG_MSG	0
-
-// enable all print information
-#define LOG_NDEBUG 1
-
-#define F_LOG ALOGV("%s, line: %d", __FUNCTION__, __LINE__);
-
-#define LOGV	ALOGV
-#define LOGD	ALOGD
-#define LOGW	ALOGW
-#define LOGE	ALOGE
-#define PATH "/data/camera/"
-
-#define LOGE_IF	ALOGE_IF
-#define LOGW_IF	ALOGW_IF
-
-// performance debug
-#define DBG_TIME_ENABLE		0
-#if DBG_TIME_ENABLE
-#define LOG_TIME			ALOGD
-#define DBG_TIME_BEGIN(inf, en)											\
-	int64_t llt_ms = systemTime() / 1000000;							\
-	int64_t lt_ms = llt_ms;												\
-	int64_t nt_ms = 0;													\
-	if (en)	LOG_TIME("\t[T_DBG_bgn] %s timestamp: %lld", inf, lt_ms);
-
-#define DBG_TIME_DIFF(inf)												\
-	nt_ms = systemTime() / 1000000;										\
-	LOG_TIME("\t[T_DBG_dff] %s use: %lld(ms)", inf, (nt_ms - lt_ms));	\
-	lt_ms = nt_ms;
-
-#define DBG_TIME_END(inf, en)											\
-	nt_ms = systemTime() / 1000000;										\
-	LOG_TIME("\t[T_DBG_end] %s use: %lld(ms)", inf, (nt_ms - llt_ms));	\
-	if (en) LOG_TIME("\t[T_DBG_end] %s timestamp: %lld", inf, nt_ms);
-#else
-#define DBG_TIME_BEGIN(inf, en)
-#define DBG_TIME_DIFF(inf)
-#define DBG_TIME_END(inf, en)
-#endif
-
-#define DBG_TIME_AVG_ENABLE		0
-#if DBG_TIME_AVG_ENABLE
-#define LOG_TIME_AVG			ALOGD
-#define DBG_TIME_AVG_BEGIN(tag)											\
-	static int64_t tag##_time = 0;										\
-	static int tag##_cnt = 0;
-
-#define DBG_TIME_AVG_INIT(tag)											\
-	tag##_time = 0;	tag##_cnt = 0;
-
-#define DBG_TIME_AVG_AREA_IN(tag)										\
-	int64_t tag##_diff = systemTime();
-	
-#define DBG_TIME_AVG_AREA_OUT(tag)										\
-	tag##_diff = systemTime() - tag##_diff;								\
-	tag##_time += tag##_diff;											\
-	tag##_cnt++;
-	
-#define DBG_TIME_AVG_END(tag, inf)										\
-	if (tag##_cnt > 0) LOG_TIME_AVG("\t[T_DBG_avg] %s cnt: %d, average use: %lld(us)", inf, tag##_cnt, tag##_time/tag##_cnt/1000);
-#else
-#define DBG_TIME_AVG_BEGIN(tag)
-#define DBG_TIME_AVG_INIT(tag)
-#define DBG_TIME_AVG_AREA_IN(tag)
-#define DBG_TIME_AVG_AREA_OUT(tag)
-#define DBG_TIME_AVG_END(tag, inf)
-#endif
-
-
-#ifdef __SUN4I__
-#define USE_MP_CONVERT
-#endif
-
-#ifdef __SUN6I__
-#define USE_MP_CONVERT
-#endif
-
-#ifdef __SUN9I__
- 
+#ifndef __HAL_CAMERA_DEBUG_H__
+#define __HAL_CAMERA_DEBUG_H__
+
+#define CAMERA_HAL_VERSION		"3000130327_V1.0"
+
+#define CAMERA_HAL_MODE_OLD		1
+#if	(CAMERA_HAL_MODE_OLD == 1)
+#define USE_OLD_MODE
+#else
+#define USE_NEW_MODE
+#endif
+
+#define USE_ION_MEM_ALLOCATOR
+
+#define ALIGN_4K(x) (((x) + (4095)) & ~(4095))
+#define ALIGN_32B(x) (((x) + (31)) & ~(31))
+#define ALIGN_16B(x) (((x) + (15)) & ~(15))
+#define ALIGN_8B(x) (((x) + (7)) & ~(7))
+
+#define DBG_CAMERA_HARDWARE		0
+#define DBG_V4L2_CAMERA			0
+#define DBG_PREVIEW				0
+#define DBG_CALLBACK			0
+#define DBG_CAMERA_FACTORY		0
+#define DBG_CAMERA_CONFIG		0
+#define DBG_BUFFER_LIST			0
+
+/* Defines whether we should trace parameter changes. */
+#define DEBUG_PARAM 0
+
+#define DEBUG_MSG	0
+
+#define __PLATFORM_H64__
+#define CDX20
+// enable all print information
+//#define LOG_NDEBUG 0
+
+#define F_LOG ALOGV("%s, line: %d", __FUNCTION__, __LINE__);
+
+#define LOGV	ALOGV
+#define LOGD	ALOGD
+#define LOGW	ALOGW
+#define LOGE	ALOGE
+
+#define LOGE_IF	ALOGE_IF
+#define LOGW_IF	ALOGW_IF
+
+// performance debug
+#define DBG_TIME_ENABLE		0
+#if DBG_TIME_ENABLE
+#define LOG_TIME			ALOGD
+#define DBG_TIME_BEGIN(inf, en)											\
+	int64_t llt_ms = systemTime() / 1000000;							\
+	int64_t lt_ms = llt_ms;												\
+	int64_t nt_ms = 0;													\
+	if (en)	LOG_TIME("\t[T_DBG_bgn] %s timestamp: %lld", inf, lt_ms);
+
+#define DBG_TIME_DIFF(inf)												\
+	nt_ms = systemTime() / 1000000;										\
+	LOG_TIME("\t[T_DBG_dff] %s use: %lld(ms)", inf, (nt_ms - lt_ms));	\
+	lt_ms = nt_ms;
+
+#define DBG_TIME_END(inf, en)											\
+	nt_ms = systemTime() / 1000000;										\
+	LOG_TIME("\t[T_DBG_end] %s use: %lld(ms)", inf, (nt_ms - llt_ms));	\
+	if (en) LOG_TIME("\t[T_DBG_end] %s timestamp: %lld", inf, nt_ms);
+#else
+#define DBG_TIME_BEGIN(inf, en)
+#define DBG_TIME_DIFF(inf)
+#define DBG_TIME_END(inf, en)
+#endif
+
+#define DBG_TIME_AVG_ENABLE		0
+#if DBG_TIME_AVG_ENABLE
+#define LOG_TIME_AVG			ALOGD
+#define DBG_TIME_AVG_BEGIN(tag)											\
+	static int64_t tag##_time = 0;										\
+	static int tag##_cnt = 0;
+
+#define DBG_TIME_AVG_INIT(tag)											\
+	tag##_time = 0;	tag##_cnt = 0;
+
+#define DBG_TIME_AVG_AREA_IN(tag)										\
+	int64_t tag##_diff = systemTime();
+	
+#define DBG_TIME_AVG_AREA_OUT(tag)										\
+	tag##_diff = systemTime() - tag##_diff;								\
+	tag##_time += tag##_diff;											\
+	tag##_cnt++;
+	
+#define DBG_TIME_AVG_END(tag, inf)										\
+	if (tag##_cnt > 0) LOG_TIME_AVG("\t[T_DBG_avg] %s cnt: %d, average use: %lld(us)", inf, tag##_cnt, tag##_time/tag##_cnt/1000);
+#else
+#define DBG_TIME_AVG_BEGIN(tag)
+#define DBG_TIME_AVG_INIT(tag)
+#define DBG_TIME_AVG_AREA_IN(tag)
+#define DBG_TIME_AVG_AREA_OUT(tag)
+#define DBG_TIME_AVG_END(tag, inf)
+#endif
+
+
+#ifdef __SUN4I__
+#define USE_MP_CONVERT
+#endif
+
+#ifdef __SUN6I__
 #define USE_MP_CONVERT
-#endif /*USE_ION_MEM_ALLOCATOR*/
-
-extern  bool saveframe(char *str,void *p, unsigned int length,bool is_oneframe);
-extern bool saveSize(int width, int height);
-
-#endif // __HAL_CAMERA_DEBUG_H__
-
+#endif
+
+#ifdef __SUN9I__
+//#define USE_MP_CONVERT
+#endif
+
+
+#ifdef USE_ION_MEM_ALLOCATOR
+extern "C" int ion_alloc_open();
+extern "C" int ion_alloc_close();
+extern "C" int ion_alloc_alloc(int size);
+extern "C" void ion_alloc_free(void * pbuf);
+extern "C" int ion_alloc_vir2phy(void * pbuf);
+extern "C" int ion_alloc_phy2vir(void * pbuf);
+extern "C" void ion_flush_cache(void* startAddr, int size);
+extern "C" void ion_flush_cache_all();
+ 
+#elif USE_SUNXI_MEM_ALLOCATOR
+extern "C" int sunxi_alloc_open();
+extern "C" int sunxi_alloc_close();
+extern "C" int sunxi_alloc_alloc(int size);
+extern "C" void sunxi_alloc_free(void * pbuf);
+extern "C" int sunxi_alloc_vir2phy(void * pbuf);
+extern "C" int sunxi_alloc_phy2vir(void * pbuf);
+extern "C" void sunxi_flush_cache(void* startAddr, int size);
+extern "C" void sunxi_flush_cache_all();
+#endif
+
+
+#endif // __HAL_CAMERA_DEBUG_H__
+
diff --git a/hardware/camera/CameraHardware.cpp b/hardware/camera/CameraHardware.cpp
new file mode 100755
index 0000000..f37bec7
--- /dev/null
+++ b/hardware/camera/CameraHardware.cpp
@@ -0,0 +1,2633 @@
+
+#include "CameraDebug.h"
+#if DBG_CAMERA_HARDWARE
+#define LOG_NDEBUG 0
+#endif
+#define LOG_TAG "CameraHardware"
+#include <cutils/log.h>
+
+#include <cutils/properties.h>
+#include <ui/Rect.h>
+
+#include <drv_display.h>
+
+#include "CameraHardware.h"
+#include "V4L2CameraDevice.h"
+
+#define BASE_ZOOM	0
+
+namespace android {
+
+// defined in HALCameraFactory.cpp
+extern void getCallingProcessName(char *name);
+
+#if DEBUG_PARAM
+/* Calculates and logs parameter changes.
+ * Param:
+ *  current - Current set of camera parameters.
+ *  new_par - String representation of new parameters.
+ */
+static void PrintParamDiff(const CameraParameters& current, const char* new_par);
+#else
+#define PrintParamDiff(current, new_par)   (void(0))
+#endif  /* DEBUG_PARAM */
+
+/* A helper routine that adds a value to the camera parameter.
+ * Param:
+ *  param - Camera parameter to add a value to.
+ *  val - Value to add.
+ * Return:
+ *  A new string containing parameter with the added value on success, or NULL on
+ *  a failure. If non-NULL string is returned, the caller is responsible for
+ *  freeing it with 'free'.
+ */
+static char* AddValue(const char* param, const char* val);
+
+static int faceNotifyCb(int cmd, void * data, void * user)
+{
+	CameraHardware* camera_hw = (CameraHardware *)user;
+	
+	switch (cmd)
+	{
+		case FACE_NOTITY_CMD_REQUEST_FRAME:
+			return camera_hw->getCurrentFaceFrame(data);
+			
+		case FACE_NOTITY_CMD_RESULT:
+			return camera_hw->faceDetection((camera_frame_metadata_t*)data);
+
+		case FACE_NOTITY_CMD_POSITION:
+			{
+				FocusArea_t * pdata = (FocusArea_t *)data;
+				char face_area[128];
+				sprintf(face_area, "(%d, %d, %d, %d, 1)", 
+						pdata->x, pdata->y, pdata->x1, pdata->y1);
+				return camera_hw->parse_focus_areas(face_area);
+			}
+		case FACE_NOTITY_CMD_REQUEST_ORIENTION:
+			camera_hw->getCurrentOriention((int*)data);
+			break;
+			
+		default:
+			break;
+	}
+	
+	return 0;
+}
+
+// Parse string like "640x480" or "10000,20000"
+static int parse_pair(const char *str, int *first, int *second, char delim,
+                      char **endptr = NULL)
+{
+    // Find the first integer.
+    char *end;
+    int w = (int)strtol(str, &end, 10);
+    // If a delimeter does not immediately follow, give up.
+    if (*end != delim) {
+        LOGE("Cannot find delimeter (%c) in str=%s", delim, str);
+        return -1;
+    }
+
+    // Find the second integer, immediately after the delimeter.
+    int h = (int)strtol(end+1, &end, 10);
+
+    *first = w;
+    *second = h;
+
+    if (endptr) {
+        *endptr = end;
+    }
+
+    return 0;
+}
+
+CameraHardware::CameraHardware(struct hw_module_t* module, CCameraConfig* pCameraCfg)
+        : mPreviewWindow(),
+          mCallbackNotifier(),
+          mCameraConfig(pCameraCfg),
+          mIsCameraIdle(true),
+          mFirstSetParameters(true),
+          mFullSizeWidth(0),
+          mFullSizeHeight(0),
+          mCaptureWidth(0),
+          mCaptureHeight(0),
+          mIsSupportFocus(false),
+          mIsSupportEffect(false),
+          mIsSupportFlash(false),
+          mIsSupportScene(false),
+          mIsSupportWhiteBlance(false),
+          mIsSupportExposure(false),
+          mVideoCaptureWidth(0),
+          mVideoCaptureHeight(0),
+          mZoomRatio(0),
+          mUseHwEncoder(false),
+          mFaceDetection(NULL),
+          mFocusStatus(FOCUS_STATUS_IDLE),
+          mIsSingleFocus(false),
+          mOriention(0)
+{
+    /*
+     * Initialize camera_device descriptor for this object.
+     */
+	F_LOG;
+
+    /* Common header */
+    common.tag = HARDWARE_DEVICE_TAG;
+    common.version = 0;
+    common.module = module;
+    common.close = CameraHardware::close;
+
+    /* camera_device fields. */
+    ops = &mDeviceOps;
+    priv = this;
+
+	// instance V4L2CameraDevice object
+	mV4L2CameraDevice = new V4L2CameraDevice(this, &mPreviewWindow, &mCallbackNotifier);
+	if (mV4L2CameraDevice == NULL)
+	{
+		LOGE("Failed to create V4L2Camera instance");
+		return ;
+	}
+
+	memset((void*)mCallingProcessName, 0, sizeof(mCallingProcessName));
+
+	memset(&mFrameRectCrop, 0, sizeof(mFrameRectCrop));
+	memset((void*)mFocusAreasStr, 0, sizeof(mFocusAreasStr));
+	memset((void*)&mFocusAreas, 0, sizeof(mFocusAreas));
+	memset(&mHalCameraInfo, 0, sizeof(mHalCameraInfo));
+
+	// init command queue
+	OSAL_QueueCreate(&mQueueCommand, CMD_QUEUE_MAX);
+	memset((void*)mQueueElement, 0, sizeof(mQueueElement));
+
+	// init command thread
+	pthread_mutex_init(&mCommandMutex, NULL);
+	pthread_cond_init(&mCommandCond, NULL);
+	mCommandThread = new DoCommandThread(this);
+	mCommandThread->startThread();
+	
+	// init auto focus thread
+	pthread_mutex_init(&mAutoFocusMutex, NULL);
+	pthread_cond_init(&mAutoFocusCond, NULL);
+	mAutoFocusThread = new DoAutoFocusThread(this);
+}
+
+CameraHardware::~CameraHardware()
+{
+	if (mCommandThread != NULL)
+	{
+		mCommandThread->stopThread();
+		pthread_cond_signal(&mCommandCond);
+		mCommandThread.clear();
+		mCommandThread = 0;
+	}
+		
+	pthread_mutex_destroy(&mCommandMutex);
+	pthread_cond_destroy(&mCommandCond);
+	
+	if (mAutoFocusThread != NULL)
+	{
+		mAutoFocusThread.clear();
+		mAutoFocusThread = 0;
+	}
+
+	pthread_mutex_destroy(&mAutoFocusMutex);
+	pthread_cond_destroy(&mAutoFocusCond);
+
+	OSAL_QueueTerminate(&mQueueCommand);
+
+	if (mFaceDetection != NULL)
+	{
+		DestroyFaceDetectionDev(mFaceDetection);
+		mFaceDetection = NULL;
+	}
+
+	if (mV4L2CameraDevice != NULL)
+	{
+		delete mV4L2CameraDevice;
+		mV4L2CameraDevice = NULL;
+	}
+}
+
+// single focus
+bool CameraHardware::autoFocusThread()
+{
+	pthread_mutex_lock(&mAutoFocusMutex);
+	pthread_cond_wait(&mAutoFocusCond, &mAutoFocusMutex);
+	if (mAutoFocusThread->getThreadStatus() == THREAD_STATE_EXIT)
+	{
+		LOGD("autoFocusThread exited");
+		pthread_mutex_unlock(&mAutoFocusMutex);
+		return false;
+	}
+	pthread_mutex_unlock(&mAutoFocusMutex);
+	
+	int ret = 0;
+	const char *new_focus_mode_str = mParameters.get(CameraParameters::KEY_FOCUS_MODE);
+
+	if (!mCameraConfig->supportFocusMode())
+	{
+		goto FOCUS_END;
+	}
+	
+	if (!strcmp(new_focus_mode_str, CameraParameters::FOCUS_MODE_INFINITY)
+		|| !strcmp(new_focus_mode_str, CameraParameters::FOCUS_MODE_FIXED))
+	{
+		// 
+	}
+	else
+	{
+		bool timeout = false;
+		int64_t lastTimeMs = systemTime() / 1000000;
+		
+		setAutoFocusCtrl(V4L2_AF_TRIG_SINGLE, NULL);
+		usleep(200000);
+
+		while(1)
+		{
+			// if hw af ok
+			ret = mV4L2CameraDevice->getAutoFocusStatus(V4L2_AF_TRIG_SINGLE);
+			if ( ret == 0)
+			{
+				LOGV("auto focus ok, use time: %lld(ms)", systemTime() / 1000000 - lastTimeMs);
+				break;
+			}
+			else if (ret == EBUSY)
+			{
+				if ((systemTime() / 1000000 - lastTimeMs) > 5000)	// 5s timeout
+				{
+					LOGW("auto focus time out");
+					timeout = true;
+					break;
+				}
+				//LOGV("wait auto focus ......");
+				usleep(10000);
+			}
+			else if (ret == EFAULT)
+			{
+				LOGW("auto focus failed");
+				break;
+			}
+			else if (ret < 0)
+			{
+				LOGE("auto focus interface error");
+				break;
+			}
+		}
+
+		if (ret == 0)
+		{
+			setAutoFocusCtrl(V4L2_AF_LOCK, NULL);
+		}
+	}
+
+FOCUS_END:
+
+	mCallbackNotifier.autoFocusMsg(ret == 0);
+	
+	LOGV("auto focus end");
+
+	return true;
+}
+
+bool CameraHardware::commandThread()
+{
+	pthread_mutex_lock(&mCommandMutex);
+	if (mCommandThread->getThreadStatus() == THREAD_STATE_EXIT)
+	{
+		LOGD("commandThread exited");
+		pthread_mutex_unlock(&mCommandMutex);
+		return false;
+	}
+	pthread_mutex_unlock(&mCommandMutex);
+	
+	Queue_Element * queue = (Queue_Element *)OSAL_Dequeue(&mQueueCommand);
+	if (queue == NULL)
+	{
+		LOGV("wait commond queue ......");
+		pthread_mutex_lock(&mCommandMutex);
+		pthread_cond_wait(&mCommandCond, &mCommandMutex);
+		pthread_mutex_unlock(&mCommandMutex);
+		return true;
+	}
+
+	V4L2CameraDevice* pV4L2Device = mV4L2CameraDevice;
+	int cmd = queue->cmd;
+	switch(cmd)
+	{
+		case CMD_QUEUE_SET_COLOR_EFFECT:
+		{
+			int new_image_effect = queue->data;
+			LOGV("CMD_QUEUE_SET_COLOR_EFFECT: %d", new_image_effect);
+			
+			if (pV4L2Device->setImageEffect(new_image_effect) < 0) 
+			{
+                LOGE("ERR(%s):Fail on mV4L2Camera->setImageEffect(effect(%d))", __FUNCTION__, new_image_effect);
+            }
+			break;
+		}
+		case CMD_QUEUE_SET_WHITE_BALANCE:
+		{
+			int new_white = queue->data;
+			LOGV("CMD_QUEUE_SET_WHITE_BALANCE: %d", new_white);
+			
+            if (pV4L2Device->setWhiteBalance(new_white) < 0) 
+			{
+                LOGE("ERR(%s):Fail on mV4L2Camera->setWhiteBalance(white(%d))", __FUNCTION__, new_white);
+            }
+			break;
+		}
+		case CMD_QUEUE_SET_EXPOSURE_COMPENSATION:
+		{
+			int new_exposure_compensation = queue->data;
+			LOGV("CMD_QUEUE_SET_EXPOSURE_COMPENSATION: %d", new_exposure_compensation);
+			
+			if (pV4L2Device->setExposure(new_exposure_compensation) < 0) 
+			{
+				LOGE("ERR(%s):Fail on mV4L2Camera->setBrightness(brightness(%d))", __FUNCTION__, new_exposure_compensation);
+			}
+			break;
+		}
+		case CMD_QUEUE_SET_FLASH_MODE:
+		{
+			LOGD("CMD_QUEUE_SET_FLASH_MODE to do ...");
+			break;
+		}
+		case CMD_QUEUE_SET_FOCUS_MODE:
+		{
+			LOGV("CMD_QUEUE_SET_FOCUS_MODE");
+			if(setAutoFocusMode() != OK)
+	        {
+				LOGE("unknown focus mode");
+	       	}
+			break;
+		}
+		case CMD_QUEUE_SET_FOCUS_AREA:
+		{
+			char * new_focus_areas_str = (char *)queue->data;
+			if (new_focus_areas_str != NULL)
+			{
+				LOGV("CMD_QUEUE_SET_FOCUS_AREA: %s", new_focus_areas_str);
+        		parse_focus_areas(new_focus_areas_str);
+			}
+        	break;
+		}
+		case CMD_QUEUE_START_FACE_DETECTE:
+		{
+			int width = 0, height = 0;
+			LOGV("CMD_QUEUE_START_FACE_DETECTE");
+			const char * preview_capture_width_str = mParameters.get(KEY_PREVIEW_CAPTURE_SIZE_WIDTH);
+			const char * preview_capture_height_str = mParameters.get(KEY_PREVIEW_CAPTURE_SIZE_HEIGHT);
+			if (preview_capture_width_str != NULL
+				&& preview_capture_height_str != NULL)
+			{
+				width  = atoi(preview_capture_width_str);
+				height = atoi(preview_capture_height_str);
+			}
+			if (mFaceDetection != 0)
+			{
+				usleep(500000);
+				mFaceDetection->ioctrl(mFaceDetection, FACE_OPS_CMD_START, width, height);
+			}
+			else
+			{
+				LOGW("CMD_QUEUE_START_FACE_DETECTE failed, mFaceDetection not opened.");
+			}
+			break;
+		}
+		case CMD_QUEUE_STOP_FACE_DETECTE:
+		{
+			LOGV("CMD_QUEUE_STOP_FACE_DETECTE");
+			if (mFaceDetection != 0)
+			{
+				mFaceDetection->ioctrl(mFaceDetection, FACE_OPS_CMD_STOP, 0, 0);
+			}
+			else
+			{
+				LOGW("CMD_QUEUE_STOP_FACE_DETECTE failed, mFaceDetection not opened.");
+			}
+			break;
+		}
+		case CMD_QUEUE_TAKE_PICTURE:
+		{
+			LOGV("CMD_QUEUE_TAKE_PICTURE");
+			doTakePicture();
+			break;
+		}
+		case CMD_QUEUE_PICTURE_MSG:
+		{
+			LOGV("CMD_QUEUE_PICTURE_MSG");
+			void * frame = (void *)queue->data;
+			mCallbackNotifier.notifyPictureMsg(frame);
+			if (strcmp(mCallingProcessName, "com.android.cts.stub") != 0
+				&& strcmp(mCallingProcessName, "com.android.cts.mediastress") != 0)
+			{
+				doTakePictureEnd();
+			}
+			break;
+		}
+		case CMD_QUEUE_STOP_CONTINUOUSSNAP:
+		{
+			cancelPicture();
+			doTakePictureEnd();
+			break;
+		}
+		case CMD_QUEUE_SET_FOCUS_STATUS:
+		{
+			mCallbackNotifier.autoFocusMsg(true);
+			break;
+		}
+		default:
+			LOGW("unknown queue command: %d", cmd);
+			break;
+	}
+	
+	return true;
+}
+
+/****************************************************************************
+ * Public API
+ ***************************************************************************/
+
+status_t CameraHardware::Initialize()
+{
+	F_LOG;
+
+	getCallingProcessName(mCallingProcessName);
+	mCallbackNotifier.setCallingProcess(mCallingProcessName);
+/*
+	if (mFaceDetection == NULL)
+	{
+		// create FaceDetection object
+		CreateFaceDetectionDev(&mFaceDetection);
+		if (mFaceDetection == NULL)
+		{
+			LOGE("create FaceDetection failed");
+			return UNKNOWN_ERROR;
+		}
+	}
+
+	mFaceDetection->ioctrl(mFaceDetection, FACE_OPS_CMD_REGISTE_USER, (int)this, 0);
+	mFaceDetection->setCallback(mFaceDetection, faceNotifyCb);
+*/
+	initDefaultParameters();
+
+    return NO_ERROR;
+}
+
+void CameraHardware::initDefaultParameters()
+{
+    CameraParameters p = mParameters;
+	String8 parameterString;
+	char * value;
+
+	// version
+	p.set(KEY_CAMERA_HAL_VERSION, CAMERA_HAL_VERSION);
+
+	// facing and orientation
+	if (mHalCameraInfo.facing == CAMERA_FACING_BACK)
+	{
+	    p.set(CameraHardware::FACING_KEY, CameraHardware::FACING_BACK);
+	    LOGV("%s: camera is facing %s", __FUNCTION__, CameraHardware::FACING_BACK);
+	}
+	else
+	{
+	    p.set(CameraHardware::FACING_KEY, CameraHardware::FACING_FRONT);
+	    LOGV("%s: camera is facing %s", __FUNCTION__, CameraHardware::FACING_FRONT);
+	}
+	
+    p.set(CameraHardware::ORIENTATION_KEY, mHalCameraInfo.orientation);
+
+	// exif Make and Model
+	mCallbackNotifier.setExifMake(mCameraConfig->getExifMake());
+	mCallbackNotifier.setExifModel(mCameraConfig->getExifModel());
+
+	LOGD("........................... to do initDefaultParameters");
+	// for USB camera
+	if (mHalCameraInfo.is_uvc)
+	{
+		// preview, picture, video size
+		char sizeStr[256];
+		mV4L2CameraDevice->enumSize(sizeStr, 256);
+		LOGV("enum size: %s", sizeStr);
+		if (strlen(sizeStr) > 0)
+		{
+			p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_SIZES, sizeStr);
+			p.set(CameraParameters::KEY_SUPPORTED_PICTURE_SIZES, sizeStr);
+		}
+		else
+		{
+			p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_SIZES, "640x480");
+			p.set(CameraParameters::KEY_SUPPORTED_PICTURE_SIZES, "640x480");
+		}
+		p.set(CameraParameters::KEY_PREVIEW_SIZE, "640x480");
+		p.set(CameraParameters::KEY_PICTURE_SIZE, "640x480");
+		p.set(CameraParameters::KEY_VIDEO_SIZE, "640x480");
+
+		// add for android CTS
+		p.set(CameraParameters::KEY_SUPPORTED_FOCUS_MODES, CameraParameters::FOCUS_MODE_AUTO);
+		p.set(CameraParameters::KEY_FOCUS_MODE, CameraParameters::FOCUS_MODE_AUTO);
+		p.set(CameraParameters::KEY_FOCUS_AREAS, "(0,0,0,0,0)");
+		p.set(CameraParameters::KEY_FOCAL_LENGTH, "3.43");
+		mCallbackNotifier.setFocalLenght(3.43);
+		p.set(CameraParameters::KEY_FOCUS_DISTANCES, "0.10,1.20,Infinity");
+
+		// fps
+		p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FRAME_RATES, "30");
+		p.set(CameraParameters::KEY_PREVIEW_FPS_RANGE, "5000,60000");				// add temp for CTS
+		p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FPS_RANGE, "(5000,60000)");	// add temp for CTS
+		p.set(CameraParameters::KEY_PREVIEW_FRAME_RATE, "30");
+		mV4L2CameraDevice->setFrameRate(30);
+
+		// exposure compensation
+		p.set(CameraParameters::KEY_MIN_EXPOSURE_COMPENSATION, "0");
+		p.set(CameraParameters::KEY_MAX_EXPOSURE_COMPENSATION, "0");
+		p.set(CameraParameters::KEY_EXPOSURE_COMPENSATION_STEP, "0");
+		p.set(CameraParameters::KEY_EXPOSURE_COMPENSATION, "0");
+		
+		goto COMMOM_PARAMS;
+	}
+
+	// fast picture mode
+	if (mHalCameraInfo.fast_picture_mode)
+	{
+		// capture size of picture-mode preview
+		
+		
+		// any other differences ??
+		
+	}
+	
+	// preview size
+	LOGV("init preview size");
+	value = mCameraConfig->supportPreviewSizeValue();
+	p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_SIZES, value);
+	LOGV("supportPreviewSizeValue: [%s] %s", CameraParameters::KEY_SUPPORTED_PREVIEW_SIZES, value);
+
+#ifdef USE_NEW_MODE
+	// KEY_SUPPORTED_VIDEO_SIZES and KEY_PREFERRED_PREVIEW_SIZE_FOR_VIDEO should be set
+	// at the same time, or both NULL. 
+	// At present, we use preview and video the same size. Next version, maybe different.
+	p.set(CameraParameters::KEY_SUPPORTED_VIDEO_SIZES, value);
+	p.set(CameraParameters::KEY_PREFERRED_PREVIEW_SIZE_FOR_VIDEO, "1280x720");
+#endif
+
+	value = mCameraConfig->defaultPreviewSizeValue();
+	p.set(CameraParameters::KEY_PREVIEW_SIZE, value);
+	p.set(CameraParameters::KEY_VIDEO_SIZE, value);
+	
+	// picture size
+	LOGV("to init picture size");
+	value = mCameraConfig->supportPictureSizeValue();
+	p.set(CameraParameters::KEY_SUPPORTED_PICTURE_SIZES, value);
+	LOGV("supportPreviewSizeValue: [%s] %s", CameraParameters::KEY_SUPPORTED_PICTURE_SIZES, value);
+
+	value = mCameraConfig->defaultPictureSizeValue();
+	p.set(CameraParameters::KEY_PICTURE_SIZE, value);
+
+	// frame rate
+	LOGV("to init frame rate");
+	value = mCameraConfig->supportFrameRateValue();
+	p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FRAME_RATES, value);
+	LOGV("supportFrameRateValue: [%s] %s", CameraParameters::KEY_SUPPORTED_PREVIEW_FRAME_RATES, value);
+
+	p.set(CameraParameters::KEY_PREVIEW_FPS_RANGE, "5000,60000");				// add temp for CTS
+	p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FPS_RANGE, "(5000,60000)");	// add temp for CTS
+
+	value = mCameraConfig->defaultFrameRateValue();
+	p.set(CameraParameters::KEY_PREVIEW_FRAME_RATE, value);
+
+	mV4L2CameraDevice->setFrameRate(atoi(value));
+
+	// focus
+	LOGV("to init focus");
+	if (mCameraConfig->supportFocusMode())
+	{
+		value = mCameraConfig->supportFocusModeValue();
+		p.set(CameraParameters::KEY_SUPPORTED_FOCUS_MODES, value);
+		value = mCameraConfig->defaultFocusModeValue();
+		p.set(CameraParameters::KEY_FOCUS_MODE, value);
+		p.set(CameraParameters::KEY_MAX_NUM_FOCUS_AREAS,"1");
+	}
+	else
+	{
+		// add for CTS
+		p.set(CameraParameters::KEY_SUPPORTED_FOCUS_MODES, CameraParameters::FOCUS_MODE_FIXED);
+		p.set(CameraParameters::KEY_FOCUS_MODE, CameraParameters::FOCUS_MODE_FIXED);
+	}
+	p.set(CameraParameters::KEY_FOCUS_AREAS, "(0,0,0,0,0)");
+	p.set(CameraParameters::KEY_FOCAL_LENGTH, "3.43");
+	mCallbackNotifier.setFocalLenght(3.43);
+	p.set(CameraParameters::KEY_FOCUS_DISTANCES, "0.10,1.20,Infinity");
+
+	
+	// color effect 
+	LOGV("to init color effect");
+	if (mCameraConfig->supportColorEffect())
+	{
+		value = mCameraConfig->supportColorEffectValue();
+		p.set(CameraParameters::KEY_SUPPORTED_EFFECTS, value);
+		value = mCameraConfig->defaultColorEffectValue();
+		p.set(CameraParameters::KEY_EFFECT, value);
+	}
+
+	// flash mode
+	LOGV("to init flash mode");
+	if (mCameraConfig->supportFlashMode())
+	{
+		value = mCameraConfig->supportFlashModeValue();
+		p.set(CameraParameters::KEY_SUPPORTED_FLASH_MODES, value);
+		value = mCameraConfig->defaultFlashModeValue();
+		p.set(CameraParameters::KEY_FLASH_MODE, value);
+	}
+
+	// scene mode
+	LOGV("to init scene mode");
+	if (mCameraConfig->supportSceneMode())
+	{
+		value = mCameraConfig->supportSceneModeValue();
+		p.set(CameraParameters::KEY_SUPPORTED_SCENE_MODES, value);
+		value = mCameraConfig->defaultSceneModeValue();
+		p.set(CameraParameters::KEY_SCENE_MODE, value);
+	}
+
+	// white balance
+	LOGV("to init white balance");
+	if (mCameraConfig->supportWhiteBalance())
+	{
+		value = mCameraConfig->supportWhiteBalanceValue();
+		p.set(CameraParameters::KEY_SUPPORTED_WHITE_BALANCE, value);
+		value = mCameraConfig->defaultWhiteBalanceValue();
+		p.set(CameraParameters::KEY_WHITE_BALANCE, value);
+	}
+
+	// exposure compensation
+	LOGV("to init exposure compensation");
+	if (mCameraConfig->supportExposureCompensation())
+	{
+		value = mCameraConfig->minExposureCompensationValue();
+		p.set(CameraParameters::KEY_MIN_EXPOSURE_COMPENSATION, value);
+
+		value = mCameraConfig->maxExposureCompensationValue();
+		p.set(CameraParameters::KEY_MAX_EXPOSURE_COMPENSATION, value);
+
+		value = mCameraConfig->stepExposureCompensationValue();
+		p.set(CameraParameters::KEY_EXPOSURE_COMPENSATION_STEP, value);
+
+		value = mCameraConfig->defaultExposureCompensationValue();
+		p.set(CameraParameters::KEY_EXPOSURE_COMPENSATION, value);
+	}
+	else
+	{
+		p.set(CameraParameters::KEY_MIN_EXPOSURE_COMPENSATION, "0");
+		p.set(CameraParameters::KEY_MAX_EXPOSURE_COMPENSATION, "0");
+		p.set(CameraParameters::KEY_EXPOSURE_COMPENSATION_STEP, "0");
+		p.set(CameraParameters::KEY_EXPOSURE_COMPENSATION, "0");
+	}
+
+COMMOM_PARAMS:
+	// zoom
+	LOGV("to init zoom");
+	p.set(CameraParameters::KEY_ZOOM_SUPPORTED, "true");
+	p.set(CameraParameters::KEY_SMOOTH_ZOOM_SUPPORTED, "false");
+	p.set(CameraParameters::KEY_MAX_ZOOM, "100");
+
+	int max_zoom = 100;
+	char zoom_ratios[1024];
+	memset(zoom_ratios, 0, 1024);
+	for (int i = 0; i <= max_zoom; i++)
+	{
+		int i_ratio = 200 * i / max_zoom + 100;
+		char str[8];
+		sprintf(str, "%d,", i_ratio);
+		strcat(zoom_ratios, str);
+	}
+	int len = strlen(zoom_ratios);
+	zoom_ratios[len - 1] = 0;
+	LOGV("zoom_ratios: %s", zoom_ratios);
+	p.set(CameraParameters::KEY_ZOOM_RATIOS, zoom_ratios);
+	p.set(CameraParameters::KEY_ZOOM, "0");
+
+	mV4L2CameraDevice->setCrop(BASE_ZOOM, max_zoom);
+
+	mZoomRatio = 100;
+	
+	// for some apps
+	if (strcmp(mCallingProcessName, "com.android.facelock") == 0)
+	{
+		p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_SIZES, "160x120");
+		p.set(CameraParameters::KEY_PREVIEW_SIZE, "160x120");
+	}
+
+	// capture size
+	const char *parm = p.get(CameraParameters::KEY_PREVIEW_SIZE);
+	parse_pair(parm, &mCaptureWidth, &mCaptureHeight, 'x');
+	LOGV("default preview size: %dx%d", mCaptureWidth, mCaptureHeight);
+
+	p.set(KEY_CAPTURE_SIZE_WIDTH, mCaptureWidth);
+	p.set(KEY_CAPTURE_SIZE_HEIGHT, mCaptureHeight);
+	p.set(KEY_PREVIEW_CAPTURE_SIZE_WIDTH, mCaptureWidth);
+	p.set(KEY_PREVIEW_CAPTURE_SIZE_HEIGHT, mCaptureHeight);
+
+	mCallbackNotifier.setCBSize(mCaptureWidth, mCaptureHeight);
+
+	// preview formats, CTS must support at least 2 formats
+	parameterString = CameraParameters::PIXEL_FORMAT_YUV420SP;			// NV21, default
+	parameterString.append(",");
+	parameterString.append(CameraParameters::PIXEL_FORMAT_YUV420P);		// YV12
+	p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FORMATS, parameterString.string());
+	
+	p.set(CameraParameters::KEY_VIDEO_FRAME_FORMAT, CameraParameters::PIXEL_FORMAT_YUV420SP);
+	p.set(CameraParameters::KEY_PREVIEW_FORMAT, CameraParameters::PIXEL_FORMAT_YUV420SP);
+
+    p.set(CameraParameters::KEY_SUPPORTED_PICTURE_FORMATS, CameraParameters::PIXEL_FORMAT_JPEG);
+	
+	p.set(CameraParameters::KEY_JPEG_QUALITY, "95"); // maximum quality
+	p.set(CameraParameters::KEY_SUPPORTED_JPEG_THUMBNAIL_SIZES, "320x240,0x0");
+	p.set(CameraParameters::KEY_JPEG_THUMBNAIL_WIDTH, "320");
+	p.set(CameraParameters::KEY_JPEG_THUMBNAIL_HEIGHT, "240");
+	p.set(CameraParameters::KEY_JPEG_THUMBNAIL_QUALITY, "90");
+	
+	p.setPictureFormat(CameraParameters::PIXEL_FORMAT_JPEG);
+
+	mCallbackNotifier.setJpegThumbnailSize(320, 240);
+
+	// record hint
+	p.set(CameraParameters::KEY_RECORDING_HINT, "false");
+
+	// rotation
+	p.set(CameraParameters::KEY_ROTATION, 0);
+		
+	// add for CTS
+	p.set(CameraParameters::KEY_HORIZONTAL_VIEW_ANGLE, "51.2");
+    p.set(CameraParameters::KEY_VERTICAL_VIEW_ANGLE, "39.4");
+
+	p.set(CameraParameters::KEY_MAX_NUM_DETECTED_FACES_HW, 10);
+	p.set(CameraParameters::KEY_MAX_NUM_DETECTED_FACES_SW, 0);
+	
+	// take picture in video mode
+	p.set(CameraParameters::KEY_VIDEO_SNAPSHOT_SUPPORTED, "true");
+
+	mParameters = p;
+
+	mFirstSetParameters = true;
+
+	LOGV("CameraHardware::initDefaultParameters ok");
+}
+
+void CameraHardware::onCameraDeviceError(int err)
+{
+	F_LOG;
+    /* Errors are reported through the callback notifier */
+    mCallbackNotifier.onCameraDeviceError(err);
+}
+
+/****************************************************************************
+ * Camera API implementation.
+ ***************************************************************************/
+
+status_t CameraHardware::setCameraHardwareInfo(HALCameraInfo * halInfo)
+{
+	// check input params
+	if (halInfo == NULL)
+	{
+		LOGE("ERROR camera info");
+		return EINVAL;
+	}
+	
+	memcpy((void*)&mHalCameraInfo, (void*)halInfo, sizeof(HALCameraInfo));
+
+	return NO_ERROR;
+}
+
+bool CameraHardware::isCameraIdle()
+{
+	Mutex::Autolock locker(&mCameraIdleLock);
+	return mIsCameraIdle;
+}
+
+status_t CameraHardware::connectCamera(hw_device_t** device)
+{
+    F_LOG;
+    status_t res = EINVAL;
+	
+	{
+		Mutex::Autolock locker(&mCameraIdleLock);
+		mIsCameraIdle = false;
+	}
+
+	if (mV4L2CameraDevice != NULL)
+	{
+		res = mV4L2CameraDevice->connectDevice(&mHalCameraInfo);
+		if (res == NO_ERROR)
+		{
+			*device = &common;
+			if (mCameraConfig->supportFocusMode())
+			{
+				// auto focus init for some module
+				setAutoFocusCtrl(V4L2_AF_INIT, NULL);
+			
+				// start focus thread
+				mAutoFocusThread->startThread();
+			}
+		}
+		else
+		{
+			Mutex::Autolock locker(&mCameraIdleLock);
+			mIsCameraIdle = true;
+		}
+	}
+    return -res;
+}
+
+status_t CameraHardware::closeCamera()
+{
+    F_LOG;
+	
+    return cleanupCamera();
+}
+
+status_t CameraHardware::setPreviewWindow(struct preview_stream_ops* window)
+{
+	F_LOG;
+    /* Callback should return a negative errno. */
+	return -mPreviewWindow.setPreviewWindow(window);
+}
+
+void CameraHardware::setCallbacks(camera_notify_callback notify_cb,
+                                  camera_data_callback data_cb,
+                                  camera_data_timestamp_callback data_cb_timestamp,
+                                  camera_request_memory get_memory,
+                                  void* user)
+{
+	F_LOG;
+    mCallbackNotifier.setCallbacks(notify_cb, data_cb, data_cb_timestamp,
+                                    get_memory, user);
+}
+
+void CameraHardware::enableMsgType(int32_t msg_type)
+{
+    mCallbackNotifier.enableMessage(msg_type);
+}
+
+void CameraHardware::disableMsgType(int32_t msg_type)
+{
+    mCallbackNotifier.disableMessage(msg_type);
+}
+
+int CameraHardware::isMsgTypeEnabled(int32_t msg_type)
+{
+    return mCallbackNotifier.isMessageEnabled(msg_type);
+}
+
+status_t CameraHardware::startPreview()
+{
+	F_LOG;
+    Mutex::Autolock locker(&mObjectLock);
+    /* Callback should return a negative errno. */
+    return -doStartPreview();
+}
+
+void CameraHardware::stopPreview()
+{
+	F_LOG;
+	
+	mQueueElement[CMD_QUEUE_STOP_FACE_DETECTE].cmd = CMD_QUEUE_STOP_FACE_DETECTE;
+	OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_STOP_FACE_DETECTE]);
+	pthread_cond_signal(&mCommandCond);
+	
+    Mutex::Autolock locker(&mObjectLock);
+    doStopPreview();
+}
+
+int CameraHardware::isPreviewEnabled()
+{
+	F_LOG;
+    return mPreviewWindow.isPreviewEnabled();
+}
+
+status_t CameraHardware::storeMetaDataInBuffers(int enable)
+{
+	F_LOG;
+    /* Callback should return a negative errno. */
+    return -mCallbackNotifier.storeMetaDataInBuffers(enable);
+}
+
+status_t CameraHardware::startRecording()
+{
+	F_LOG;
+	
+	// video hint
+    const char * valstr = mParameters.get(CameraParameters::KEY_RECORDING_HINT);
+    if (valstr) 
+	{
+		LOGV("KEY_RECORDING_HINT: %s -> true", valstr);
+    }
+
+	mParameters.set(KEY_SNAP_PATH, "");
+	mCallbackNotifier.setSnapPath("");
+
+	mParameters.set(CameraParameters::KEY_RECORDING_HINT, CameraParameters::TRUE);
+
+	if (mVideoCaptureWidth != mCaptureWidth
+		|| mVideoCaptureHeight != mCaptureHeight)
+	{
+		doStopPreview();
+		doStartPreview();
+	}
+	
+    /* Callback should return a negative errno. */
+    return -mCallbackNotifier.enableVideoRecording();
+}
+
+void CameraHardware::stopRecording()
+{
+	F_LOG;
+    mCallbackNotifier.disableVideoRecording();
+	mV4L2CameraDevice->setHwEncoder(false);
+}
+
+int CameraHardware::isRecordingEnabled()
+{
+	F_LOG;
+    return mCallbackNotifier.isVideoRecordingEnabled();
+}
+
+void CameraHardware::releaseRecordingFrame(const void* opaque)
+{
+	if (mUseHwEncoder)
+	{
+    	mV4L2CameraDevice->releasePreviewFrame(*(int*)opaque);
+	}
+}
+
+/****************************************************************************
+ * Focus 
+ ***************************************************************************/
+
+status_t CameraHardware::setAutoFocus()
+{
+	if (!mCameraConfig->supportFocusMode())
+	{
+		mQueueElement[CMD_QUEUE_SET_FOCUS_STATUS].cmd = CMD_QUEUE_SET_FOCUS_STATUS;
+		OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_SET_FOCUS_STATUS]);
+		pthread_cond_signal(&mCommandCond);
+		
+		return OK;
+	}
+	
+	pthread_cond_signal(&mAutoFocusCond);
+
+	return OK;
+}
+
+status_t CameraHardware::cancelAutoFocus()
+{
+	F_LOG;
+
+	/* TODO: Future enhancements. */
+	return NO_ERROR;
+}
+
+int CameraHardware::parse_focus_areas(const char *str)
+{
+	int ret = -1;
+	char *ptr,*tmp;
+	char p1[6] = {0}, p2[6] = {0};
+	char p3[6] = {0}, p4[6] = {0}, p5[6] = {0};
+	int  l,t,r,b;
+	int  w,h;
+
+	if (str == NULL
+		|| !mCameraConfig->supportFocusMode())
+	{
+		return 0;
+	}
+
+	// LOGV("parse_focus_areas : %s", str);
+
+	tmp = strchr(str,'(');
+	tmp++;
+	ptr = strchr(tmp,',');
+	memcpy(p1,tmp,ptr-tmp);
+	
+	tmp = ptr+1;
+	ptr = strchr(tmp,',');
+	memcpy(p2,tmp,ptr-tmp);
+
+	tmp = ptr+1;
+	ptr = strchr(tmp,',');
+	memcpy(p3,tmp,ptr-tmp);
+
+	tmp = ptr+1;
+	ptr = strchr(tmp,',');
+	memcpy(p4,tmp,ptr-tmp);
+
+	tmp = ptr+1;
+	ptr = strchr(tmp,')');
+	memcpy(p5,tmp,ptr-tmp);
+
+	l = atoi(p1);
+	t = atoi(p2);
+	r = atoi(p3);
+	b = atoi(p4);
+	
+	w = l + (r-l)/2;
+	h = t + (b-t)/2;
+
+	mFocusAreas.width = mFrameRectCrop.right - (1000 - w) * (mFrameRectCrop.right - mFrameRectCrop.left) / 2000;
+	mFocusAreas.height= mFrameRectCrop.bottom - (1000 - h) * (mFrameRectCrop.bottom - mFrameRectCrop.top) / 2000;
+
+	// LOGV("V4L2_AF_WIN_XY: %d,%d", mFocusAreas.width, mFocusAreas.height);
+	setAutoFocusCtrl(V4L2_AF_WIN_XY, (void*)&mFocusAreas);
+
+	return 0;
+}
+
+int CameraHardware::setAutoFocusMode()
+{
+	F_LOG;
+	v4l2_autofocus_mode af_mode = V4L2_AF_FIXED;
+    if (mCameraConfig->supportFocusMode())
+	{
+	    // focus
+		const char *new_focus_mode_str = mParameters.get(CameraParameters::KEY_FOCUS_MODE);
+		if (!strcmp(new_focus_mode_str, CameraParameters::FOCUS_MODE_AUTO))
+		{
+			af_mode = V4L2_AF_AUTO;
+		}
+		else if (!strcmp(new_focus_mode_str, CameraParameters::FOCUS_MODE_INFINITY))
+		{
+			af_mode = V4L2_AF_INFINITY;
+		}
+		else if (!strcmp(new_focus_mode_str, CameraParameters::FOCUS_MODE_MACRO))
+		{
+			af_mode = V4L2_AF_MACRO;
+		}
+		else if (!strcmp(new_focus_mode_str, CameraParameters::FOCUS_MODE_FIXED))
+		{
+			af_mode = V4L2_AF_FIXED;
+		}
+		else if (!strcmp(new_focus_mode_str, CameraParameters::FOCUS_MODE_CONTINUOUS_PICTURE)
+					|| !strcmp(new_focus_mode_str, CameraParameters::FOCUS_MODE_CONTINUOUS_VIDEO))
+		{
+			LOGD("%s : continuous focus to do ...", __FUNCTION__);
+			af_mode = V4L2_AF_AUTO;
+		}
+		else
+		{
+			return -EINVAL;
+		}
+	}
+	else
+	{
+		af_mode = V4L2_AF_FIXED;
+	}
+	
+	mV4L2CameraDevice->setAutoFocusMode(af_mode);
+	
+	return OK;
+}
+
+int CameraHardware::setAutoFocusCtrl(int ctrl, void *data)
+{
+	if (mCameraConfig->supportFocusMode())
+	{
+		mV4L2CameraDevice->setAutoFocusCtrl(ctrl, data);
+	}
+	return OK;
+}
+
+bool CameraHardware::checkFocusMode(const char * mode)
+{
+	const char * str = mParameters.get(CameraParameters::KEY_SUPPORTED_FOCUS_MODES);
+	if (!strstr(str, mode))
+	{
+		return false;
+	}
+	return true;
+}
+
+bool CameraHardware::checkFocusArea(const char * area)
+{
+	if (area == NULL)
+	{
+		return false;
+	}
+
+	int i = 0;
+	int arr[5];		// [l, t, r, b, w]
+	char temp[128];
+	strcpy(temp, area);
+	char *pval = temp;
+	char *seps = "(,)";
+	int offset = 0;
+	pval = strtok(pval, seps);
+	while (pval != NULL)
+	{
+		if (i >= 5)
+		{
+			return false;
+		}
+		arr[i++] = atoi(pval);
+		pval = strtok(NULL, seps);
+	}
+
+	LOGV("%s : (%d, %d, %d, %d, %d)", __FUNCTION__, arr[0], arr[1],arr[2],arr[3],arr[4]);
+	
+	if ((arr[0] == 0)
+		&& (arr[1] == 0)
+		&& (arr[2] == 0)
+		&& (arr[3] == 0)
+		&& (arr[4] == 0))
+	{
+		return true;
+	}
+	
+	if (arr[4] < 1)
+	{
+		return false;
+	}
+	
+	for(i = 0; i < 4; i++)
+	{
+		if ((arr[i] < -1000) || (arr[i] > 1000))
+		{
+			return false;
+		}
+	}
+
+	if ((arr[0] >= arr[2])
+		|| (arr[1] >= arr[3]))
+	{
+		return false;
+	}
+	
+	return true;
+}
+
+/****************************************************************************
+ * take picture management
+ ***************************************************************************/
+
+status_t CameraHardware::doTakePicture()
+{
+	F_LOG;
+    Mutex::Autolock locker(&mObjectLock);
+
+	/* Get JPEG quality. */
+    int jpeg_quality = mParameters.getInt(CameraParameters::KEY_JPEG_QUALITY);
+    if (jpeg_quality <= 0) {
+        jpeg_quality = 90;
+    }
+
+	/* Get JPEG rotate. */
+    int jpeg_rotate = mParameters.getInt(CameraParameters::KEY_ROTATION);
+    if (jpeg_rotate <= 0) {
+        jpeg_rotate = 0;  /* Fall back to default. */
+    }
+
+	/* Get JPEG size. */
+	int pic_width, pic_height;
+    mParameters.getPictureSize(&pic_width, &pic_height);
+
+	mCallbackNotifier.setJpegQuality(jpeg_quality);
+	mCallbackNotifier.setJpegRotate(jpeg_rotate);
+    mCallbackNotifier.setPictureSize(pic_width, pic_height);
+
+	// if in recording mode
+	const char * valstr = mParameters.get(CameraParameters::KEY_RECORDING_HINT);
+	bool video_hint = (strcmp(valstr, CameraParameters::TRUE) == 0);
+	if (video_hint)
+	{
+		//mCallbackNotifier.setPictureSize(mCaptureWidth*4, 4*mCaptureHeight);
+		mV4L2CameraDevice->setTakePictureState(TAKE_PICTURE_RECORD);
+		return OK;
+	}
+
+	// picture mode
+	const char * cur_picture_mode = mParameters.get(KEY_PICTURE_MODE);
+	if (cur_picture_mode != NULL)
+	{
+		// continuous picture
+		if (!strcmp(cur_picture_mode, PICTURE_MODE_CONTINUOUS)
+			|| !strcmp(cur_picture_mode, PICTURE_MODE_CONTINUOUS_FAST))
+		{
+			// test continuous picture
+			int number = 0;
+			if (!strcmp(cur_picture_mode, PICTURE_MODE_CONTINUOUS))
+			{
+				number = 100;
+				mV4L2CameraDevice->setTakePictureState(TAKE_PICTURE_CONTINUOUS);
+			}
+			else if (!strcmp(cur_picture_mode, PICTURE_MODE_CONTINUOUS_FAST))
+			{
+				number = 10;
+				mV4L2CameraDevice->setTakePictureState(TAKE_PICTURE_CONTINUOUS_FAST);
+			}
+			mCallbackNotifier.setPictureSize(pic_width, pic_height);
+			mCallbackNotifier.setContinuousPictureCnt(number);
+			mCallbackNotifier.startContinuousPicture();
+			mV4L2CameraDevice->setContinuousPictureCnt(number);
+			mV4L2CameraDevice->startContinuousPicture();
+
+			return OK;
+		}
+	}
+
+	// normal picture mode
+
+	// full-size capture
+	bool fast_picture_mode = mHalCameraInfo.fast_picture_mode;
+	if (fast_picture_mode)
+	{
+		mV4L2CameraDevice->setTakePictureState(TAKE_PICTURE_FAST);
+		return OK;
+	}
+
+	// normal taking picture mode
+	int frame_width = pic_width;
+	int frame_height = pic_height;
+	mV4L2CameraDevice->tryFmtSize(&frame_width, &frame_height);
+
+	if (mCaptureWidth == frame_width
+		&& mCaptureHeight == frame_height)
+	{
+		LOGV("current capture size[%dx%d] is the same as picture size", frame_width, frame_height);
+		mV4L2CameraDevice->setTakePictureState(TAKE_PICTURE_FAST);
+		return OK;
+	}
+	
+	// preview format and video format are the same
+	const char* pix_fmt = mParameters.getPictureFormat();
+	uint32_t org_fmt = V4L2_PIX_FMT_NV12;
+
+	/*
+     * Make sure preview is not running, and device is stopped before taking
+     * picture.
+     */
+    const bool preview_on = mPreviewWindow.isPreviewEnabled();
+    if (preview_on) {
+        doStopPreview();
+    }
+
+	/* Camera device should have been stopped when the shutter message has been
+	 * enabled. */
+	if (mV4L2CameraDevice->isStarted()) 
+	{
+		LOGW("%s: Camera device is started", __FUNCTION__);
+		mV4L2CameraDevice->stopDeliveringFrames();
+		mV4L2CameraDevice->stopDevice();
+	}
+
+	/*
+	 * Take the picture now.
+	 */
+	
+	mV4L2CameraDevice->setTakePictureState(TAKE_PICTURE_NORMAL);
+
+	mCaptureWidth = frame_width;
+	mCaptureHeight = frame_height;
+
+	LOGD("Starting camera: %dx%d -> %.4s(%s)",
+		 mCaptureWidth, mCaptureHeight, reinterpret_cast<const char*>(&org_fmt), pix_fmt);
+	status_t res = mV4L2CameraDevice->startDevice(mCaptureWidth, mCaptureHeight, org_fmt, video_hint);
+	if (res != NO_ERROR) 
+	{
+		if (preview_on) {
+            doStartPreview();
+        }
+		return res;
+	}
+	
+	res = mV4L2CameraDevice->startDeliveringFrames();
+	if (res != NO_ERROR) 
+	{
+		mV4L2CameraDevice->setTakePictureState(TAKE_PICTURE_NULL);
+        if (preview_on) {
+            doStartPreview();
+        }
+	}
+
+	return OK;
+}
+
+status_t CameraHardware::doTakePictureEnd()
+{
+	F_LOG;
+	
+    Mutex::Autolock locker(&mObjectLock);
+
+	if (mV4L2CameraDevice->isConnected() 			// camera is connected or started
+		&& !mPreviewWindow.isPreviewEnabled()		// preview is not enable
+		&& !mHalCameraInfo.fast_picture_mode)
+	{
+		// 
+		LOGV("doTakePictureEnd to doStartPreview");
+		doStartPreview();
+	}
+
+	return OK;
+}
+
+status_t CameraHardware::takePicture()
+{
+	F_LOG;
+	mQueueElement[CMD_QUEUE_TAKE_PICTURE].cmd = CMD_QUEUE_TAKE_PICTURE;
+	OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_TAKE_PICTURE]);
+	pthread_cond_signal(&mCommandCond);
+	
+    return OK;
+}
+
+status_t CameraHardware::cancelPicture()
+{
+    F_LOG;
+	mV4L2CameraDevice->setTakePictureState(TAKE_PICTURE_NULL);
+
+    return NO_ERROR;
+}
+
+// 
+void CameraHardware::notifyPictureMsg(const void* frame)
+{
+	mQueueElement[CMD_QUEUE_PICTURE_MSG].cmd = CMD_QUEUE_PICTURE_MSG;
+	mQueueElement[CMD_QUEUE_PICTURE_MSG].data = (int)frame;
+	OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_PICTURE_MSG]);
+	pthread_cond_signal(&mCommandCond);
+}
+
+/****************************************************************************
+ * set and get parameters
+ ***************************************************************************/
+
+void CameraHardware::setVideoCaptureSize(int video_w, int video_h)
+{
+	// video size is video_w x video_h, capture size may be different
+	// now the same
+	mVideoCaptureWidth = video_w;
+	mVideoCaptureHeight= video_h;
+
+	LOGD("setVideoCaptureSize next version to do ......");
+
+	int ret = mV4L2CameraDevice->tryFmtSize(&mVideoCaptureWidth, &mVideoCaptureHeight);
+	if(ret < 0)
+	{
+		LOGE("setVideoCaptureSize tryFmtSize failed");
+		return;
+	}
+	LOGV("setVideoCaptureSize video source: %dx%d", mVideoCaptureWidth, mVideoCaptureHeight);
+	
+	mParameters.set(KEY_CAPTURE_SIZE_WIDTH, mVideoCaptureWidth);
+	mParameters.set(KEY_CAPTURE_SIZE_HEIGHT, mVideoCaptureHeight);
+}
+
+void CameraHardware::getCurrentOriention(int * oriention)
+{
+	*oriention = mOriention;
+	
+	if(mHalCameraInfo.facing == CAMERA_FACING_FRONT)   //for direction of front camera facedetection by fuqiang
+	{
+		if(*oriention == 90)
+		{
+			*oriention = 270;
+		}
+		else if(*oriention == 270)
+		{
+			*oriention = 90;
+		}
+	}
+}
+
+status_t CameraHardware::setParameters(const char* p)
+{
+	F_LOG;
+	int ret = UNKNOWN_ERROR;
+	
+    PrintParamDiff(mParameters, p);
+
+    CameraParameters params;
+	String8 str8_param(p);
+    params.unflatten(str8_param);
+
+	V4L2CameraDevice* pV4L2Device = mV4L2CameraDevice;
+	if (pV4L2Device == NULL)
+	{
+		LOGE("%s : getCameraDevice failed", __FUNCTION__);
+		return UNKNOWN_ERROR;
+	}
+
+	// stop continuous picture
+	const char * cur_picture_mode = mParameters.get(KEY_PICTURE_MODE);
+	const char * stop_continuous_picture = params.get(KEY_CANCEL_CONTINUOUS_PICTURE);
+	LOGV("%s : stop_continuous_picture : %s", __FUNCTION__, stop_continuous_picture);
+	if (cur_picture_mode != NULL
+		&& stop_continuous_picture != NULL
+		&& !strcmp(cur_picture_mode, PICTURE_MODE_CONTINUOUS)
+		&& !strcmp(stop_continuous_picture, "true")) 
+	{
+		mQueueElement[CMD_QUEUE_STOP_CONTINUOUSSNAP].cmd = CMD_QUEUE_STOP_CONTINUOUSSNAP;
+		OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_STOP_CONTINUOUSSNAP]);
+	}
+
+	// picture mode
+	const char * new_picture_mode = params.get(KEY_PICTURE_MODE);
+	LOGV("%s : new_picture_mode : %s", __FUNCTION__, new_picture_mode);
+    if (new_picture_mode != NULL) 
+	{
+		if (!strcmp(new_picture_mode, PICTURE_MODE_NORMAL)
+			|| !strcmp(new_picture_mode, PICTURE_MODE_CONTINUOUS)
+			|| !strcmp(new_picture_mode, PICTURE_MODE_CONTINUOUS_FAST))
+		{
+        	mParameters.set(KEY_PICTURE_MODE, new_picture_mode);
+		}
+		else
+		{
+        	LOGW("%s : unknown picture mode: %s", __FUNCTION__, new_picture_mode);
+		}
+	
+		// continuous picture path
+		if (!strcmp(new_picture_mode, PICTURE_MODE_CONTINUOUS)
+			|| !strcmp(new_picture_mode, PICTURE_MODE_CONTINUOUS_FAST))
+		{
+			const char * new_path = params.get(KEY_CONTINUOUS_PICTURE_PATH);
+			LOGV("%s : new_path : %s", __FUNCTION__, new_path);
+			if (new_path != NULL)
+			{
+				mParameters.set(KEY_CONTINUOUS_PICTURE_PATH, new_path);
+				mCallbackNotifier.setSaveFolderPath(new_path);
+			}
+			else
+			{
+				LOGW("%s : invalid path: %s in %s picture mode", __FUNCTION__, new_path, new_picture_mode);
+				mParameters.set(KEY_PICTURE_MODE, PICTURE_MODE_NORMAL);
+			}
+		}
+		else if(!strcmp(new_picture_mode, PICTURE_MODE_NORMAL))
+		{
+			const char * new_path = params.get(KEY_SNAP_PATH);
+			LOGV("%s : snap new_path : %s", __FUNCTION__, new_path);
+			if (new_path != NULL)
+			{
+				mParameters.set(KEY_SNAP_PATH, new_path);
+				mCallbackNotifier.setSnapPath(new_path);
+			}
+		}
+    }
+
+	// preview format
+	const char * new_preview_format = params.getPreviewFormat();
+	LOGV("%s : new_preview_format : %s", __FUNCTION__, new_preview_format);
+	if (new_preview_format != NULL
+		&& (strcmp(new_preview_format, CameraParameters::PIXEL_FORMAT_YUV420SP) == 0
+		|| strcmp(new_preview_format, CameraParameters::PIXEL_FORMAT_YUV420P) == 0)) 
+	{
+		mParameters.setPreviewFormat(new_preview_format);
+	}
+	else
+    {
+        LOGE("%s : Only yuv420sp or yuv420p preview is supported", __FUNCTION__);
+        return -EINVAL;
+    }
+
+	// picture format
+	const char * new_picture_format = params.getPictureFormat();
+	LOGV("%s : new_picture_format : %s", __FUNCTION__, new_picture_format);
+	if (new_picture_format == NULL
+		|| (strcmp(new_picture_format, CameraParameters::PIXEL_FORMAT_JPEG) != 0)) 
+    {
+        LOGE("%s : Only jpeg still pictures are supported", __FUNCTION__);
+        return -EINVAL;
+    }
+
+	// picture size
+	int new_picture_width  = 0;
+    int new_picture_height = 0;
+    params.getPictureSize(&new_picture_width, &new_picture_height);
+    LOGV("%s : new_picture_width x new_picture_height = %dx%d", __FUNCTION__, new_picture_width, new_picture_height);
+    if (0 < new_picture_width && 0 < new_picture_height) 
+	{
+		mParameters.setPictureSize(new_picture_width, new_picture_height);
+    }
+	else
+	{
+		LOGE("%s : error picture size", __FUNCTION__);
+		return -EINVAL;
+	}
+
+	// preview size
+    int new_preview_width  = 0;
+    int new_preview_height = 0;
+    params.getPreviewSize(&new_preview_width, &new_preview_height);
+    LOGV("%s : new_preview_width x new_preview_height = %dx%d",
+         __FUNCTION__, new_preview_width, new_preview_height);
+	if (0 < new_preview_width && 0 < new_preview_height)
+	{
+		mParameters.setPreviewSize(new_preview_width, new_preview_height);
+	
+		mCallbackNotifier.setCBSize(new_preview_width, new_preview_height);
+		
+		// try size
+		ret = pV4L2Device->tryFmtSize(&new_preview_width, &new_preview_height);
+		if(ret < 0)
+		{
+			return ret;
+		}
+		
+		mParameters.set(KEY_PREVIEW_CAPTURE_SIZE_WIDTH, new_preview_width);
+		mParameters.set(KEY_PREVIEW_CAPTURE_SIZE_HEIGHT, new_preview_height);
+	}
+	else
+	{
+		LOGE("%s : error preview size", __FUNCTION__);
+		return -EINVAL;
+	}
+
+	// video size
+	int new_video_width		= 0;
+	int new_video_height	= 0;
+	params.getVideoSize(&new_video_width, &new_video_height);
+    LOGV("%s : new_video_width x new_video_height = %dx%d",
+         __FUNCTION__, new_video_width, new_video_height);
+	if (0 < new_video_width && 0 < new_video_height)
+	{
+		int video_width		= 0;
+		int video_height	= 0;
+		mParameters.getVideoSize(&video_width, &video_height);
+		if (mFirstSetParameters
+			|| video_width != new_video_width
+			|| video_height != new_video_height)
+		{
+			mParameters.setVideoSize(new_video_width, new_video_height);
+			if (new_video_width != mVideoCaptureWidth
+				|| new_video_height != mVideoCaptureHeight)
+			{
+				setVideoCaptureSize(new_video_width, new_video_height);
+			}
+		}
+	}
+	else
+	{
+		LOGE("%s : error video size", __FUNCTION__);
+		return -EINVAL;
+	}
+
+	// video hint
+    const char * valstr = params.get(CameraParameters::KEY_RECORDING_HINT);
+    if (valstr) 
+	{
+		LOGV("%s : KEY_RECORDING_HINT: %s", __FUNCTION__, valstr);
+        mParameters.set(CameraParameters::KEY_RECORDING_HINT, valstr);
+    }
+
+	// frame rate
+	int new_min_frame_rate, new_max_frame_rate;
+	params.getPreviewFpsRange(&new_min_frame_rate, &new_max_frame_rate);
+	int new_preview_frame_rate = params.getPreviewFrameRate();
+	if (0 < new_preview_frame_rate && 0 < new_min_frame_rate 
+		&& new_min_frame_rate <= new_max_frame_rate)
+	{
+		int preview_frame_rate = mParameters.getPreviewFrameRate();
+		if (mFirstSetParameters
+			|| preview_frame_rate != new_preview_frame_rate)
+		{
+			mParameters.setPreviewFrameRate(new_preview_frame_rate);
+			pV4L2Device->setFrameRate(new_preview_frame_rate);
+		}
+	}
+	else
+	{
+		if (pV4L2Device->getCaptureFormat() == V4L2_PIX_FMT_YUYV)
+		{
+			LOGV("may be usb camera, don't care frame rate");
+		}
+		else
+		{
+			LOGE("%s : error preview frame rate", __FUNCTION__);
+			return -EINVAL;
+		}
+	}
+
+	// JPEG image quality
+    int new_jpeg_quality = params.getInt(CameraParameters::KEY_JPEG_QUALITY);
+    LOGV("%s : new_jpeg_quality %d", __FUNCTION__, new_jpeg_quality);
+    if (new_jpeg_quality >=1 && new_jpeg_quality <= 100) 
+	{
+		mParameters.set(CameraParameters::KEY_JPEG_QUALITY, new_jpeg_quality);
+    }
+	else
+	{
+		if (pV4L2Device->getCaptureFormat() == V4L2_PIX_FMT_YUYV)
+		{
+			LOGV("may be usb camera, don't care picture quality");
+			mParameters.set(CameraParameters::KEY_JPEG_QUALITY, 90);
+		}
+		else
+		{
+			LOGE("%s : error picture quality", __FUNCTION__);
+			return -EINVAL;
+		}
+	}
+
+	// rotation	
+	int new_rotation = params.getInt(CameraParameters::KEY_ROTATION);
+    LOGV("%s : new_rotation %d", __FUNCTION__, new_rotation);
+    if (0 <= new_rotation) 
+	{
+		mOriention = new_rotation;
+        mParameters.set(CameraParameters::KEY_ROTATION, new_rotation);
+    }
+	else
+	{
+		LOGE("%s : error rotate", __FUNCTION__);
+		return -EINVAL;
+	}
+
+	// image effect
+	if (mCameraConfig->supportColorEffect())
+	{
+		const char *now_image_effect_str = mParameters.get(CameraParameters::KEY_EFFECT);
+		const char *new_image_effect_str = params.get(CameraParameters::KEY_EFFECT);
+		LOGV("%s : new_image_effect_str %s", __FUNCTION__, new_image_effect_str);
+	    if ((new_image_effect_str != NULL)
+			&& (mFirstSetParameters || strcmp(now_image_effect_str, new_image_effect_str)))
+		{
+	        int  new_image_effect = -1;
+
+	        if (!strcmp(new_image_effect_str, CameraParameters::EFFECT_NONE))
+	            new_image_effect = V4L2_COLORFX_NONE;
+	        else if (!strcmp(new_image_effect_str, CameraParameters::EFFECT_MONO))
+	            new_image_effect = V4L2_COLORFX_BW;
+	        else if (!strcmp(new_image_effect_str, CameraParameters::EFFECT_SEPIA))
+	            new_image_effect = V4L2_COLORFX_SEPIA;
+	        else if (!strcmp(new_image_effect_str, CameraParameters::EFFECT_AQUA))
+	            new_image_effect = V4L2_COLORFX_GRASS_GREEN;
+	        else if (!strcmp(new_image_effect_str, CameraParameters::EFFECT_NEGATIVE))
+	            new_image_effect = V4L2_COLORFX_NEGATIVE;
+	        else {
+	            //posterize, whiteboard, blackboard, solarize
+	            LOGE("ERR(%s):Invalid effect(%s)", __FUNCTION__, new_image_effect_str);
+	            ret = UNKNOWN_ERROR;
+	        }
+
+	        if (new_image_effect >= 0) {
+	            mParameters.set(CameraParameters::KEY_EFFECT, new_image_effect_str);
+				mQueueElement[CMD_QUEUE_SET_COLOR_EFFECT].cmd = CMD_QUEUE_SET_COLOR_EFFECT;
+				mQueueElement[CMD_QUEUE_SET_COLOR_EFFECT].data = new_image_effect;
+				OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_SET_COLOR_EFFECT]);
+	        }
+	    }
+	}
+
+	// white balance
+	if (mCameraConfig->supportWhiteBalance())
+	{
+		const char *now_white_str = mParameters.get(CameraParameters::KEY_WHITE_BALANCE);
+		const char *new_white_str = params.get(CameraParameters::KEY_WHITE_BALANCE);
+	    LOGV("%s : new_white_str %s", __FUNCTION__, new_white_str);
+	    if ((new_white_str != NULL)
+			&& (mFirstSetParameters || strcmp(now_white_str, new_white_str)))
+		{
+	        int new_white = -1;
+	        int no_auto_balance = 1;
+
+	        if (!strcmp(new_white_str, CameraParameters::WHITE_BALANCE_AUTO))
+	        {
+	            new_white = V4L2_WB_AUTO;
+	            no_auto_balance = 0;
+	        }
+	        else if (!strcmp(new_white_str,
+	                         CameraParameters::WHITE_BALANCE_DAYLIGHT))
+	            new_white = V4L2_WB_DAYLIGHT;
+	        else if (!strcmp(new_white_str,
+	                         CameraParameters::WHITE_BALANCE_CLOUDY_DAYLIGHT))
+	            new_white = V4L2_WB_CLOUD;
+	        else if (!strcmp(new_white_str,
+	                         CameraParameters::WHITE_BALANCE_FLUORESCENT))
+	            new_white = V4L2_WB_FLUORESCENT;
+	        else if (!strcmp(new_white_str,
+	                         CameraParameters::WHITE_BALANCE_INCANDESCENT))
+	            new_white = V4L2_WB_INCANDESCENCE;
+	        else if (!strcmp(new_white_str,
+	                         CameraParameters::WHITE_BALANCE_WARM_FLUORESCENT))
+	            new_white = V4L2_WB_TUNGSTEN;
+	        else{
+	            LOGE("ERR(%s):Invalid white balance(%s)", __FUNCTION__, new_white_str); //twilight, shade
+	            ret = UNKNOWN_ERROR;
+	        }
+
+	        mCallbackNotifier.setWhiteBalance(no_auto_balance);
+
+	        if (0 <= new_white)
+			{
+				mParameters.set(CameraParameters::KEY_WHITE_BALANCE, new_white_str);
+				mQueueElement[CMD_QUEUE_SET_WHITE_BALANCE].cmd = CMD_QUEUE_SET_WHITE_BALANCE;
+				mQueueElement[CMD_QUEUE_SET_WHITE_BALANCE].data = new_white;
+				OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_SET_WHITE_BALANCE]);
+	        }
+	    }
+	}
+	
+	// exposure compensation
+	if (mCameraConfig->supportExposureCompensation())
+	{
+		int now_exposure_compensation = mParameters.getInt(CameraParameters::KEY_EXPOSURE_COMPENSATION);
+		int new_exposure_compensation = params.getInt(CameraParameters::KEY_EXPOSURE_COMPENSATION);
+		int max_exposure_compensation = params.getInt(CameraParameters::KEY_MAX_EXPOSURE_COMPENSATION);
+		int min_exposure_compensation = params.getInt(CameraParameters::KEY_MIN_EXPOSURE_COMPENSATION);
+		LOGV("%s : new_exposure_compensation %d", __FUNCTION__, new_exposure_compensation);
+		if ((min_exposure_compensation <= new_exposure_compensation)
+			&& (max_exposure_compensation >= new_exposure_compensation))
+		{
+			if (mFirstSetParameters || (now_exposure_compensation != new_exposure_compensation))
+			{
+				mParameters.set(CameraParameters::KEY_EXPOSURE_COMPENSATION, new_exposure_compensation);
+				mQueueElement[CMD_QUEUE_SET_EXPOSURE_COMPENSATION].cmd = CMD_QUEUE_SET_EXPOSURE_COMPENSATION;
+				mQueueElement[CMD_QUEUE_SET_EXPOSURE_COMPENSATION].data = new_exposure_compensation;
+				OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_SET_EXPOSURE_COMPENSATION]);
+			}
+		}
+		else
+		{
+			LOGE("ERR(%s):invalid exposure compensation: %d", __FUNCTION__, new_exposure_compensation);
+			return -EINVAL;
+		}
+	}
+	
+	// flash mode	
+	if (mCameraConfig->supportFlashMode())
+	{
+		const char *new_flash_mode_str = params.get(CameraParameters::KEY_FLASH_MODE);
+		mParameters.set(CameraParameters::KEY_FLASH_MODE, new_flash_mode_str);
+	}
+
+	// zoom
+	int max_zoom = mParameters.getInt(CameraParameters::KEY_MAX_ZOOM);
+	int new_zoom = params.getInt(CameraParameters::KEY_ZOOM);
+	LOGV("%s : new_zoom: %d", __FUNCTION__, new_zoom);
+	if (0 <= new_zoom && new_zoom <= max_zoom)
+	{
+		mParameters.set(CameraParameters::KEY_ZOOM, new_zoom);
+		pV4L2Device->setCrop(new_zoom + BASE_ZOOM, max_zoom);
+		mZoomRatio = (new_zoom + BASE_ZOOM) * 2 * 100 / max_zoom + 100;
+	}
+	else
+	{
+		LOGE("ERR(%s): invalid zoom value: %d", __FUNCTION__, new_zoom);
+		return -EINVAL;
+	}
+
+	// focus
+	if (mCameraConfig->supportFocusMode())
+	{
+		const char *now_focus_mode_str = mParameters.get(CameraParameters::KEY_FOCUS_MODE);
+		const char *now_focus_areas_str = mParameters.get(CameraParameters::KEY_FOCUS_AREAS);
+		const char *new_focus_mode_str = params.get(CameraParameters::KEY_FOCUS_MODE);
+        const char *new_focus_areas_str = params.get(CameraParameters::KEY_FOCUS_AREAS);
+
+		if (!checkFocusArea(new_focus_areas_str))
+		{
+			LOGE("ERR(%s): invalid focus areas", __FUNCTION__);
+			return -EINVAL;
+		}
+		
+		if (!checkFocusMode(new_focus_mode_str))
+		{
+			LOGE("ERR(%s): invalid focus mode", __FUNCTION__);
+			return -EINVAL;
+		}
+		
+		if (mFirstSetParameters || strcmp(now_focus_mode_str, new_focus_mode_str))
+		{
+			mParameters.set(CameraParameters::KEY_FOCUS_MODE, new_focus_mode_str);
+			mQueueElement[CMD_QUEUE_SET_FOCUS_MODE].cmd = CMD_QUEUE_SET_FOCUS_MODE;
+			OSAL_QueueSetElem(&mQueueCommand, &mQueueElement[CMD_QUEUE_SET_FOCUS_MODE]);
+		}
+
+		// to do, check running??
+		if (/*pV4L2Device->getThreadRunning()
+			&&*/ strcmp(now_focus_areas_str, new_focus_areas_str))
+		{
+			mParameters.set(CameraParameters::KEY_FOCUS_AREAS, new_focus_areas_str);
+
+#if 0
+			strcpy(mFocusAreasStr, new_focus_areas_str);
+			mQueueElement[CMD_QUEUE_SET_FOCUS_AREA].cmd = CMD_QUEUE_SET_FOCUS_AREA;
+			mQueueElement[CMD_QUEUE_SET_FOCUS_AREA].data = (int)&mFocusAreasStr;
+			OSAL_QueueSetElem(&mQueueCommand, &mQueueElement[CMD_QUEUE_SET_FOCUS_AREA]);
+#else
+			parse_focus_areas(new_focus_areas_str);
+#endif
+		}
+	}
+	else
+	{
+		const char *new_focus_mode_str = params.get(CameraParameters::KEY_FOCUS_MODE);
+		if (strcmp(new_focus_mode_str, CameraParameters::FOCUS_MODE_FIXED))
+		{
+			LOGE("ERR(%s): invalid focus mode: %s", __FUNCTION__, new_focus_mode_str);
+			return -EINVAL;
+		}
+		mParameters.set(CameraParameters::KEY_FOCUS_MODE, CameraParameters::FOCUS_MODE_FIXED);
+	}
+
+	// gps latitude
+    const char *new_gps_latitude_str = params.get(CameraParameters::KEY_GPS_LATITUDE);
+	if (new_gps_latitude_str) {
+		mCallbackNotifier.setGPSLatitude(atof(new_gps_latitude_str));
+        mParameters.set(CameraParameters::KEY_GPS_LATITUDE, new_gps_latitude_str);
+    } else {
+    	mCallbackNotifier.setGPSLatitude(0.0);
+        mParameters.remove(CameraParameters::KEY_GPS_LATITUDE);
+    }
+
+    // gps longitude
+    const char *new_gps_longitude_str = params.get(CameraParameters::KEY_GPS_LONGITUDE);
+    if (new_gps_longitude_str) {
+		mCallbackNotifier.setGPSLongitude(atof(new_gps_longitude_str));
+        mParameters.set(CameraParameters::KEY_GPS_LONGITUDE, new_gps_longitude_str);
+    } else {
+    	mCallbackNotifier.setGPSLongitude(0.0);
+        mParameters.remove(CameraParameters::KEY_GPS_LONGITUDE);
+    }
+  
+    // gps altitude
+    const char *new_gps_altitude_str = params.get(CameraParameters::KEY_GPS_ALTITUDE);
+	if (new_gps_altitude_str) {
+		mCallbackNotifier.setGPSAltitude(atol(new_gps_altitude_str));
+        mParameters.set(CameraParameters::KEY_GPS_ALTITUDE, new_gps_altitude_str);
+    } else {
+		mCallbackNotifier.setGPSAltitude(0);
+        mParameters.remove(CameraParameters::KEY_GPS_ALTITUDE);
+    }
+
+    // gps timestamp
+    const char *new_gps_timestamp_str = params.get(CameraParameters::KEY_GPS_TIMESTAMP);
+	if (new_gps_timestamp_str) {
+		mCallbackNotifier.setGPSTimestamp(atol(new_gps_timestamp_str));
+        mParameters.set(CameraParameters::KEY_GPS_TIMESTAMP, new_gps_timestamp_str);
+    } else {
+		mCallbackNotifier.setGPSTimestamp(0);
+        mParameters.remove(CameraParameters::KEY_GPS_TIMESTAMP);
+    }
+
+    // gps processing method
+    const char *new_gps_processing_method_str = params.get(CameraParameters::KEY_GPS_PROCESSING_METHOD);
+	if (new_gps_processing_method_str) {
+		mCallbackNotifier.setGPSMethod(new_gps_processing_method_str);
+        mParameters.set(CameraParameters::KEY_GPS_PROCESSING_METHOD, new_gps_processing_method_str);
+    } else {
+		mCallbackNotifier.setGPSMethod("");
+        mParameters.remove(CameraParameters::KEY_GPS_PROCESSING_METHOD);
+    }
+	
+	// JPEG thumbnail size
+	int new_jpeg_thumbnail_width = params.getInt(CameraParameters::KEY_JPEG_THUMBNAIL_WIDTH);
+	int new_jpeg_thumbnail_height= params.getInt(CameraParameters::KEY_JPEG_THUMBNAIL_HEIGHT);
+	LOGV("%s : new_jpeg_thumbnail_width: %d, new_jpeg_thumbnail_height: %d",
+		__FUNCTION__, new_jpeg_thumbnail_width, new_jpeg_thumbnail_height);
+	if (0 <= new_jpeg_thumbnail_width && 0 <= new_jpeg_thumbnail_height) {
+		mCallbackNotifier.setJpegThumbnailSize(new_jpeg_thumbnail_width, new_jpeg_thumbnail_height);
+		mParameters.set(CameraParameters::KEY_JPEG_THUMBNAIL_WIDTH, new_jpeg_thumbnail_width);
+		mParameters.set(CameraParameters::KEY_JPEG_THUMBNAIL_HEIGHT, new_jpeg_thumbnail_height);
+	}
+
+	mFirstSetParameters = false;
+	pthread_cond_signal(&mCommandCond);
+	
+    return NO_ERROR;
+}
+
+/* A dumb variable indicating "no params" / error on the exit from
+ * CameraHardware::getParameters(). */
+static char lNoParam = '\0';
+char* CameraHardware::getParameters()
+{
+	F_LOG;
+    String8 params(mParameters.flatten());
+    char* ret_str =
+        reinterpret_cast<char*>(malloc(sizeof(char) * (params.length()+1)));
+    memset(ret_str, 0, params.length()+1);
+    if (ret_str != NULL) {
+        strncpy(ret_str, params.string(), params.length()+1);
+        return ret_str;
+    } else {
+        LOGE("%s: Unable to allocate string for %s", __FUNCTION__, params.string());
+        /* Apparently, we can't return NULL fron this routine. */
+        return &lNoParam;
+    }
+}
+
+void CameraHardware::putParameters(char* params)
+{
+	F_LOG;
+    /* This method simply frees parameters allocated in getParameters(). */
+    if (params != NULL && params != &lNoParam) {
+        free(params);
+    }
+}
+
+status_t CameraHardware::setFd(int fd)
+{
+	F_LOG;
+	mCallbackNotifier.setFd(fd);
+	return NO_ERROR;
+}
+
+void CameraHardware::setNewCrop(Rect * rect)
+{
+	F_LOG;
+	memcpy(&mFrameRectCrop, rect, sizeof(Rect));
+}
+
+status_t CameraHardware::sendCommand(int32_t cmd, int32_t arg1, int32_t arg2)
+{
+    LOGV("%s: cmd = %x, arg1 = %d, arg2 = %d", __FUNCTION__, cmd, arg1, arg2);
+
+    /* TODO: Future enhancements. */
+
+	switch (cmd)
+	{
+	case CAMERA_CMD_SET_CEDARX_RECORDER:
+		mUseHwEncoder = true;
+		mV4L2CameraDevice->setHwEncoder(true);
+		return OK;
+	case CAMERA_CMD_START_FACE_DETECTION:
+	{
+		const char *face = mParameters.get(CameraParameters::KEY_MAX_NUM_DETECTED_FACES_HW);
+		if (face == NULL || (atoi(face) <= 0))
+		{
+			return -EINVAL;
+		}
+		mQueueElement[CMD_QUEUE_START_FACE_DETECTE].cmd = CMD_QUEUE_START_FACE_DETECTE;
+		OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_START_FACE_DETECTE]);
+		pthread_cond_signal(&mCommandCond);
+		return OK;
+	}
+	case CAMERA_CMD_STOP_FACE_DETECTION:
+		mQueueElement[CMD_QUEUE_STOP_FACE_DETECTE].cmd = CMD_QUEUE_STOP_FACE_DETECTE;
+		OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_STOP_FACE_DETECTE]);
+		pthread_cond_signal(&mCommandCond);
+		return OK;
+	case CAMERA_CMD_PING:
+		return OK;
+	case CAMERA_CMD_ENABLE_FOCUS_MOVE_MSG:
+	{
+		bool enable = static_cast<bool>(arg1);
+        if (enable) {
+			enableMsgType(CAMERA_MSG_FOCUS_MOVE);
+        } else {
+			disableMsgType(CAMERA_MSG_FOCUS_MOVE);
+        }
+		return OK;
+	}
+	case CAMERA_CMD_SET_DISPLAY_ORIENTATION:
+		LOGD("CAMERA_CMD_SET_DISPLAY_ORIENTATION, to do ...");
+		return OK;
+	}
+
+    return -EINVAL;
+}
+
+void CameraHardware::releaseCamera()
+{
+    LOGV("%s", __FUNCTION__);
+
+    cleanupCamera();
+}
+
+status_t CameraHardware::dumpCamera(int fd)
+{
+    LOGV("%s", __FUNCTION__);
+
+    /* TODO: Future enhancements. */
+    return -EINVAL;
+}
+
+/****************************************************************************
+ * Facedetection management
+ ***************************************************************************/
+
+int CameraHardware::getCurrentFaceFrame(void * frame)
+{
+	return mV4L2CameraDevice->getCurrentFaceFrame(frame);
+}
+
+int CameraHardware::faceDetection(camera_frame_metadata_t *face)
+{
+	if (mZoomRatio != 0)
+	{
+		int number_of_faces = face->number_of_faces;
+		for(int i =0; i < number_of_faces; i++)
+		{
+			face->faces[i].rect[0] = (face->faces[i].rect[0] * mZoomRatio) / 100;
+			face->faces[i].rect[1] = (face->faces[i].rect[1] * mZoomRatio) / 100;
+			face->faces[i].rect[2] = (face->faces[i].rect[2] * mZoomRatio) / 100;
+			face->faces[i].rect[3] = (face->faces[i].rect[3] * mZoomRatio) / 100;
+		}
+	}
+	return mCallbackNotifier.faceDetectionMsg(face);
+}
+
+/****************************************************************************
+ * Preview management.
+ ***************************************************************************/
+
+status_t CameraHardware::doStartPreview()
+{
+	F_LOG;
+	
+	V4L2CameraDevice* const camera_dev = mV4L2CameraDevice;
+
+	if (camera_dev->isStarted()
+		&& mPreviewWindow.isPreviewEnabled())
+	{
+		LOGD("CameraHardware::doStartPreview has been already started");
+		return NO_ERROR;
+	}
+	
+	if (camera_dev->isStarted()) 
+	{
+        camera_dev->stopDeliveringFrames();
+        camera_dev->stopDevice();
+    }
+
+	status_t res = mPreviewWindow.startPreview();
+    if (res != NO_ERROR) 
+	{
+        return res;
+    }
+
+	// Make sure camera device is connected.
+	if (!camera_dev->isConnected())
+	{
+		res = camera_dev->connectDevice(&mHalCameraInfo);
+		if (res != NO_ERROR) 
+		{
+			mPreviewWindow.stopPreview();
+			return res;
+		}
+
+		setAutoFocusCtrl(V4L2_AF_INIT, NULL);
+	}
+
+	const char * valstr = mParameters.get(CameraParameters::KEY_RECORDING_HINT);
+	bool video_hint = (strcmp(valstr, CameraParameters::TRUE) == 0);
+
+	// preview size
+	int preview_width = 0, preview_height = 0;
+	const char * preview_capture_width_str = mParameters.get(KEY_PREVIEW_CAPTURE_SIZE_WIDTH);
+	const char * preview_capture_height_str = mParameters.get(KEY_PREVIEW_CAPTURE_SIZE_HEIGHT);
+	if (preview_capture_width_str != NULL
+		&& preview_capture_height_str != NULL)
+	{
+		preview_width  = atoi(preview_capture_width_str);
+		preview_height = atoi(preview_capture_height_str);
+	}
+
+	// video size
+	int video_width = 0, video_height = 0;
+	mParameters.getVideoSize(&video_width, &video_height);
+
+	// capture size
+	if (video_hint)
+	{
+		mCaptureWidth = mVideoCaptureWidth;
+		mCaptureHeight= mVideoCaptureHeight;
+	}
+	else
+	{
+		if (mHalCameraInfo.fast_picture_mode)
+		{
+			mCaptureWidth = mFullSizeWidth;
+			mCaptureHeight= mFullSizeHeight;
+		}
+		else
+		{
+			mCaptureWidth = preview_width;
+			mCaptureHeight= preview_height;
+		}
+	}
+
+	// preview format and video format are the same
+	uint32_t org_fmt = V4L2_PIX_FMT_NV21;		// android default
+	const char* preview_format = mParameters.getPreviewFormat();
+	if (preview_format != NULL) 
+	{
+		if (strcmp(preview_format, CameraParameters::PIXEL_FORMAT_YUV420SP) == 0)
+		{
+#ifdef __SUN6I__
+			org_fmt = V4L2_PIX_FMT_NV12;		// SGX support NV12
+#else
+			org_fmt = V4L2_PIX_FMT_NV21;		// MALI support NV21
+#endif
+		}
+		else if (strcmp(preview_format, CameraParameters::PIXEL_FORMAT_YUV420P) == 0)
+		{
+			// org_fmt = V4L2_PIX_FMT_YVU420;		// YV12
+			org_fmt = V4L2_PIX_FMT_YUV420;		// YU12			// tmp for cts
+		}
+		else
+		{
+			LOGE("unknown preview format");
+		}
+	}
+	
+	LOGD("Starting camera: %dx%d -> %.4s(%s)",
+         mCaptureWidth, mCaptureHeight, reinterpret_cast<const char*>(&org_fmt), preview_format);
+    res = camera_dev->startDevice(mCaptureWidth, mCaptureHeight, org_fmt, video_hint);
+    if (res != NO_ERROR) 
+	{
+        mPreviewWindow.stopPreview();
+        return res;
+    }
+	
+	res = camera_dev->startDeliveringFrames();
+    if (res != NO_ERROR) 
+	{
+        camera_dev->stopDevice();
+        mPreviewWindow.stopPreview();
+    }
+	
+    return res;
+}
+
+status_t CameraHardware::doStopPreview()
+{
+	F_LOG;
+	
+	status_t res = NO_ERROR;
+	if (mPreviewWindow.isPreviewEnabled()) 
+	{
+		/* Stop the camera. */
+		if (mV4L2CameraDevice->isStarted()) 
+		{
+			mV4L2CameraDevice->stopDeliveringFrames();
+			res = mV4L2CameraDevice->stopDevice();
+		}
+
+		if (res == NO_ERROR) 
+		{
+			/* Disable preview as well. */
+			mPreviewWindow.stopPreview();
+		}
+	}
+
+    return NO_ERROR;
+}
+
+/****************************************************************************
+ * Private API.
+ ***************************************************************************/
+
+status_t CameraHardware::cleanupCamera()
+{
+	F_LOG;
+
+    status_t res = NO_ERROR;
+
+	mParameters.set(KEY_SNAP_PATH, "");
+	mCallbackNotifier.setSnapPath("");
+
+	// reset preview format to yuv420sp
+	mParameters.set(CameraParameters::KEY_PREVIEW_FORMAT, CameraParameters::PIXEL_FORMAT_YUV420SP);
+
+	mV4L2CameraDevice->setHwEncoder(false);
+
+	mParameters.set(CameraParameters::KEY_JPEG_THUMBNAIL_WIDTH, 320);
+	mParameters.set(CameraParameters::KEY_JPEG_THUMBNAIL_HEIGHT, 240);
+
+	mParameters.set(CameraParameters::KEY_ZOOM, 0);
+
+	mVideoCaptureWidth = 0;
+	mVideoCaptureHeight = 0;
+	mUseHwEncoder = false;
+	
+	// stop focus thread
+	pthread_mutex_lock(&mAutoFocusMutex);
+	if (mAutoFocusThread->isThreadStarted())
+	{
+		mAutoFocusThread->stopThread();
+		pthread_cond_signal(&mAutoFocusCond);
+	}
+	pthread_mutex_unlock(&mAutoFocusMutex);
+	
+    /* If preview is running - stop it. */
+    res = doStopPreview();
+    if (res != NO_ERROR) {
+        return -res;
+    }
+
+    /* Stop and disconnect the camera device. */
+    V4L2CameraDevice* const camera_dev = mV4L2CameraDevice;
+    if (camera_dev != NULL) 
+	{
+        if (camera_dev->isStarted()) 
+		{
+            camera_dev->stopDeliveringFrames();
+            res = camera_dev->stopDevice();
+            if (res != NO_ERROR) {
+                return -res;
+            }
+        }
+        if (camera_dev->isConnected()) 
+		{
+            res = camera_dev->disconnectDevice();
+            if (res != NO_ERROR) {
+                return -res;
+            }
+        }
+    }
+
+    mCallbackNotifier.cleanupCBNotifier();
+
+	{
+		Mutex::Autolock locker(&mCameraIdleLock);
+		mIsCameraIdle = true;
+	}
+
+    return NO_ERROR;
+}
+
+/****************************************************************************
+ * Camera API callbacks as defined by camera_device_ops structure.
+ *
+ * Callbacks here simply dispatch the calls to an appropriate method inside
+ * CameraHardware instance, defined by the 'dev' parameter.
+ ***************************************************************************/
+
+int CameraHardware::set_preview_window(struct camera_device* dev,
+                                       struct preview_stream_ops* window)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+    return ec->setPreviewWindow(window);
+}
+
+void CameraHardware::set_callbacks(
+        struct camera_device* dev,
+        camera_notify_callback notify_cb,
+        camera_data_callback data_cb,
+        camera_data_timestamp_callback data_cb_timestamp,
+        camera_request_memory get_memory,
+        void* user)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return;
+    }
+    ec->setCallbacks(notify_cb, data_cb, data_cb_timestamp, get_memory, user);
+}
+
+void CameraHardware::enable_msg_type(struct camera_device* dev, int32_t msg_type)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return;
+    }
+    ec->enableMsgType(msg_type);
+}
+
+void CameraHardware::disable_msg_type(struct camera_device* dev, int32_t msg_type)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return;
+    }
+    ec->disableMsgType(msg_type);
+}
+
+int CameraHardware::msg_type_enabled(struct camera_device* dev, int32_t msg_type)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+    return ec->isMsgTypeEnabled(msg_type);
+}
+
+int CameraHardware::start_preview(struct camera_device* dev)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+    return ec->startPreview();
+}
+
+void CameraHardware::stop_preview(struct camera_device* dev)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return;
+    }
+    ec->stopPreview();
+}
+
+int CameraHardware::preview_enabled(struct camera_device* dev)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+    return ec->isPreviewEnabled();
+}
+
+int CameraHardware::store_meta_data_in_buffers(struct camera_device* dev,
+                                               int enable)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+    return ec->storeMetaDataInBuffers(enable);
+}
+
+int CameraHardware::start_recording(struct camera_device* dev)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+    return ec->startRecording();
+}
+
+void CameraHardware::stop_recording(struct camera_device* dev)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return;
+    }
+    ec->stopRecording();
+}
+
+int CameraHardware::recording_enabled(struct camera_device* dev)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+    return ec->isRecordingEnabled();
+}
+
+void CameraHardware::release_recording_frame(struct camera_device* dev,
+                                             const void* opaque)
+{
+	CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return;
+    }
+    ec->releaseRecordingFrame(opaque);
+}
+
+int CameraHardware::auto_focus(struct camera_device* dev)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+    return ec->setAutoFocus();
+}
+
+int CameraHardware::cancel_auto_focus(struct camera_device* dev)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+    return ec->cancelAutoFocus();
+}
+
+int CameraHardware::take_picture(struct camera_device* dev)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+    return ec->takePicture();
+}
+
+int CameraHardware::cancel_picture(struct camera_device* dev)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+    return ec->cancelPicture();
+}
+
+int CameraHardware::set_parameters(struct camera_device* dev, const char* parms)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+
+	int64_t lasttime = systemTime();
+	int ret = ec->setParameters(parms);
+	LOGV("setParameters use time: %lld(ms)", (systemTime() - lasttime)/1000000);
+	
+    return ret;
+}
+
+int CameraHardware::set_fd(struct camera_device* dev, int fd)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+	
+	int ret = ec->setFd(fd);	
+    return ret;
+}
+
+char* CameraHardware::get_parameters(struct camera_device* dev)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return NULL;
+    }
+    return ec->getParameters();
+}
+
+void CameraHardware::put_parameters(struct camera_device* dev, char* params)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return;
+    }
+    ec->putParameters(params);
+}
+
+int CameraHardware::send_command(struct camera_device* dev,
+                                 int32_t cmd,
+                                 int32_t arg1,
+                                 int32_t arg2)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+    return ec->sendCommand(cmd, arg1, arg2);
+}
+
+void CameraHardware::release(struct camera_device* dev)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return;
+    }
+    ec->releaseCamera();
+}
+
+int CameraHardware::dump(struct camera_device* dev, int fd)
+{
+    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+    return ec->dumpCamera(fd);
+}
+
+int CameraHardware::close(struct hw_device_t* device)
+{
+    CameraHardware* ec =
+        reinterpret_cast<CameraHardware*>(reinterpret_cast<struct camera_device*>(device)->priv);
+    if (ec == NULL) {
+        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
+        return -EINVAL;
+    }
+    return ec->closeCamera();
+}
+
+// -------------------------------------------------------------------------
+// extended interfaces here <***** star *****>
+// -------------------------------------------------------------------------
+
+/****************************************************************************
+ * Static initializer for the camera callback API
+ ****************************************************************************/
+
+camera_device_ops_t CameraHardware::mDeviceOps = {
+    CameraHardware::set_preview_window,
+    CameraHardware::set_callbacks,
+    CameraHardware::enable_msg_type,
+    CameraHardware::disable_msg_type,
+    CameraHardware::msg_type_enabled,
+    CameraHardware::start_preview,
+    CameraHardware::stop_preview,
+    CameraHardware::preview_enabled,
+    CameraHardware::store_meta_data_in_buffers,
+    CameraHardware::start_recording,
+    CameraHardware::stop_recording,
+    CameraHardware::recording_enabled,
+    CameraHardware::release_recording_frame,
+    CameraHardware::auto_focus,
+    CameraHardware::cancel_auto_focus,
+    CameraHardware::take_picture,
+    CameraHardware::cancel_picture,
+    CameraHardware::set_parameters,
+    CameraHardware::set_fd,
+    CameraHardware::get_parameters,
+    CameraHardware::put_parameters,
+    CameraHardware::send_command,
+    CameraHardware::release,
+    CameraHardware::dump
+};
+
+/****************************************************************************
+ * Common keys
+ ***************************************************************************/
+
+const char CameraHardware::FACING_KEY[]         = "prop-facing";
+const char CameraHardware::ORIENTATION_KEY[]    = "prop-orientation";
+const char CameraHardware::RECORDING_HINT_KEY[] = "recording-hint";
+
+/****************************************************************************
+ * Common string values
+ ***************************************************************************/
+
+const char CameraHardware::FACING_BACK[]      = "back";
+const char CameraHardware::FACING_FRONT[]     = "front";
+
+/****************************************************************************
+ * Helper routines
+ ***************************************************************************/
+
+static char* AddValue(const char* param, const char* val)
+{
+    const size_t len1 = strlen(param);
+    const size_t len2 = strlen(val);
+    char* ret = reinterpret_cast<char*>(malloc(len1 + len2 + 2));
+    LOGE_IF(ret == NULL, "%s: Memory failure", __FUNCTION__);
+    if (ret != NULL) {
+        memcpy(ret, param, len1);
+        ret[len1] = ',';
+        memcpy(ret + len1 + 1, val, len2);
+        ret[len1 + len2 + 1] = '\0';
+    }
+    return ret;
+}
+
+/****************************************************************************
+ * Parameter debugging helpers
+ ***************************************************************************/
+
+#if DEBUG_PARAM
+static void PrintParamDiff(const CameraParameters& current,
+                            const char* new_par)
+{
+    char tmp[2048];
+    const char* wrk = new_par;
+
+    /* Divided with ';' */
+    const char* next = strchr(wrk, ';');
+    while (next != NULL) {
+        snprintf(tmp, sizeof(tmp), "%.*s", next-wrk, wrk);
+        /* in the form key=value */
+        char* val = strchr(tmp, '=');
+        if (val != NULL) {
+            *val = '\0'; val++;
+            const char* in_current = current.get(tmp);
+            if (in_current != NULL) {
+                if (strcmp(in_current, val)) {
+                    LOGD("=== Value changed: %s: %s -> %s", tmp, in_current, val);
+                }
+            } else {
+                LOGD("+++ New parameter: %s=%s", tmp, val);
+            }
+        } else {
+            LOGW("No value separator in %s", tmp);
+        }
+        wrk = next + 1;
+        next = strchr(wrk, ';');
+    }
+}
+#endif  /* DEBUG_PARAM */
+
+}; /* namespace android */
diff --git a/hardware/camera/CameraHardware.h b/hardware/camera/CameraHardware.h
new file mode 100755
index 0000000..1127727
--- /dev/null
+++ b/hardware/camera/CameraHardware.h
@@ -0,0 +1,559 @@
+
+#ifndef __HAL_CAMERA_HARDWARE_H__
+#define __HAL_CAMERA_HARDWARE_H__
+
+/*
+ * Contains declaration of a class CameraHardware that encapsulates functionality
+ * common to all V4L2Cameras ("fake", "webcam", "video file", etc.).
+ * Instances of this class (for each V4L2Camera) are created during the
+ * construction of the HALCameraFactory instance.
+ * This class serves as an entry point for all camera API calls that defined
+ * by camera_device_ops_t API.
+ */
+
+#include <utils/Mutex.h>
+
+#include <videodev2.h>
+#include <camera/CameraParameters.h>
+#include <FaceDetectionApi.h>
+
+#include "V4L2CameraDevice.h"
+#include "PreviewWindow.h"
+#include "CallbackNotifier.h"
+#include "CCameraConfig.h"
+
+namespace android {
+
+#define KEY_CAMERA_HAL_VERSION			"camera-hal-version"
+#define KEY_CAPTURE_SIZE_WIDTH			"capture-size-width"
+#define KEY_CAPTURE_SIZE_HEIGHT			"capture-size-height"
+#define KEY_PREVIEW_CAPTURE_SIZE_WIDTH	"preview_capture-size-width"
+#define KEY_PREVIEW_CAPTURE_SIZE_HEIGHT	"preview_capture-size-height"
+
+#define KEY_PICTURE_MODE				"picture-mode"
+#define PICTURE_MODE_NORMAL				"normal"
+#define PICTURE_MODE_CONTINUOUS			"continuous"
+#define PICTURE_MODE_CONTINUOUS_FAST	"continuous-fast"
+#define KEY_CANCEL_CONTINUOUS_PICTURE	"cancel_continuous_picture"		// "true" for stopping
+#define KEY_CONTINUOUS_PICTURE_PATH		"continuous-picture-path"
+
+#define KEY_SNAP_PATH					"snap-path"
+
+/* Encapsulates functionality common to all V4L2Cameras.
+ *
+ * Note that HALCameraFactory instantiates object of this class just once,
+ * when HALCameraFactory instance gets constructed. Connection to /
+ * disconnection from the actual camera device is handled by calls to connectDevice(),
+ * and closeCamera() methods of this class that are ivoked in response to
+ * hw_module_methods_t::open, and camera_device::close callbacks.
+ */
+class CameraHardware : public camera_device {
+public:
+    /* Constructs CameraHardware instance.
+     * Param:
+     *  module - V4L2Camera HAL module descriptor.
+     */
+    CameraHardware(struct hw_module_t* module, CCameraConfig* pCameraCfg);
+
+    /* Destructs CameraHardware instance. */
+    virtual ~CameraHardware();
+
+    /****************************************************************************
+     * Public API
+     ***************************************************************************/
+
+public:
+    /* Initializes CameraHardware instance.
+     * Return:
+     *  NO_ERROR on success, or an appropriate error status on failure.
+     */
+    virtual status_t Initialize();
+
+    /* Entry point for notifications that occur in camera device.
+     * Param:
+     *  err - CAMERA_ERROR_XXX error code.
+     */
+    virtual void onCameraDeviceError(int err);
+
+    /****************************************************************************
+     * Camera API implementation
+     ***************************************************************************/
+
+public:
+    /* Creates connection to the V4L2Camera device.
+     * This method is called in response to hw_module_methods_t::open callback.
+     * NOTE: When this method is called the object is locked.
+     * Note that failures in this method are reported as negave EXXX statuses.
+     */
+    virtual status_t connectCamera(hw_device_t** device);
+
+    /* Closes connection to the V4L2Camera.
+     * This method is called in response to camera_device::close callback.
+     * NOTE: When this method is called the object is locked.
+     * Note that failures in this method are reported as negave EXXX statuses.
+     */
+    virtual status_t closeCamera();
+
+    /****************************************************************************
+     * Camera API implementation.
+     * These methods are called from the camera API callback routines.
+     ***************************************************************************/
+
+protected:
+    /* Actual handler for camera_device_ops_t::set_preview_window callback.
+     * NOTE: When this method is called the object is locked.
+     * Note that failures in this method are reported as negave EXXX statuses.
+     */
+    virtual status_t setPreviewWindow(struct preview_stream_ops *window);
+
+    /* Actual handler for camera_device_ops_t::set_callbacks callback.
+     * NOTE: When this method is called the object is locked.
+     */
+    virtual void setCallbacks(camera_notify_callback notify_cb,
+                              camera_data_callback data_cb,
+                              camera_data_timestamp_callback data_cb_timestamp,
+                              camera_request_memory get_memory,
+                              void* user);
+
+    /* Actual handler for camera_device_ops_t::enable_msg_type callback.
+     * NOTE: When this method is called the object is locked.
+     */
+    virtual void enableMsgType(int32_t msg_type);
+
+    /* Actual handler for camera_device_ops_t::disable_msg_type callback.
+     * NOTE: When this method is called the object is locked.
+     */
+    virtual void disableMsgType(int32_t msg_type);
+
+    /* Actual handler for camera_device_ops_t::msg_type_enabled callback.
+     * NOTE: When this method is called the object is locked.
+     * Return:
+     *  0 if message(s) is (are) disabled, != 0 if enabled.
+     */
+    virtual int isMsgTypeEnabled(int32_t msg_type);
+
+    /* Actual handler for camera_device_ops_t::start_preview callback.
+     * NOTE: When this method is called the object is locked.
+     * Note that failures in this method are reported as negave EXXX statuses.
+     */
+    virtual status_t startPreview();
+
+    /* Actual handler for camera_device_ops_t::stop_preview callback.
+     * NOTE: When this method is called the object is locked.
+     */
+    virtual void stopPreview();
+
+    /* Actual handler for camera_device_ops_t::preview_enabled callback.
+     * NOTE: When this method is called the object is locked.
+     * Return:
+     *  0 if preview is disabled, != 0 if enabled.
+     */
+    virtual int isPreviewEnabled();
+
+    /* Actual handler for camera_device_ops_t::store_meta_data_in_buffers callback.
+     * NOTE: When this method is called the object is locked.
+     * Note that failures in this method are reported as negave EXXX statuses.
+     */
+    virtual status_t storeMetaDataInBuffers(int enable);
+
+    /* Actual handler for camera_device_ops_t::start_recording callback.
+     * NOTE: When this method is called the object is locked.
+     * Note that failures in this method are reported as negave EXXX statuses.
+     */
+    virtual status_t startRecording();
+
+    /* Actual handler for camera_device_ops_t::stop_recording callback.
+     * NOTE: When this method is called the object is locked.
+     */
+    virtual void stopRecording();
+
+    /* Actual handler for camera_device_ops_t::recording_enabled callback.
+     * NOTE: When this method is called the object is locked.
+     * Return:
+     *  0 if recording is disabled, != 0 if enabled.
+     */
+    virtual int isRecordingEnabled();
+
+    /* Actual handler for camera_device_ops_t::release_recording_frame callback.
+     * NOTE: When this method is called the object is locked.
+     */
+    virtual void releaseRecordingFrame(const void* opaque);
+
+    /* Actual handler for camera_device_ops_t::auto_focus callback.
+     * NOTE: When this method is called the object is locked.
+     * Note that failures in this method are reported as negave EXXX statuses.
+     */
+    virtual status_t setAutoFocus();
+
+    /* Actual handler for camera_device_ops_t::cancel_auto_focus callback.
+     * NOTE: When this method is called the object is locked.
+     * Note that failures in this method are reported as negave EXXX statuses.
+     */
+    virtual status_t cancelAutoFocus();
+
+    /* Actual handler for camera_device_ops_t::take_picture callback.
+     * NOTE: When this method is called the object is locked.
+     * Note that failures in this method are reported as negave EXXX statuses.
+     */
+    virtual status_t takePicture();
+
+    /* Actual handler for camera_device_ops_t::cancel_picture callback.
+     * NOTE: When this method is called the object is locked.
+     * Note that failures in this method are reported as negave EXXX statuses.
+     */
+    virtual status_t cancelPicture();
+
+    /* Actual handler for camera_device_ops_t::set_parameters callback.
+     * NOTE: When this method is called the object is locked.
+     * Note that failures in this method are reported as negave EXXX statuses.
+     */
+    virtual status_t setParameters(const char* parms);
+
+	virtual status_t setFd(int fd);
+
+    /* Actual handler for camera_device_ops_t::get_parameters callback.
+     * NOTE: When this method is called the object is locked.
+     * Return:
+     *  Flattened parameters string. The caller will free the buffer allocated
+     *  for the string by calling camera_device_ops_t::put_parameters callback.
+     */
+    virtual char* getParameters();
+
+    /* Actual handler for camera_device_ops_t::put_parameters callback.
+     * Called to free the string returned from camera_device_ops_t::get_parameters
+     * callback. There is nothing more to it: the name of the callback is just
+     * misleading.
+     * NOTE: When this method is called the object is locked.
+     */
+    virtual void putParameters(char* params);
+
+    /* Actual handler for camera_device_ops_t::send_command callback.
+     * NOTE: When this method is called the object is locked.
+     * Note that failures in this method are reported as negave EXXX statuses.
+     */
+    virtual status_t sendCommand(int32_t cmd, int32_t arg1, int32_t arg2);
+
+    /* Actual handler for camera_device_ops_t::release callback.
+     * NOTE: When this method is called the object is locked.
+     */
+    virtual void releaseCamera();
+
+    /* Actual handler for camera_device_ops_t::dump callback.
+     * NOTE: When this method is called the object is locked.
+     * Note that failures in this method are reported as negave EXXX statuses.
+     */
+    virtual status_t dumpCamera(int fd);
+
+    /****************************************************************************
+     * Preview management.
+     ***************************************************************************/
+
+protected:
+public:
+    /* Starts preview.
+     * Note that when this method is called mPreviewWindow may be NULL,
+     * indicating that framework has an intention to start displaying video
+     * frames, but didn't create the preview window yet.
+     * Return:
+     *  NO_ERROR on success, or an appropriate error status on failure.
+     */
+    virtual status_t doStartPreview();
+
+    /* Stops preview.
+     * This method reverts DoStartPreview.
+     * Return:
+     *  NO_ERROR on success, or an appropriate error status on failure.
+     */
+    virtual status_t doStopPreview();
+
+	status_t doTakePicture();
+	status_t doTakePictureEnd();
+
+    /****************************************************************************
+     * Private API.
+     ***************************************************************************/
+
+protected:
+    /* Cleans up camera when released. */
+    virtual status_t cleanupCamera();
+
+    /****************************************************************************
+     * Camera API callbacks as defined by camera_device_ops structure.
+     * See hardware/libhardware/include/hardware/camera.h for information on
+     * each of these callbacks. Implemented in this class, these callbacks simply
+     * dispatch the call into an instance of CameraHardware class defined by the
+     * 'camera_device' parameter.
+     ***************************************************************************/
+
+private:
+    static int set_preview_window(struct camera_device* dev,
+                                   struct preview_stream_ops* window);
+
+    static void set_callbacks(struct camera_device* dev,
+                              camera_notify_callback notify_cb,
+                              camera_data_callback data_cb,
+                              camera_data_timestamp_callback data_cb_timestamp,
+                              camera_request_memory get_memory,
+                              void* user);
+
+    static void enable_msg_type(struct camera_device* dev, int32_t msg_type);
+
+    static void disable_msg_type(struct camera_device* dev, int32_t msg_type);
+
+    static int msg_type_enabled(struct camera_device* dev, int32_t msg_type);
+
+    static int start_preview(struct camera_device* dev);
+
+    static void stop_preview(struct camera_device* dev);
+
+    static int preview_enabled(struct camera_device* dev);
+
+    static int store_meta_data_in_buffers(struct camera_device* dev, int enable);
+
+    static int start_recording(struct camera_device* dev);
+
+    static void stop_recording(struct camera_device* dev);
+
+    static int recording_enabled(struct camera_device* dev);
+
+    static void release_recording_frame(struct camera_device* dev,
+                                        const void* opaque);
+
+    static int auto_focus(struct camera_device* dev);
+
+    static int cancel_auto_focus(struct camera_device* dev);
+
+    static int take_picture(struct camera_device* dev);
+
+    static int cancel_picture(struct camera_device* dev);
+
+    static int set_parameters(struct camera_device* dev, const char* parms);
+
+	static int set_fd(struct camera_device* dev, int fd);
+
+    static char* get_parameters(struct camera_device* dev);
+
+    static void put_parameters(struct camera_device* dev, char* params);
+
+    static int send_command(struct camera_device* dev,
+                            int32_t cmd,
+                            int32_t arg1,
+                            int32_t arg2);
+
+    static void release(struct camera_device* dev);
+
+    static int dump(struct camera_device* dev, int fd);
+
+    static int close(struct hw_device_t* device);
+
+    /****************************************************************************
+     * Data members
+     ***************************************************************************/
+
+protected:
+    /* Locks this instance for parameters, state, etc. change. */
+    Mutex                           mObjectLock;
+
+    /* Camera parameters. */
+    CameraParameters                mParameters;
+
+    /* Preview window. */
+    PreviewWindow                   mPreviewWindow;
+
+    /* Callback notifier. */
+    CallbackNotifier                mCallbackNotifier;
+
+	V4L2CameraDevice *   			mV4L2CameraDevice;
+
+private:
+    /* Registered callbacks implementing camera API. */
+    static camera_device_ops_t      mDeviceOps;
+
+    /****************************************************************************
+     * Common keys
+     ***************************************************************************/
+
+public:
+    static const char FACING_KEY[];
+    static const char ORIENTATION_KEY[];
+    static const char RECORDING_HINT_KEY[];
+
+     /****************************************************************************
+     * Common string values
+     ***************************************************************************/
+
+    /* Possible values for FACING_KEY */
+    static const char FACING_BACK[];
+    static const char FACING_FRONT[];
+
+	// -------------------------------------------------------------------------
+	// extended interfaces here <***** star *****>
+	// -------------------------------------------------------------------------
+public:
+	status_t setCameraHardwareInfo(HALCameraInfo * halInfo);
+	void initDefaultParameters();
+
+	void notifyPictureMsg(const void* frame);
+	
+	void setNewCrop(Rect * rect);
+	int setAutoFocusMode();
+	int setAutoFocusCtrl(int af_ctrl, void *areas);
+	int getCurrentFaceFrame(void * frame);
+	int faceDetection(camera_frame_metadata_t *face);
+    
+    int parse_focus_areas(const char * str);
+	bool checkFocusArea(const char * area);
+	bool checkFocusMode(const char * mode);
+
+	bool commandThread();
+	bool autoFocusThread();
+
+	void setVideoCaptureSize(int video_w, int video_h);
+	void getCurrentOriention(int * oriention);
+
+	bool isCameraIdle();
+
+protected:
+	CCameraConfig * 				mCameraConfig;
+
+	HALCameraInfo					mHalCameraInfo;
+
+    Mutex                           mCameraIdleLock;
+	bool							mIsCameraIdle;
+
+	bool							mFirstSetParameters;
+	bool							mIsSupportFocus;
+	bool							mIsSupportEffect;
+	bool							mIsSupportFlash;
+	bool							mIsSupportScene;
+	bool							mIsSupportWhiteBlance;
+	bool							mIsSupportExposure;
+
+	int								mFullSizeWidth;
+	int								mFullSizeHeight;
+	int								mCaptureWidth;
+	int								mCaptureHeight;
+	int								mVideoCaptureWidth;
+	int								mVideoCaptureHeight;
+	bool							mUseHwEncoder;
+
+	char							mCallingProcessName[128];
+
+	FaceDetectionDev *				mFaceDetection;
+	
+	Rect							mFrameRectCrop;		// current frame buffer crop for focus
+	char							mFocusAreasStr[32];
+	struct v4l2_pix_size			mFocusAreas;
+
+	typedef enum CMD_QUEUE_t{
+		CMD_QUEUE_SET_COLOR_EFFECT 	= 0,
+		CMD_QUEUE_SET_WHITE_BALANCE,
+		CMD_QUEUE_SET_FLASH_MODE,
+		CMD_QUEUE_SET_FOCUS_MODE,
+		CMD_QUEUE_SET_FOCUS_AREA,
+		CMD_QUEUE_SET_EXPOSURE_COMPENSATION,
+		
+		CMD_QUEUE_START_FACE_DETECTE,
+		CMD_QUEUE_STOP_FACE_DETECTE,
+
+		CMD_QUEUE_TAKE_PICTURE,
+		CMD_QUEUE_PICTURE_MSG,
+		CMD_QUEUE_STOP_CONTINUOUSSNAP,
+			
+		CMD_QUEUE_SET_FOCUS_STATUS,
+
+		CMD_QUEUE_MAX
+	}CMD_QUEUE;
+
+	OSAL_QUEUE						mQueueCommand;
+	
+	typedef struct Queue_Element_t {
+		CMD_QUEUE cmd;
+		int data;
+	}Queue_Element;
+
+	Queue_Element					mQueueElement[CMD_QUEUE_MAX];
+
+	class DoCommandThread : public Thread {
+        CameraHardware* mCameraHardware;
+		ThreadState		mThreadStatus;
+    public:
+        DoCommandThread(CameraHardware* hw) :
+			Thread(false),
+			mCameraHardware(hw),
+			mThreadStatus(THREAD_STATE_NULL) {
+		}
+        void startThread() {
+			mThreadStatus = THREAD_STATE_RUNNING;
+			run("CameraCommandThread", PRIORITY_NORMAL);
+        }
+		void stopThread() {
+			mThreadStatus = THREAD_STATE_EXIT;
+        }
+		ThreadState getThreadStatus() {
+			return mThreadStatus;
+		}
+		bool isThreadStarted() {
+			return (mThreadStatus == THREAD_STATE_PAUSED) || (mThreadStatus == THREAD_STATE_RUNNING);
+		}
+        virtual bool threadLoop() {
+			return mCameraHardware->commandThread();
+        }
+    };
+	sp<DoCommandThread>				mCommandThread;
+	
+	pthread_mutex_t 				mCommandMutex;
+	pthread_cond_t					mCommandCond;
+
+	class DoAutoFocusThread : public Thread {
+        CameraHardware* mCameraHardware;
+		ThreadState		mThreadStatus;
+    public:
+        DoAutoFocusThread(CameraHardware* hw) :
+			Thread(false),
+			mCameraHardware(hw),
+			mThreadStatus(THREAD_STATE_NULL) {
+		}
+        void startThread() {
+			mThreadStatus = THREAD_STATE_RUNNING;
+			run("CameraAutoFocusThread", PRIORITY_NORMAL);
+        }
+		void stopThread() {
+			mThreadStatus = THREAD_STATE_EXIT;
+        }
+		ThreadState getThreadStatus() {
+			return mThreadStatus;
+		}
+		bool isThreadStarted() {
+			return (mThreadStatus == THREAD_STATE_PAUSED) || (mThreadStatus == THREAD_STATE_RUNNING);
+		}
+        virtual bool threadLoop() {
+			return mCameraHardware->autoFocusThread();
+        }
+    };
+	sp<DoAutoFocusThread>			mAutoFocusThread;
+	
+	pthread_mutex_t 				mAutoFocusMutex;
+	pthread_cond_t					mAutoFocusCond;
+
+public:
+	typedef enum FocusStatus_t {
+		FOCUS_STATUS_IDLE		= 0x0,
+		FOCUS_STATUS_SUCCESS	= 0x1,
+		FOCUS_STATUS_FAIL		= 0x2,
+		FOCUS_STATUS_DONE		= FOCUS_STATUS_SUCCESS | FOCUS_STATUS_FAIL,
+		FOCUS_STATUS_BUSY		= 0x4,
+	}FocusStatus;
+
+protected:
+	FocusStatus						mFocusStatus;
+	bool							mIsSingleFocus;
+
+	int								mOriention;
+
+	int								mZoomRatio;
+};
+
+}; /* namespace android */
+
+#endif  /* __HAL_CAMERA_HARDWARE_H__ */
diff --git a/hardware/camera/CameraHardware2.cpp b/hardware/camera/CameraHardware2.cpp
index 47b8db1..4cae357 100755
--- a/hardware/camera/CameraHardware2.cpp
+++ b/hardware/camera/CameraHardware2.cpp
@@ -10,14 +10,11 @@
 #include <ui/Rect.h>
 
 #include <drv_display.h>
-#include <stdlib.h>
-#include <stdio.h>
+
 #include "CameraHardware2.h"
 #include "V4L2CameraDevice2.h"
-#ifdef __CEDARX_FRAMEWORK_2__
 #include "vencoder.h"
 #include "MetadataBufferType.h"
-#endif
 
 #define BASE_ZOOM	0
 
@@ -51,89 +48,18 @@ static char* AddValue(const char* param, const char* val);
 static int faceNotifyCb(int cmd, void * data, void * user)
 {
 	CameraHardware* camera_hw = (CameraHardware *)user;
-	int len = 0;
-	int ret = 0;
-	int width, height;
-#if DBG_CAMERA_HARDWARE
-	FILE *fd;
-	int oriention;
-	int old_oriention=-1,new_oriention=0;
-	char buf[10];
-	char path[128];
-	HALCameraInfo *halinfo;
-#endif
-	camera_frame_metadata_t *result = (camera_frame_metadata_t*)data;
 	
 	switch (cmd)
 	{
 		case FACE_NOTITY_CMD_REQUEST_FRAME:
-			width = 0;
-			height = 0;
-			camera_hw->getCurrentFaceFrame(data, &width, &height);
-			len = width*height;
-#if DBG_CAMERA_HARDWARE
-			LOGV("width: %d,height: %d\n",width,height);
-			camera_hw->getCurrentOriention(&oriention);
-			new_oriention = oriention;
+			return camera_hw->getCurrentFaceFrame(data);
 			
-			if(new_oriention!=old_oriention) {
-				sprintf(buf, "%d", new_oriention);
-				strcpy(path , "/data/camera/");
-				strcat(path, buf);
-				halinfo = camera_hw->get_halinfo();
-				if(halinfo->facing == CAMERA_FACING_BACK)
-					strcat(path,"back.bin");
-				else
-					strcat(path,"front.bin");
-				saveframe(path, data, len, 1);
-				old_oriention = new_oriention;
-			}
-#endif
-			if (len >0)
-			{
-			    memset(camera_hw->mFrameData, 0, width*height);
-			    if (len < 1024*1024*4)
-			        memcpy(camera_hw->mFrameData, (char *)data, len);
-				else
-					ALOGD("Be careful: frame buffer size > 4*1024*1024");
-				return 0;
-			}else {
-			    return -1;
-			}
 		case FACE_NOTITY_CMD_RESULT:
-			pthread_mutex_lock(&camera_hw->mFaceDetectionMutex);
-            camera_hw->mFrameFaceData.facePositions = &camera_hw->mFacePosition;
-			memcpy(camera_hw->mFrameFaceData.frameData, camera_hw->mFrameData, camera_hw->mPreviewWidth*camera_hw->mPreviewHeight);
-			camera_hw->mFrameFaceData.faceNum = result->number_of_faces;
-			// rotation angle
-			//camera_hw->mFrameFaceData.angle = camera_hw->mPreviewRotation;
-			camera_hw->getCurrentOriention((int*)(&camera_hw->mFrameFaceData.angle),180, 1, 0);
-			// preview size
-			camera_hw->mFrameFaceData.frameWidth = camera_hw->mPreviewWidth;
-			camera_hw->mFrameFaceData.frameHeight = camera_hw->mPreviewHeight;
-#if 0
-			saveframe("/data/camera/smile.bin", camera_hw->mFrameFaceData.frameData, camera_hw->mPreviewWidth*camera_hw->mPreviewHeight, 1);
-			fd = fopen("/data/camera/smile.data","wt");
-			fprintf(fd,"faceTopLeftX=%d\n",camera_hw->mFacePosition.faceTopLeftX);
-			fprintf(fd,"faceTopLeftX=%d\n",camera_hw->mFacePosition.faceTopLeftY);
-			fprintf(fd,"faceTopLeftX=%d\n",camera_hw->mFacePosition.faceWidth);
-			fprintf(fd,"faceTopLeftX=%d\n",camera_hw->mFacePosition.faceHeigth);		
-			fprintf(fd,"number_of_faces=%d\n",result->number_of_faces);
-			fprintf(fd,"angle=%d\n",camera_hw->mFrameFaceData.angle);
-			fprintf(fd,"frameWidth=%d\n",camera_hw->mPreviewWidth);
-			fprintf(fd,"frameHeight=%d\n",camera_hw->mPreviewHeight);
-			fclose(fd);
-#endif
-			pthread_mutex_unlock(&camera_hw->mFaceDetectionMutex);
 			return camera_hw->faceDetection((camera_frame_metadata_t*)data);
 
 		case FACE_NOTITY_CMD_POSITION:
 			{
 				FocusArea_t * pdata = (FocusArea_t *)data;
-                camera_hw->mFacePosition.faceTopLeftX = pdata->x;
-				camera_hw->mFacePosition.faceTopLeftY= pdata->y;
-				camera_hw->mFacePosition.faceWidth= pdata->x1 - pdata->x;
-				camera_hw->mFacePosition.faceHeigth= pdata->y1 - pdata->y;
 				char face_area[128];
 				sprintf(face_area, "(%d, %d, %d, %d, 1)", 
 						pdata->x, pdata->y, pdata->x1, pdata->y1);
@@ -142,11 +68,14 @@ static int faceNotifyCb(int cmd, void * data, void * user)
 		case FACE_NOTITY_CMD_REQUEST_ORIENTION:
 			camera_hw->getCurrentOriention((int*)data);
 			break;
+			
 		default:
 			break;
 	}
+	
 	return 0;
 }
+
 static int smileNotifyCb(int cmd, void * data, void * user)
 {
 	CameraHardware* camera_hw = (CameraHardware *)user;
@@ -154,6 +83,7 @@ static int smileNotifyCb(int cmd, void * data, void * user)
 	struct Status * mStatus = (struct Status *) data;
 	mSmile.number_of_smiles = mStatus->num;
 	mSmile.smiles = mStatus->sta;
+	
 	switch (cmd)
 	{			
 		case SMILE_NOTITY_CMD_RESULT:
@@ -188,37 +118,6 @@ static int blinkNotifyCb(int cmd, void * data, void * user)
 	return 0;
 }
 
-static int ApperceiveNotifyCb(int cmd, void * data, void * user)
-{
-	CameraHardware* camera_hw = (CameraHardware *)user;
-	long result;
-	switch (cmd)
-	{
-		case APPERCEIVEPEOPLE_NOTITY_CMD_REQUEST_FRAME:
-			ALOGV("notify request frame");
-			break;
-			
-		case APPERCEIVEPEOPLE_NOTITY_CMD_RESULT:
-			result = *((long*)data);
-			ALOGD("notify result %d", result);
-			return camera_hw->smartDetection(result);
-
-		case APPERCEIVEPEOPLE_NOTITY_CMD_POSITION:
-			ALOGV("notify position");
-			break;
-		case APPERCEIVEPEOPLE_NOTITY_CMD_REQUEST_ORIENTION:
-			ALOGV("notify request orientation");
-			camera_hw->getHWOrientionInfo(data);
-			//LOGV("-------info->scree_oriention %d",((struct APPERCEIVEPEOPLE_INFO*)data)->scree_oriention);
-			//LOGV("+++++++info->buffer_oriention %d",((struct APPERCEIVEPEOPLE_INFO*)data)->buffer_oriention);			
-			break;
-			
-		default:
-			break;
-	}
-	
-	return 0;
-}
 
 // Parse string like "640x480" or "10000,20000"
 static int parse_pair(const char *str, int *first, int *second, char delim,
@@ -259,41 +158,35 @@ CameraHardware::CameraHardware(struct hw_module_t* module, CCameraConfig* pCamer
           mVideoCaptureWidth(0),
           mVideoCaptureHeight(0),
           mUseHwEncoder(false),
+          mFrameData(NULL),
+          mPreviewRotation(0),
+          mPreviewWidth(0),
+          mPreviewHeight(0),
+          mIsSupportFocus(false),
+          mIsSupportEffect(false),
+          mIsSupportFlash(false),
+          mIsSupportScene(false),
+          mIsSupportWhiteBlance(false),
+          mIsSupportExposure(false),
+          mSmileDetectionCmdEnable(false),
+          mBlinkDetectionCmdEnable(false),
+          mBlinkPictureStarted(false),
+          mBlinkPictureResult(false),
+          mSmilePictureResult(false),
+          mZoomRatio(0),
           mFaceDetection(NULL),
           mSmileDetection(NULL),
           mBlinkDetection(NULL),
-          mSmartDetection(NULL),
           mFocusStatus(FOCUS_STATUS_IDLE),
           mSmileDetectionState(FACE_DETECTION_UNINITIALIZED),
           mBlinkDetectionState(FACE_DETECTION_UNINITIALIZED),
           mSmileDetectionEnable(false),
           mBlinkDetectionEnable(false),
-          mSmartDetectionEnable(false),
-          mSmartMode(0x01),
-          mSmartDiscardFrameNum(0),
           mIsSingleFocus(false),
           mOriention(0),
-          mZoomRatio(100),
-          mIsSupportFocus(false),
-          mIsSupportEffect(false),
-          mIsSupportFlash(false),
-          mIsSupportScene(false),
-          mIsSupportWhiteBlance(false),
-          mIsSupportExposure(false),
           mAutoFocusThreadExit(true),
           mFaceDetectionThreadExit(true),
-          mIsImageCaptureIntent(false),
-          mFrameData(NULL),
-          mSmartData(NULL),
-          mPreviewRotation(0),
-          mPreviewWidth(0),
-          mPreviewHeight(0),	
-          mSmileDetectionCmdEnable(false),
-          mBlinkDetectionCmdEnable(false),
-          mBlinkPictureStarted(false),
-          mBlinkPictureResult(false),
-          mSmilePictureResult(false),
-          mSmartThreadExit(true)
+          mIsImageCaptureIntent(false)
 {
     /*
      * Initialize camera_device descriptor for this object.
@@ -317,12 +210,15 @@ CameraHardware::CameraHardware(struct hw_module_t* module, CCameraConfig* pCamer
 		LOGE("Failed to create V4L2Camera instance");
 		return ;
 	}
-	memset((void*)mFDOriention,0,sizeof(mFDOriention));
+
 	memset((void*)mCallingProcessName, 0, sizeof(mCallingProcessName));
-	memset(&mHalCameraInfo,0,sizeof(mHalCameraInfo));
+
 	memset(&mFrameRectCrop, 0, sizeof(mFrameRectCrop));
 	memset((void*)mFocusAreasStr, 0, sizeof(mFocusAreasStr));
 	memset((void*)&mLastFocusAreas, 0, sizeof(mLastFocusAreas));
+	memset(&mHalCameraInfo, 0, sizeof(mHalCameraInfo));
+	memset(&mFrameFaceData, 0, sizeof(FrameFaceData));
+	memset(&mFacePosition, 0, sizeof(FacePosition));
 
 	// init command queue
 	OSAL_QueueCreate(&mQueueCommand, CMD_QUEUE_MAX);
@@ -338,20 +234,12 @@ CameraHardware::CameraHardware(struct hw_module_t* module, CCameraConfig* pCamer
 	pthread_mutex_init(&mAutoFocusMutex, NULL);
 	pthread_cond_init(&mAutoFocusCond, NULL);
 	mAutoFocusThread = new DoAutoFocusThread(this);
-#ifdef __OPEN_FACEDECTION__
+
 	// init face detection thread 
 	pthread_mutex_init(&mFaceDetectionMutex, NULL);
 	pthread_mutex_init(&mFaceDetectionStateMutex, NULL);
 	pthread_cond_init(&mFaceDetectionCond, NULL);
 	mFaceDetectionThread = new DoFaceDetectionThread(this);
-#endif
-
-#ifdef __OPEN_APPERCEIVEPEOPLE__
-	// init smart thread
-	pthread_mutex_init(&mSmartMutex, NULL);
-	pthread_cond_init(&mSmartCond, NULL);
-	mSmartThread = new DoSmartThread(this);
-#endif
 }
 
 CameraHardware::~CameraHardware()
@@ -366,6 +254,7 @@ CameraHardware::~CameraHardware()
 		
 	pthread_mutex_destroy(&mCommandMutex);
 	pthread_cond_destroy(&mCommandCond);
+
 	OSAL_QueueTerminate(&mQueueCommand);
 	
 	if (mAutoFocusThread != NULL)
@@ -377,42 +266,46 @@ CameraHardware::~CameraHardware()
 	pthread_mutex_destroy(&mAutoFocusMutex);
 	pthread_cond_destroy(&mAutoFocusCond);
 
-#ifdef __OPEN_FACEDECTION__
-
+	
 	if (mFaceDetectionThread != NULL)
 	{
 		mFaceDetectionThread.clear();
 		mFaceDetectionThread = 0;
 	}
-	
+
 	pthread_mutex_destroy(&mFaceDetectionMutex);
 	pthread_mutex_destroy(&mFaceDetectionStateMutex);
-	pthread_cond_destroy(&mFaceDetectionCond);	
-#endif
+	pthread_cond_destroy(&mFaceDetectionCond);
 
-#ifdef __OPEN_APPERCEIVEPEOPLE__
-	if (mSmartThread != NULL)
+	if (mBlinkDetection != NULL)
 	{
-		mSmartThread.clear();
-		mSmartThread = 0;
+		DestroyEyeBlinkDetectionDev(mBlinkDetection);
+		mBlinkDetection = NULL;
 	}
 
-	pthread_mutex_destroy(&mSmartMutex);
-	pthread_cond_destroy(&mSmartCond);
-	
+	if (mSmileDetection != NULL)
+	{
+		DestroySmileDetectionDev(mSmileDetection);
+		mSmileDetection = NULL;
+	}
 
-	if (mSmartDetection != NULL)
-    {
-        DestroyApperceivePeopleDev(mSmartDetection);
-		mSmartDetection = NULL;
-    }
+	if (mFaceDetection != NULL)
+	{
+		DestroyFaceDetectionDev(mFaceDetection);
+		mFaceDetection = NULL;
+	}
 
-	if (mSmartData != NULL)
+	if (mFrameData != NULL)
 	{
-	    free(mSmartData);
-		mSmartData = NULL;
+	    free(mFrameData);
+		mFrameData = NULL;
+	}
+
+	if (mFrameFaceData.frameData != NULL)
+	{
+	    free(mFrameFaceData.frameData);
+		mFrameFaceData.frameData = NULL;
 	}
-#endif
 
 	if (mV4L2CameraDevice != NULL)
 	{
@@ -525,7 +418,7 @@ bool CameraHardware::autoFocusThread()
 		}
 		else
 		{
-			LOGW("unknow focus status: %d", status);
+		//	LOGW("unknow focus status: %d", status);
 			ret = true;
 			goto FOCUS_THREAD_EXIT;
 		}
@@ -579,85 +472,6 @@ FOCUS_THREAD_EXIT:
 	return ret;
 }
 
-bool CameraHardware::smartThread()
-{
-	bool result = true;
-	int status = -1;
-	int width, height;
-
-	pthread_mutex_lock(&mSmartMutex);
-	if (mSmartThread->getThreadStatus() == THREAD_STATE_EXIT)
-	{
-		LOGD("mSmartThread exited");
-		result = false;		// exit thread
-		pthread_mutex_unlock(&mSmartMutex);
-		goto SMART_THREAD_EXIT;
-	}
-	mSmartThreadExit = false;
-	pthread_mutex_unlock(&mSmartMutex);
-	{
-		LOGV("mSmartThread no msg, sleep...");
-		//pthread_mutex_lock(&mSmartMutex);
-		//pthread_cond_wait(&mSmartCond, &mSmartMutex);
-		//pthread_mutex_unlock(&mSmartMutex);
-	}
-	
-    if (mSmartDetectionEnable)
-    {
-		//memset(mSmartData, 0, 1920*1080);
-		pthread_mutex_lock(&mSmartMutex);
-        int ret = getCurrentFaceFrame(mSmartData, &width, &height);
-		pthread_mutex_unlock(&mSmartMutex);
-
-		if(ret != 0)
-		{
-		    ALOGD("get current face frame failed!!!");
-			smartDetection(0);
-			usleep(500*1000);	
-		}else {
-		    #if 1
-		    if (mSmartDiscardFrameNum >0)
-		    {
-		        mSmartDiscardFrameNum--;
-				usleep(100*1000);
-				return result;
-		    }
-			#endif
-		    pthread_mutex_lock(&mSmartMutex);
-			ALOGV("APPERCEIVEPEOPLE_OPS_CMD_START");
-			if (mSmartDetection != NULL)
-			{
-				ret = mSmartDetection->ioctrl(mSmartDetection, APPERCEIVEPEOPLE_OPS_CMD_START, width, height, mSmartData, mSmartMode);
-			    if(ret < 0)
-			    {
-			        smartDetection(0);
-			        ALOGD("smart detection failed!!!");
-			    }
-			}
-			else
-			{
-			    smartDetection(0);
-				ALOGW("APPERCEIVEPEOPLE_OPS_CMD_START failed, mSmartDetection not opened.");
-			}
-			pthread_mutex_unlock(&mSmartMutex);
-			usleep(500*1000);
-		}
-    }else {
-        usleep(2000*1000);
-    }
-
-SMART_THREAD_EXIT:
-	if (result == false)
-	{
-		pthread_mutex_lock(&mSmartMutex);
-		mSmartThreadExit = true;
-		pthread_cond_signal(&mSmartCond);
-		pthread_mutex_unlock(&mSmartMutex);
-	}
-	return result;
-}
-
-
 bool CameraHardware::faceDetectionThread()
 {
 	bool ret = true;
@@ -706,13 +520,11 @@ bool CameraHardware::faceDetectionThread()
 
 	pthread_mutex_unlock(&mFaceDetectionMutex);
 
-#if __OPEN_BLINKDECTION__
-
 	pthread_mutex_lock(&mFaceDetectionMutex);
 
 	if (mBlinkDetectionEnable == true)
     {
-		LOGV("EYE_BLINK_OPS_CMD_START");
+		LOGV("~~ EYE_BLINK_OPS_CMD_START");
 		if (mBlinkDetection != 0)
 		{
 		    pthread_mutex_lock(&mFaceDetectionStateMutex);
@@ -728,8 +540,6 @@ bool CameraHardware::faceDetectionThread()
     }
 	pthread_mutex_unlock(&mFaceDetectionMutex);
 
-#endif
-
 FACE_DETECTION_THREAD_EXIT:
 	if (ret == false)
 	{
@@ -740,6 +550,7 @@ FACE_DETECTION_THREAD_EXIT:
 	}
 	return ret;
 }
+
 bool CameraHardware::commandThread()
 {
 	pthread_mutex_lock(&mCommandMutex);
@@ -749,17 +560,19 @@ bool CameraHardware::commandThread()
 		pthread_mutex_unlock(&mCommandMutex);
 		return false;
 	}
-	pthread_mutex_unlock(&mCommandMutex);
+//	pthread_mutex_unlock(&mCommandMutex);
 	
 	Queue_Element * queue = (Queue_Element *)OSAL_Dequeue(&mQueueCommand);
 	if (queue == NULL)
 	{
-		pthread_mutex_lock(&mCommandMutex);
+//		pthread_mutex_lock(&mCommandMutex);
 		LOGV("wait commond queue ......");
 		pthread_cond_wait(&mCommandCond, &mCommandMutex);
 		pthread_mutex_unlock(&mCommandMutex);
 		return true;
 	}
+	pthread_mutex_unlock(&mCommandMutex);
+
 
 	V4L2CameraDevice* pV4L2Device = mV4L2CameraDevice;
 	int cmd = queue->cmd;
@@ -802,10 +615,12 @@ bool CameraHardware::commandThread()
 		{
 			unsigned long new_flash = queue->data;
 			LOGV("CMD_QUEUE_SET_FLASH_MODE: %d", new_flash);
+			
 			if (pV4L2Device->setFlashMode(new_flash) < 0) 
 			{
 			  LOGE("ERR(%s):Fail on mV4L2Camera->setFlashMode(flash(%d))", __FUNCTION__, new_flash);
 			}
+			
 			break;
 		}
 		case CMD_QUEUE_SET_FOCUS_MODE:
@@ -833,7 +648,14 @@ bool CameraHardware::commandThread()
 			LOGV("CMD_QUEUE_START_FACE_DETECTE");
 			if (mHalCameraInfo.fast_picture_mode)
 			{
-				pV4L2Device->getThumbSize(&width, &height);
+				int scale = pV4L2Device->getSuitableThumbScale(mCaptureWidth, mCaptureHeight);
+				if (scale <= 0)
+				{
+					LOGE("error thumb scale: %d, full-size: %dx%d", scale, mCaptureWidth, mCaptureHeight);
+					break;
+				}
+				width = mCaptureWidth / scale;
+				height = mCaptureHeight / scale;
 			}
 			else
 			{
@@ -849,6 +671,7 @@ bool CameraHardware::commandThread()
 			
 			if (mFaceDetection != 0)
 			{
+			    // rotation	
 				int mRotation = mParameters.getInt(CameraParameters::KEY_ROTATION);
 			    if (0 <= mRotation) 
 				{
@@ -856,6 +679,7 @@ bool CameraHardware::commandThread()
 			    }
 				mPreviewWidth = width;
 				mPreviewHeight = height;
+
 				LOGV("start facedetection size: %dx%d", width, height);
 				mFaceDetection->ioctrl(mFaceDetection, FACE_OPS_CMD_START, width, height);
 			}
@@ -944,7 +768,7 @@ bool CameraHardware::commandThread()
 			if (strcmp(mCallingProcessName, "com.android.cts.stub") != 0
 				&& strcmp(mCallingProcessName, "com.android.cts.mediastress") != 0
 				&& mIsImageCaptureIntent == false)
-			{			
+			{
 				doTakePictureEnd();
 			}
 			break;
@@ -998,9 +822,10 @@ status_t CameraHardware::Initialize()
     mFrameFaceData.frameData = (unsigned char*)malloc(4*1024*1024);
 	
 #endif
-
 #ifdef __OPEN_SMILEDECTION__
 		
+//	#if 1
+
 	if (mSmileDetection == NULL)
 	{
 		// create SmileDetection object
@@ -1075,12 +900,6 @@ void CameraHardware::initDefaultParameters()
 	//mCallbackNotifier.setExifMake(mCameraConfig->getExifMake());
 	//mCallbackNotifier.setExifModel(mCameraConfig->getExifModel());
 
-
-		//add for android CTS by clx
-	p.set(CameraParameters::KEY_SUPPORTED_ANTIBANDING, CameraParameters::ANTIBANDING_AUTO);
-	p.set(CameraParameters::KEY_ANTIBANDING, CameraParameters::ANTIBANDING_AUTO);
-	p.set(CameraParameters::KEY_AUTO_EXPOSURE_LOCK_SUPPORTED, "true");
-
 	// for USB camera
 	if (mHalCameraInfo.is_uvc)
 	{
@@ -1103,17 +922,17 @@ void CameraHardware::initDefaultParameters()
 		p.set(CameraParameters::KEY_VIDEO_SIZE, "640x480");
 
 		// add for android CTS
-		p.set(CameraParameters::KEY_SUPPORTED_FOCUS_MODES, CameraParameters::FOCUS_MODE_AUTO);
-		p.set(CameraParameters::KEY_FOCUS_MODE, CameraParameters::FOCUS_MODE_AUTO);
+		p.set(CameraParameters::KEY_SUPPORTED_FOCUS_MODES, CameraParameters::FOCUS_MODE_FIXED);
+		p.set(CameraParameters::KEY_FOCUS_MODE, CameraParameters::FOCUS_MODE_FIXED);
 		p.set(CameraParameters::KEY_FOCUS_AREAS, "(0,0,0,0,0)");
-		//p.set(CameraParameters::KEY_FOCAL_LENGTH, "3.43");
-		//mCallbackNotifier.setFocalLenght(3.43);
+		p.set(CameraParameters::KEY_FOCAL_LENGTH, "3.43");
+		mCallbackNotifier.setFocalLenght(3.43);
 		p.set(CameraParameters::KEY_FOCUS_DISTANCES, "0.10,1.20,Infinity");
 
 		// fps
 		p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FRAME_RATES, "30");
-		p.set(CameraParameters::KEY_PREVIEW_FPS_RANGE, "3000,60000");				// add temp for CTS
-		p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FPS_RANGE, "(3000,60000)");	// add temp for CTS
+		p.set(CameraParameters::KEY_PREVIEW_FPS_RANGE, "5000,60000");				// add temp for CTS
+		p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FPS_RANGE, "(5000,60000)");	// add temp for CTS
 		p.set(CameraParameters::KEY_PREVIEW_FRAME_RATE, "30");
 		mV4L2CameraDevice->setFrameRate(30);
 
@@ -1130,7 +949,6 @@ void CameraHardware::initDefaultParameters()
 	// if (mHalCameraInfo.fast_picture_mode)
 	{
 		// capture size of picture-mode preview
-		// get full size from the driver, to do
 		mFullSizeWidth = 2592;
 		mFullSizeHeight = 1936;
 
@@ -1155,13 +973,10 @@ void CameraHardware::initDefaultParameters()
 	p.set(CameraParameters::KEY_SUPPORTED_VIDEO_SIZES, value);
 	p.set(CameraParameters::KEY_PREFERRED_PREVIEW_SIZE_FOR_VIDEO, "1280x720");
 #endif
-	p.set(CameraParameters::KEY_SUPPORTED_VIDEO_SIZES, value);
-	p.set(CameraParameters::KEY_PREFERRED_PREVIEW_SIZE_FOR_VIDEO, "640x480");
 
 	value = mCameraConfig->defaultPreviewSizeValue();
 	p.set(CameraParameters::KEY_PREVIEW_SIZE, value);
 	p.set(CameraParameters::KEY_VIDEO_SIZE, value);
-	p.set(CameraParameters::KEY_PREFERRED_PREVIEW_SIZE_FOR_VIDEO, value);
 	
 	// picture size
 	LOGV("to init picture size");
@@ -1178,8 +993,8 @@ void CameraHardware::initDefaultParameters()
 	p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FRAME_RATES, value);
 	LOGV("supportFrameRateValue: [%s] %s", CameraParameters::KEY_SUPPORTED_PREVIEW_FRAME_RATES, value);
 
-	p.set(CameraParameters::KEY_PREVIEW_FPS_RANGE, "3000,60000");				// add temp for CTS
-	p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FPS_RANGE, "(3000,60000)");	// add temp for CTS
+	p.set(CameraParameters::KEY_PREVIEW_FPS_RANGE, "5000,60000");				// add temp for CTS
+	p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FPS_RANGE, "(5000,60000)");	// add temp for CTS
 
 	value = mCameraConfig->defaultFrameRateValue();
 	p.set(CameraParameters::KEY_PREVIEW_FRAME_RATE, value);
@@ -1203,8 +1018,8 @@ void CameraHardware::initDefaultParameters()
 		p.set(CameraParameters::KEY_FOCUS_MODE, CameraParameters::FOCUS_MODE_FIXED);
 	}
 	p.set(CameraParameters::KEY_FOCUS_AREAS, "(0,0,0,0,0)");
-	//p.set(CameraParameters::KEY_FOCAL_LENGTH, "3.43");
-	//mCallbackNotifier.setFocalLenght(3.43);
+	p.set(CameraParameters::KEY_FOCAL_LENGTH, "3.43");
+	mCallbackNotifier.setFocalLenght(3.43);
 	p.set(CameraParameters::KEY_FOCUS_DISTANCES, "0.10,1.20,Infinity");
 
 	
@@ -1266,11 +1081,10 @@ void CameraHardware::initDefaultParameters()
 	}
 	else
 	{
-	//modify for CTS by clx
-		p.set(CameraParameters::KEY_MIN_EXPOSURE_COMPENSATION, "-3");
-		p.set(CameraParameters::KEY_MAX_EXPOSURE_COMPENSATION, "3");
-		p.set(CameraParameters::KEY_EXPOSURE_COMPENSATION_STEP, "1");
-		//p.set(CameraParameters::KEY_EXPOSURE_COMPENSATION, "1");
+		p.set(CameraParameters::KEY_MIN_EXPOSURE_COMPENSATION, "0");
+		p.set(CameraParameters::KEY_MAX_EXPOSURE_COMPENSATION, "0");
+		p.set(CameraParameters::KEY_EXPOSURE_COMPENSATION_STEP, "0");
+		p.set(CameraParameters::KEY_EXPOSURE_COMPENSATION, "0");
 	}
 
 COMMOM_PARAMS:
@@ -1326,17 +1140,12 @@ COMMOM_PARAMS:
 	parameterString = CameraParameters::PIXEL_FORMAT_YUV420SP;			// NV21, default
 	parameterString.append(",");
 	parameterString.append(CameraParameters::PIXEL_FORMAT_YUV420P);		// YV12
-	//parameterString.append(",");
-	//parameterString.append(CameraParameters::PIXEL_FORMAT_RGBA8888);    // rgba8888
-	
 	p.set(CameraParameters::KEY_SUPPORTED_PREVIEW_FORMATS, parameterString.string());
 	
 	p.set(CameraParameters::KEY_VIDEO_FRAME_FORMAT, CameraParameters::PIXEL_FORMAT_YUV420SP);
 	p.set(CameraParameters::KEY_PREVIEW_FORMAT, CameraParameters::PIXEL_FORMAT_YUV420SP);
 
     p.set(CameraParameters::KEY_SUPPORTED_PICTURE_FORMATS, CameraParameters::PIXEL_FORMAT_JPEG);
-
-	p.set(CameraParameters::KEY_PICTURE_FORMAT, CameraParameters::PIXEL_FORMAT_JPEG);
 	
 	p.set(CameraParameters::KEY_JPEG_QUALITY, "95"); // maximum quality
 	p.set(CameraParameters::KEY_SUPPORTED_JPEG_THUMBNAIL_SIZES, "320x240,0x0");
@@ -1355,45 +1164,19 @@ COMMOM_PARAMS:
 	p.set(CameraParameters::KEY_ROTATION, 0);
 		
 	// add for CTS
-#if 0
 	if (mHalCameraInfo.facing == CAMERA_FACING_BACK)
 	{
-		p.set(CameraParameters::KEY_HORIZONTAL_VIEW_ANGLE, "56.4");
+		p.set(CameraParameters::KEY_HORIZONTAL_VIEW_ANGLE, "51.2");
 	    p.set(CameraParameters::KEY_VERTICAL_VIEW_ANGLE, "39.4");
 	}
 	else
 	{
-		p.set(CameraParameters::KEY_HORIZONTAL_VIEW_ANGLE, "54.0");
+		p.set(CameraParameters::KEY_HORIZONTAL_VIEW_ANGLE, "51.2");
 	    p.set(CameraParameters::KEY_VERTICAL_VIEW_ANGLE, "39.4");
 	}
-#endif
-	float HorizonalViewAngle = mCameraConfig->getHorizonalViewAngle();
-	float VerticalViewAngle = mCameraConfig->getVerticalViewAngle();
 
-	if(HorizonalViewAngle < 0.001 || VerticalViewAngle < 0.001)
-	{
-		if (mHalCameraInfo.facing == CAMERA_FACING_BACK)
-		{
-			HorizonalViewAngle = 56.4;
-			VerticalViewAngle = 39.4;
-		}
-		else
-		{
-			HorizonalViewAngle = 54.0;
-			VerticalViewAngle = 39.4;
-		}
-	}
-	//LOGV("getHorizonalViewAngle: %f",HorizonalViewAngle);
-	//LOGV("getVerticalViewAngle: %f ",VerticalViewAngle);
-	p.setFloat(CameraParameters::KEY_HORIZONTAL_VIEW_ANGLE, HorizonalViewAngle);
-	p.setFloat(CameraParameters::KEY_VERTICAL_VIEW_ANGLE, VerticalViewAngle);
-#ifdef __OPEN_FACEDECTION__
 	p.set(CameraParameters::KEY_MAX_NUM_DETECTED_FACES_HW, 15);
 	p.set(CameraParameters::KEY_MAX_NUM_DETECTED_FACES_SW, 0);
-#else
-	p.set(CameraParameters::KEY_MAX_NUM_DETECTED_FACES_HW, 0);
-	p.set(CameraParameters::KEY_MAX_NUM_DETECTED_FACES_SW, 0);
-#endif
 	
 	// take picture in video mode
 	p.set(CameraParameters::KEY_VIDEO_SNAPSHOT_SUPPORTED, "true");
@@ -1404,6 +1187,7 @@ COMMOM_PARAMS:
 	p.set("snap-path", "");
 	p.set("picture-mode", "normal");
 	p.set("cancel_continuous_picture", "false");
+
 	mParameters = p;
 
 	mFirstSetParameters = true;
@@ -1415,13 +1199,6 @@ COMMOM_PARAMS:
 
 	LOGV("CameraHardware::initDefaultParameters ok");
 }
-int CameraHardware::setExifInfo(struct isp_exif_attribute exifinfo)
-{
-	float focal_lenght = (float)exifinfo.focal_length/100.0;
-	mParameters.setFloat(CameraParameters::KEY_FOCAL_LENGTH,focal_lenght);
-	//mParameters.dump();
-	return 0;
-}
 
 void CameraHardware::onCameraDeviceError(int err)
 {
@@ -1530,20 +1307,6 @@ int CameraHardware::isMsgTypeEnabled(int32_t msg_type)
     return mCallbackNotifier.isMessageEnabled(msg_type);
 }
 
-void CameraHardware::enableSmartMsgType(int32_t msg_type)
-{
-    mCallbackNotifier.enableSmartMessage(msg_type);
-}
-
-void CameraHardware::disableSmartMsgType(int32_t msg_type)
-{
-    mCallbackNotifier.disableSmartMessage(msg_type);
-}
-
-int CameraHardware::isSmartMsgTypeEnabled(int32_t msg_type)
-{
-    return mCallbackNotifier.isSmartMessageEnabled(msg_type);
-}
 status_t CameraHardware::startPreview()
 {
 	F_LOG;
@@ -1572,37 +1335,28 @@ int CameraHardware::isPreviewEnabled()
     return mPreviewWindow.isPreviewEnabled();
 }
 
-status_t CameraHardware::enablePreview()
+status_t CameraHardware::storeMetaDataInBuffers(int enable)
 {
 	F_LOG;
-	mPreviewWindow.startPreview();
-    return NO_ERROR;
-}
 
-status_t CameraHardware::disablePreview()
-{
-	F_LOG;
-	mPreviewWindow.stopPreview();
-    return NO_ERROR;
-}
+#if 1
+
+    if(enable == false) {
+        mUseHwEncoder = false;
+        mV4L2CameraDevice->setHwEncoder(false);
+    }else{
+        mUseHwEncoder = true;
+        mV4L2CameraDevice->setHwEncoder(true);
+    }
+
+    return OK;
+
+#else
 
-status_t CameraHardware::storeMetaDataInBuffers(int enable)
-{
-	F_LOG;
-#ifdef __CEDARX_FRAMEWORK_1__
     /* Callback should return a negative errno. */
     return -mCallbackNotifier.storeMetaDataInBuffers(enable);
-#elif defined __CEDARX_FRAMEWORK_2__
-	if(enable == false) {
-		mUseHwEncoder = false;
-		mV4L2CameraDevice->setHwEncoder(false);	
-	}else{
-		mUseHwEncoder = true;
-		mV4L2CameraDevice->setHwEncoder(true);
-	}
-	return OK;
 #endif
- 
+
 }
 
 status_t CameraHardware::startRecording()
@@ -1661,17 +1415,18 @@ void CameraHardware::releaseRecordingFrame(const void* opaque)
 {
 	if (mUseHwEncoder)
 	{
-#ifdef __CEDARX_FRAMEWORK_1__
-		mV4L2CameraDevice->releasePreviewFrame(*(int*)opaque);
-#elif defined __CEDARX_FRAMEWORK_2__
 		int buffer_type =  *(int*)(opaque);
 
 		if(buffer_type!= kMetadataBufferTypeCameraSource)
 		{
 			ALOGE("releaseRecordingFrame,error buffer type: %d", buffer_type);
 		}
+
+#if 1
 		mV4L2CameraDevice->releasePreviewFrame(((VencInputBuffer*)(opaque+4))->nID);
-#endif    	
+#else
+		mV4L2CameraDevice->releasePreviewFrame(*((int*)opaque));
+#endif
 	}
 }
 
@@ -1706,11 +1461,6 @@ status_t CameraHardware::setAutoFocus()
 	else
 	{
 		mV4L2CameraDevice->set3ALock(~(V4L2_LOCK_FOCUS | V4L2_LOCK_EXPOSURE| V4L2_LOCK_WHITE_BALANCE));
-		if((mLastFocusAreas.x1 == 0 && mLastFocusAreas.y1 == 0 && mLastFocusAreas.x2 == 0 && mLastFocusAreas.y2 == 0) || \
-			mLastFocusAreas.x1 == -1000 && mLastFocusAreas.y1 == -1000 && mLastFocusAreas.x2 == -1000 && mLastFocusAreas.y2 == -1000){
-				mV4L2CameraDevice->setAutoFocusRange(V4L2_AUTO_FOCUS_RANGE_AUTO);
-		}
-		else
 		mV4L2CameraDevice->setAutoFocusStart();
 	}
 
@@ -1963,8 +1713,6 @@ status_t CameraHardware::doTakePicture()
 	mCallbackNotifier.setJpegRotate(jpeg_rotate);
     mCallbackNotifier.setPictureSize(pic_width, pic_height);
 
-	// mV4L2CameraDevice->setTakePictureCtrl();
-
 	// if in recording mode
 	const char * valstr = mParameters.get(CameraParameters::KEY_RECORDING_HINT);
 	bool video_hint = (strcmp(valstr, CameraParameters::TRUE) == 0);
@@ -1973,8 +1721,7 @@ status_t CameraHardware::doTakePicture()
 		if (strcmp(mCallingProcessName, "com.android.cts.stub"))
 		{
 			// not cts
-			//modify for cts by clx
-			//mCallbackNotifier.setPictureSize(mCaptureWidth, mCaptureHeight);
+			mCallbackNotifier.setPictureSize(mCaptureWidth, mCaptureHeight);
 		}
 		mV4L2CameraDevice->setTakePictureState(TAKE_PICTURE_RECORD);
 		return OK;
@@ -1990,7 +1737,6 @@ status_t CameraHardware::doTakePicture()
 		{
 			// test continuous picture
 			int number = 0;
-			mV4L2CameraDevice->setTakePictureCtrl(V4L2_TAKE_PICTURE_FAST);
 			if (!strcmp(cur_picture_mode, PICTURE_MODE_CONTINUOUS))
 			{
 				number = 40;
@@ -2011,40 +1757,20 @@ status_t CameraHardware::doTakePicture()
 		}
 		else if (!strcmp(cur_picture_mode, PICTURE_MODE_BLINK))
 		{
-			mV4L2CameraDevice->setTakePictureCtrl(V4L2_TAKE_PICTURE_FAST);
 		    mV4L2CameraDevice->setTakePictureState(TAKE_PICTURE_SMART);
 			mV4L2CameraDevice->startSmartPicture();
 			return OK;
-	}
+		}
 		else if (!strcmp(cur_picture_mode, PICTURE_MODE_SMILE))
 		{
-			mV4L2CameraDevice->setTakePictureCtrl(V4L2_TAKE_PICTURE_FAST);
 		    mV4L2CameraDevice->setTakePictureState(TAKE_PICTURE_SMART);
 			mV4L2CameraDevice->startSmartPicture();
 			return OK;
 		}
-		else if (!strcmp(cur_picture_mode, PICTURE_MODE_SCENE_MODE))
-		{
-			const char *now_scene_mode_str = mParameters.get(CameraParameters::KEY_SCENE_MODE); 
-	        if (!strcmp(now_scene_mode_str, CameraParameters::SCENE_MODE_HDR)	|| \
-				!strcmp(now_scene_mode_str, CameraParameters::SCENE_MODE_NIGHT)){
-		        mV4L2CameraDevice->setTakePictureState(TAKE_PICTURE_SCENE_MODE);
-			    mV4L2CameraDevice->startSceneModePicture(0);
-				mV4L2CameraDevice->setTakePictureCtrl(V4L2_TAKE_PICTURE_HDR);
-			    return OK;
-		    }
-		}
 	}
 
-	if (mCameraConfig->supportFlashMode()){
-		const char * cur_flash_mode = mParameters.get(CameraParameters::KEY_FLASH_MODE);
-		if (!strcmp(cur_flash_mode, CameraParameters::FLASH_MODE_ON))
-			mV4L2CameraDevice->setTakePictureCtrl(V4L2_TAKE_PICTURE_FLASH);
-		else
-			mV4L2CameraDevice->setTakePictureCtrl(V4L2_TAKE_PICTURE_NORM);
-		}
-	else
-		mV4L2CameraDevice->setTakePictureCtrl(V4L2_TAKE_PICTURE_NORM);
+	mV4L2CameraDevice->setTakePictureCtrl();
+
 	// normal picture mode
 
 	// full-size capture
@@ -2069,11 +1795,16 @@ status_t CameraHardware::doTakePicture()
 		mV4L2CameraDevice->setTakePictureState(TAKE_PICTURE_FAST);
 		return OK;
 	}
-	
+
 	// preview format and video format are the same
 	const char* pix_fmt = mParameters.getPictureFormat();
-	uint32_t org_fmt = V4L2_PIX_FMT_NV12;
-
+	uint32_t org_fmt;
+	if (mHalCameraInfo.is_uvc)
+	{
+		org_fmt = V4L2_PIX_FMT_NV21;	
+	}else{
+		org_fmt = V4L2_PIX_FMT_NV12;
+	}
 	/*
      * Make sure preview is not running, and device is stopped before taking
      * picture.
@@ -2101,9 +1832,8 @@ status_t CameraHardware::doTakePicture()
 	mCaptureWidth = frame_width;
 	mCaptureHeight = frame_height;
 
-	LOGD("Starting camera, Size:%dx%d , picture format:%s",
-		 mCaptureWidth, mCaptureHeight, pix_fmt);
-	mV4L2CameraDevice->showformat(org_fmt, "take picture");
+	LOGD("Starting camera: %dx%d -> %.4s(%s)",
+		 mCaptureWidth, mCaptureHeight, reinterpret_cast<const char*>(&org_fmt), pix_fmt);
 	status_t res = mV4L2CameraDevice->startDevice(mCaptureWidth, mCaptureHeight, org_fmt, video_hint);
 	if (res != NO_ERROR) 
 	{
@@ -2139,97 +1869,10 @@ status_t CameraHardware::doTakePictureEnd()
 		LOGV("doTakePictureEnd to doStartPreview");
 		doStartPreview();
 	}
-	const char * valstr = mParameters.get(CameraParameters::KEY_RECORDING_HINT);
-	bool video_hint = (strcmp(valstr, CameraParameters::TRUE) == 0);
-	if(!video_hint)
-		mV4L2CameraDevice->setTakePictureCtrl(V4L2_TAKE_PICTURE_STOP);
-	return OK;
-}
-
-status_t CameraHardware::doStartSmart()
-{
-	F_LOG;
-    Mutex::Autolock locker(&mObjectLock);
-	status_t res;
-    // preview size;
-	int mWidth = 640;
-	int mHeight = 480;
-
-	V4L2CameraDevice* const camera_dev = mV4L2CameraDevice;
 
-	if (camera_dev->isStarted()) 
-	{
-        camera_dev->stopDeliveringFrames();
-        camera_dev->stopDevice();
-    }
-
-	// Make sure camera device is connected.
-	if (!camera_dev->isConnected())
-	{
-		res = camera_dev->connectDevice(&mHalCameraInfo);
-		if (res != NO_ERROR) 
-		{
-			return res;
-		}
-		camera_dev->setAutoFocusInit();
-	}
-	
-	// preview format and video format are the same
-	uint32_t org_fmt = V4L2_PIX_FMT_NV21;		// android default
-	const char* preview_format = mParameters.getPreviewFormat();
-	if (preview_format != NULL) 
-	{
-		if (strcmp(preview_format, CameraParameters::PIXEL_FORMAT_YUV420SP) == 0)
-		{
-#ifdef __SUN6I__
-			org_fmt = V4L2_PIX_FMT_NV12;		// SGX support NV12
-#else
-			org_fmt = V4L2_PIX_FMT_NV21;		// MALI support NV21
-#endif
-		}
-		else if (strcmp(preview_format, CameraParameters::PIXEL_FORMAT_YUV420P) == 0)
-		{
-			org_fmt = V4L2_PIX_FMT_YVU420;		// YV12
-		}
-		else
-		{
-			LOGE("unknown preview format");
-		}
-	}
-	LOGD("preview_format is %s", preview_format);
-	camera_dev->showformat(org_fmt, "smart preview");
-    res = camera_dev->startDevice(mWidth, mHeight, org_fmt, false);
-    if (res != NO_ERROR) 
-	{
-        return res;
-    }
-	
-	res = camera_dev->startDeliveringFrames();
-    if (res != NO_ERROR) 
-	{
-        camera_dev->stopDevice();
-    }
-	
-    return res;
+	return OK;
 }
 
-
-status_t CameraHardware::doStopSmart()
-{
-	F_LOG;
-    Mutex::Autolock locker(&mObjectLock);
-
-	status_t res = NO_ERROR;
-
-	/* Stop the camera. */
-	if (mV4L2CameraDevice->isStarted()) 
-	{
-		mV4L2CameraDevice->stopDeliveringFrames();
-		res = mV4L2CameraDevice->stopDevice();
-	}
-	
-    return NO_ERROR;
-}
 status_t CameraHardware::takePicture()
 {
 	F_LOG;
@@ -2244,9 +1887,8 @@ status_t CameraHardware::takePicture()
 			
 			if (mSmileDetectionState != FACE_DETECTION_STATE_ERROR) 
 			{
-				ALOGV("mSmileDetectionEnable is true!!!");
 		        mSmileDetectionEnable = true;
-				//mBlinkDetectionEnable = false;			    
+				mBlinkDetectionEnable = false;			    
 			}
 			else
 			{
@@ -2255,8 +1897,6 @@ status_t CameraHardware::takePicture()
 			pthread_mutex_unlock(&mFaceDetectionMutex);
 
 		}
-		
-		#if 0
 		else if(!strcmp(cur_picture_mode, PICTURE_MODE_BLINK))
 		{
 		    pthread_mutex_lock(&mFaceDetectionMutex);
@@ -2272,9 +1912,9 @@ status_t CameraHardware::takePicture()
 			}	
 			pthread_mutex_unlock(&mFaceDetectionMutex);
 		}
-		#endif
 			
 	}
+	
 	pthread_mutex_lock(&mCommandMutex);
 	mQueueElement[CMD_QUEUE_TAKE_PICTURE].cmd = CMD_QUEUE_TAKE_PICTURE;
 	OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_TAKE_PICTURE]);
@@ -2289,6 +1929,8 @@ status_t CameraHardware::cancelPicture()
     F_LOG;
 	mV4L2CameraDevice->setTakePictureState(TAKE_PICTURE_NULL);
 
+	#if 1
+
 	pthread_mutex_lock(&mFaceDetectionMutex);
 
 	if (mSmileDetectionEnable == true)
@@ -2311,10 +1953,9 @@ status_t CameraHardware::cancelPicture()
 
 		pthread_mutex_unlock(&mFaceDetectionStateMutex);
 	}
+	ALOGD("~~ cancelPicture: mSmileDetectionEnable = false");
 	pthread_mutex_unlock(&mFaceDetectionMutex);
 
-	#if 0
-
 	pthread_mutex_lock(&mFaceDetectionMutex);
 
 	if (mBlinkDetectionEnable == true)
@@ -2337,16 +1978,17 @@ status_t CameraHardware::cancelPicture()
 
 		pthread_mutex_unlock(&mFaceDetectionStateMutex);
 	}
+	ALOGD("~~ cancelPicture: mBlinkDetectionEnable = false");
 	pthread_mutex_unlock(&mFaceDetectionMutex);
 
 	#endif
+		
     return NO_ERROR;
 }
 
 // 
 void CameraHardware::notifyPictureMsg(const void* frame)
 {
-
 	pthread_mutex_lock(&mCommandMutex);
 	mQueueElement[CMD_QUEUE_PICTURE_MSG].cmd = CMD_QUEUE_PICTURE_MSG;
 	mQueueElement[CMD_QUEUE_PICTURE_MSG].data = (unsigned long)frame;
@@ -2355,9 +1997,11 @@ void CameraHardware::notifyPictureMsg(const void* frame)
 	pthread_mutex_unlock(&mCommandMutex);
 
 	pthread_mutex_lock(&mFaceDetectionMutex);
+
 	if (mSmileDetectionEnable == true)
 	{
 	    mSmileDetectionEnable = false;
+			
 		LOGV("SMILE_OPS_CMD_STOP");
 		if (mSmileDetection != 0)
 		{
@@ -2374,10 +2018,9 @@ void CameraHardware::notifyPictureMsg(const void* frame)
 
 		pthread_mutex_unlock(&mFaceDetectionStateMutex);
 	}
+	ALOGD("~~ notifyPictureMsg: mSmileDetectionState %d", mSmileDetectionState);
 	pthread_mutex_unlock(&mFaceDetectionMutex);
 
-	#if 0
-
 	pthread_mutex_lock(&mFaceDetectionMutex);
 
 	if (mBlinkDetectionEnable == true)
@@ -2400,9 +2043,9 @@ void CameraHardware::notifyPictureMsg(const void* frame)
 
 		pthread_mutex_unlock(&mFaceDetectionStateMutex);
 	}
+
+	ALOGD("~~ notifyPictureMsg: mBlinkDetectionState %d", mBlinkDetectionState);
 	pthread_mutex_unlock(&mFaceDetectionMutex);
-	
-	#endif
 
 }
 
@@ -2418,8 +2061,16 @@ void CameraHardware::setVideoCaptureSize(int video_w, int video_h)
 	// now the same
 	mVideoCaptureWidth = video_w;
 	mVideoCaptureHeight= video_h;
-	
-
+/*
+	if (mHalCameraInfo.fast_picture_mode)
+	{
+		if (mVideoCaptureWidth == 640)
+		{
+			mVideoCaptureWidth = mVideoCaptureWidth * 2;
+			mVideoCaptureHeight= mVideoCaptureHeight * 2;
+		}
+	}
+*/
 	int videoCaptureWidth = mVideoCaptureWidth;
 	int videoCaptureHeight =mVideoCaptureHeight;
 	
@@ -2452,61 +2103,25 @@ void CameraHardware::setVideoCaptureSize(int video_w, int video_h)
 	}
 }
 
-void CameraHardware::getHWOrientionInfo(void *OrientionInfo)
+void CameraHardware::getCurrentOriention(int * oriention)
 {
-	struct APPERCEIVEPEOPLE_INFO *info = (struct APPERCEIVEPEOPLE_INFO*)OrientionInfo;
-	if(mHalCameraInfo.orientation == 90 || \
-		mHalCameraInfo.orientation == 270)
-		info->scree_oriention = 2;
-	else info->scree_oriention = 1;
-	if(mHalCameraInfo.orientation == 180 || \
-		mHalCameraInfo.orientation == 270)
-		info->buffer_oriention = 1;
-	else info->buffer_oriention = 0;
-	if(mHalCameraInfo.facing = CAMERA_FACING_FRONT && info->scree_oriention == 2)
-		info->buffer_oriention = (info->buffer_oriention + 1)%2;
-}
+	*oriention = mOriention;
 
-void CameraHardware::makeFDOrientionArray()
-{
-	memset(mFDOriention,0,sizeof(mFDOriention));
-	int rotation;
-
-	//todo: test mHalCameraInfo.orientation 270 and 180
-	if(mHalCameraInfo.orientation == 90 || mHalCameraInfo.orientation == 270){
-		for(int i = 0;i < 4;i++){
-			mFDOriention[i] = (360-i * 90 + mHalCameraInfo.orientation)%360;
-			if(mHalCameraInfo.facing == CAMERA_FACING_FRONT && (i == 1 || i == 3)){
-				mFDOriention[i] = (mFDOriention[i] + 180)%360;
-			}
-			LOGV("FDOriention array[%d]: %d",i,mFDOriention[i]);
+	//do it in AWGallery
+	//if(mHalCameraInfo.facing == CAMERA_FACING_FRONT)   //for direction of front camera facedetection
+/*	{
+		if(*oriention == 90)
+		{
+			*oriention = 270;
 		}
-
-	}
-	else{
-		for(int i = 0;i < 4;i++){
-			mFDOriention[i] = (i * 90 + mHalCameraInfo.orientation)%360;
-			if(mHalCameraInfo.facing == CAMERA_FACING_FRONT && (i == 1 || i == 3)){
-				mFDOriention[i] = (mFDOriention[i] + 180)%360;
-			}
-			LOGV("FDOriention array[%d]: %d",i,mFDOriention[i]);
+		else if(*oriention == 270)
+		{
+			*oriention = 90;
 		}
 	}
-
+*/
 }
 
-void CameraHardware::getCurrentOriention(int * oriention, int compensation,bool reverse,int re_direction)
-{
-	char rota[100];
-	property_get("sys.current.rotation",rota,"Unknow");
-	mOriention = atoi(rota);
-	//LOGV("FDOriention: %d",mFDOriention[mOriention]);
-	*oriention = (mFDOriention[mOriention] + compensation)%360;
-	if(reverse && (*oriention == re_direction || *oriention == (re_direction + 180)%360)) {
-		*oriention = (*oriention + 180)%360;
-	}
-	//LOGV("FDOriention: %d",*oriention);
-}
 int CameraHardware::getPriviewSize(int* preview_width,int* preview_height,int capture_width,int capture_height)
 {
 	//in order to have a better preview image,awgallery run in a larger size,which
@@ -2569,8 +2184,7 @@ status_t CameraHardware::setParameters(const char* p)
 			|| !strcmp(new_picture_mode, PICTURE_MODE_BLINK)
 			|| !strcmp(new_picture_mode, PICTURE_MODE_SMILE)
 			|| !strcmp(new_picture_mode, PICTURE_MODE_CONTINUOUS)
-			|| !strcmp(new_picture_mode, PICTURE_MODE_CONTINUOUS_FAST)
-			|| !strcmp(new_picture_mode, PICTURE_MODE_SCENE_MODE))
+			|| !strcmp(new_picture_mode, PICTURE_MODE_CONTINUOUS_FAST))
 		{
         	mParameters.set(KEY_PICTURE_MODE, new_picture_mode);
 		}
@@ -2598,8 +2212,7 @@ status_t CameraHardware::setParameters(const char* p)
 		}
 		else if(!strcmp(new_picture_mode, PICTURE_MODE_NORMAL)
 			    || !strcmp(new_picture_mode, PICTURE_MODE_BLINK)
-			    || !strcmp(new_picture_mode, PICTURE_MODE_SMILE)
-			    || !strcmp(new_picture_mode, PICTURE_MODE_SCENE_MODE))
+			    || !strcmp(new_picture_mode, PICTURE_MODE_SMILE))
 		{
 			const char * new_path = params.get(KEY_SNAP_PATH);
 			LOGV("%s : snap new_path : %s", __FUNCTION__, new_path);
@@ -2609,71 +2222,6 @@ status_t CameraHardware::setParameters(const char* p)
 				mCallbackNotifier.setSnapPath(new_path);
 			}
 		}
-
-		#if 1
-		
-		if (mCameraConfig->supportSceneMode())
-		{
-		    const char *now_scene_mode_str = mParameters.get(CameraParameters::KEY_SCENE_MODE);
-			const char *new_scene_mode_str = params.get(CameraParameters::KEY_SCENE_MODE);
-			LOGV("%s : new_scene_mode_str %s", __FUNCTION__, new_scene_mode_str);
-		    if ((new_scene_mode_str != NULL)
-				&& (mFirstSetParameters || strcmp(now_scene_mode_str, new_scene_mode_str)))
-			{
-				mParameters.set(CameraParameters::KEY_SCENE_MODE, new_scene_mode_str);
-				const char *scene_mode_str = mParameters.get(CameraParameters::KEY_SCENE_MODE);
-
-				ALOGD("!!! scene_mode_str %s", scene_mode_str);
-	     
-				if (now_scene_mode_str != NULL)
-				{
-				    LOGV("%s : now_scene_mode_str : %s", __FUNCTION__, scene_mode_str);
-					mV4L2CameraDevice->closeSceneMode();//close old scene mode frist
-			        if (!strcmp(scene_mode_str, CameraParameters::SCENE_MODE_AUTO)) {
-						//mParameters.set(KEY_PICTURE_MODE, PICTURE_MODE_SCENE_MODE);					    
-						mParameters.set(KEY_PICTURE_MODE, PICTURE_MODE_NORMAL);
-						const char * new_path = params.get(KEY_SNAP_PATH);
-						LOGV("%s : snap new_path : %s", __FUNCTION__, new_path);
-						if (new_path != NULL)
-						{
-							mParameters.set(KEY_SNAP_PATH, new_path);
-							mCallbackNotifier.setSnapPath(new_path);
-						}
-						
-			        } else if (!strcmp(scene_mode_str, CameraParameters::SCENE_MODE_HDR)){
-			            if(0 == mV4L2CameraDevice->openSceneMode(scene_mode_str)) {
-	                        mParameters.set(KEY_PICTURE_MODE, PICTURE_MODE_SCENE_MODE);
-							const char * new_path = params.get(KEY_SNAP_PATH);
-							LOGV("%s : snap new_path : %s", __FUNCTION__, new_path);
-							if (new_path != NULL)
-							{
-								mParameters.set(KEY_SNAP_PATH, new_path);
-								mCallbackNotifier.setSnapPath(new_path);
-							}
-			            }
-					} else if (!strcmp(scene_mode_str, CameraParameters::SCENE_MODE_NIGHT)){
-			            if(0 == mV4L2CameraDevice->openSceneMode(scene_mode_str)) {
-	                        mParameters.set(KEY_PICTURE_MODE, PICTURE_MODE_SCENE_MODE);
-							const char * new_path = params.get(KEY_SNAP_PATH);
-							LOGV("%s : snap new_path : %s", __FUNCTION__, new_path);
-							if (new_path != NULL)
-							{
-								mParameters.set(KEY_SNAP_PATH, new_path);
-								mCallbackNotifier.setSnapPath(new_path);
-							}
-			            }	
-			        }else {
-			            mV4L2CameraDevice->closeSceneMode();
-						mParameters.set(KEY_PICTURE_MODE, PICTURE_MODE_NORMAL);
-			            LOGE("ERR(%s):Invalid scene mode(%s)", __FUNCTION__, now_scene_mode_str);
-			            ret = UNKNOWN_ERROR;
-			        }
-			    }	
-		    }
-
-		}
-		#endif
-		
     }
 
 	const char * new_continuous_picture_fast = params.get("is_continuous_picture_fast");
@@ -2707,6 +2255,7 @@ status_t CameraHardware::setParameters(const char* p)
 			mIsImageCaptureIntent = false;
 		}
 	}
+
 	// preview format
 	const char * new_preview_format = params.getPreviewFormat();
 	LOGV("%s : new_preview_format : %s", __FUNCTION__, new_preview_format);
@@ -2760,7 +2309,6 @@ status_t CameraHardware::setParameters(const char* p)
 	
 		mCallbackNotifier.setCBSize(new_preview_width, new_preview_height);
 #if 0
-
 		// do it in camera.cfg
 		if (!mHalCameraInfo.fast_picture_mode					// YUV sensor
 			&& new_preview_width == 640							// preview with 640x480
@@ -2772,7 +2320,7 @@ status_t CameraHardware::setParameters(const char* p)
 			new_preview_width = 1280;
 			new_preview_height = 960;
 		}
-
+#endif
 		if (strcmp(mCallingProcessName, "com.android.cts.verifier") == 0   //add for CTS Verifier by fuqiang
 			&& new_preview_width == 640
 			&& new_preview_height == 480)
@@ -2782,7 +2330,6 @@ status_t CameraHardware::setParameters(const char* p)
 			new_preview_width = 1280;
 			new_preview_height = 960;
 		}
-#endif
 
 		// try size
 		ret = pV4L2Device->tryFmtSize(&new_preview_width, &new_preview_height);
@@ -2808,7 +2355,7 @@ status_t CameraHardware::setParameters(const char* p)
 		mParameters.set(KEY_PREVIEW_CAPTURE_SIZE_WIDTH, new_preview_width);
 		mParameters.set(KEY_PREVIEW_CAPTURE_SIZE_HEIGHT, new_preview_height);
 		int format = mV4L2CameraDevice->getCaptureFormat();
-		mV4L2CameraDevice->showformat(format,"csi capture format is: ");
+		mV4L2CameraDevice->showformat(format,"Csi capture format is: ");
 		mParameters.set(KEY_CAPTURE_FORMAT, format);
 	}
 	else
@@ -2818,9 +2365,13 @@ status_t CameraHardware::setParameters(const char* p)
 	}
 
 	// video size
-	int new_video_width		= 0;
-	int new_video_height	= 0;
+	int new_video_width		= new_preview_width;//0;
+	int new_video_height	= new_preview_height;//0;
 	params.getVideoSize(&new_video_width, &new_video_height);
+	if(new_preview_width > new_video_width){
+		new_video_width = new_preview_width;
+		new_video_height = new_preview_height;
+	}
     LOGV("%s : new_video_width x new_video_height = %dx%d",
          __FUNCTION__, new_video_width, new_video_height);
 	if (0 < new_video_width && 0 < new_video_height)
@@ -2882,18 +2433,6 @@ status_t CameraHardware::setParameters(const char* p)
 		}
 	}
 
-
-// add for cts by clx
-	int new_jpeg_thumbnail_quality = params.getInt(CameraParameters::KEY_JPEG_THUMBNAIL_QUALITY);
-	
-    LOGV("%s : new_jpeg_thumbnail_quality %d", __FUNCTION__, new_jpeg_thumbnail_quality);
-	if (new_jpeg_thumbnail_quality >=1 && new_jpeg_thumbnail_quality <= 100) 
-		{
-			mParameters.set(CameraParameters::KEY_JPEG_THUMBNAIL_QUALITY, new_jpeg_thumbnail_quality);
-		}
-
-
-
 	// JPEG image quality
     int new_jpeg_quality = params.getInt(CameraParameters::KEY_JPEG_QUALITY);
     LOGV("%s : new_jpeg_quality %d", __FUNCTION__, new_jpeg_quality);
@@ -2938,7 +2477,7 @@ status_t CameraHardware::setParameters(const char* p)
 	    if ((new_image_effect_str != NULL)
 			&& (mFirstSetParameters || strcmp(now_image_effect_str, new_image_effect_str)))
 		{
-	        unsigned long  new_image_effect = -1;
+	        int  new_image_effect = -1;
 
 	        if (!strcmp(new_image_effect_str, CameraParameters::EFFECT_NONE))
 	            new_image_effect = V4L2_COLORFX_NONE;
@@ -2963,7 +2502,8 @@ status_t CameraHardware::setParameters(const char* p)
 				OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_SET_COLOR_EFFECT]);
 	        }
 	    }
-	}	
+	}
+	
 	// white balance
 	if (mCameraConfig->supportWhiteBalance())
 	{
@@ -2973,7 +2513,7 @@ status_t CameraHardware::setParameters(const char* p)
 	    if ((new_white_str != NULL)
 			&& (mFirstSetParameters || strcmp(now_white_str, new_white_str)))
 		{
-	        unsigned long new_white = -1;
+	        int new_white = -1;
 	        int no_auto_balance = 1;
 
 	        if (!strcmp(new_white_str, CameraParameters::WHITE_BALANCE_AUTO))
@@ -3012,23 +2552,15 @@ status_t CameraHardware::setParameters(const char* p)
 	        }
 	    }
 	}
-
-	 //add for cts by clx
-    const char *new_ae_lock_str = params.get(CameraParameters::KEY_AUTO_EXPOSURE_LOCK);
-    const char *now_ae_lock_str = mParameters.get(CameraParameters::KEY_AUTO_EXPOSURE_LOCK);
-        if ((new_ae_lock_str != NULL)
-                    && (mFirstSetParameters || strcmp(now_ae_lock_str, new_ae_lock_str)))
-            mParameters.set(CameraParameters::KEY_AUTO_EXPOSURE_LOCK, new_ae_lock_str);
 	
 	// exposure compensation
 	if (mCameraConfig->supportExposureCompensation())
 	{
-		long now_exposure_compensation = mParameters.getInt(CameraParameters::KEY_EXPOSURE_COMPENSATION);
-		long new_exposure_compensation = params.getInt(CameraParameters::KEY_EXPOSURE_COMPENSATION);
-		long max_exposure_compensation = params.getInt(CameraParameters::KEY_MAX_EXPOSURE_COMPENSATION);
-		long min_exposure_compensation = params.getInt(CameraParameters::KEY_MIN_EXPOSURE_COMPENSATION);
-		LOGV("%s : new_exposure_compensation %d,min_exposure_compensation %d,max_exposure_compensation %d",
-			__FUNCTION__, new_exposure_compensation,min_exposure_compensation,max_exposure_compensation);
+		int now_exposure_compensation = mParameters.getInt(CameraParameters::KEY_EXPOSURE_COMPENSATION);
+		int new_exposure_compensation = params.getInt(CameraParameters::KEY_EXPOSURE_COMPENSATION);
+		int max_exposure_compensation = params.getInt(CameraParameters::KEY_MAX_EXPOSURE_COMPENSATION);
+		int min_exposure_compensation = params.getInt(CameraParameters::KEY_MIN_EXPOSURE_COMPENSATION);
+		LOGV("%s : new_exposure_compensation %d", __FUNCTION__, new_exposure_compensation);
 		if ((min_exposure_compensation <= new_exposure_compensation)
 			&& (max_exposure_compensation >= new_exposure_compensation))
 		{
@@ -3050,23 +2582,17 @@ status_t CameraHardware::setParameters(const char* p)
 	// flash mode	
 	if (mCameraConfig->supportFlashMode())
 	{
-		unsigned long new_flash = -1;
+		int new_flash = -1;
 		const char *new_flash_mode_str = params.get(CameraParameters::KEY_FLASH_MODE);
 		mParameters.set(CameraParameters::KEY_FLASH_MODE, new_flash_mode_str);
-
-		const char * valstr = mParameters.get(CameraParameters::KEY_RECORDING_HINT);
-		bool video_hint = (strcmp(valstr, CameraParameters::TRUE) == 0);
 		LOGV("%s, flash_mode = %s", __FUNCTION__, new_flash_mode_str);
 		
 		if (!strcmp(new_flash_mode_str, CameraParameters::FLASH_MODE_OFF))
 			new_flash = V4L2_FLASH_LED_MODE_NONE;
 		else if (!strcmp(new_flash_mode_str, CameraParameters::FLASH_MODE_AUTO))
 			new_flash = V4L2_FLASH_LED_MODE_AUTO;
-		else if (!strcmp(new_flash_mode_str, CameraParameters::FLASH_MODE_ON)){
+		else if (!strcmp(new_flash_mode_str, CameraParameters::FLASH_MODE_ON))
 			new_flash = V4L2_FLASH_LED_MODE_FLASH;
-			//recording mode,Flash will keep in torch status
-			if(video_hint) new_flash = V4L2_FLASH_LED_MODE_TORCH;
-		}
 		else if (!strcmp(new_flash_mode_str, CameraParameters::FLASH_MODE_TORCH))
 			new_flash = V4L2_FLASH_LED_MODE_TORCH;
 		else if (!strcmp(new_flash_mode_str, CameraParameters::FLASH_MODE_RED_EYE))
@@ -3137,7 +2663,7 @@ status_t CameraHardware::setParameters(const char* p)
 #if 0
 			strcpy(mFocusAreasStr, new_focus_areas_str);
 			mQueueElement[CMD_QUEUE_SET_FOCUS_AREA].cmd = CMD_QUEUE_SET_FOCUS_AREA;
-			mQueueElement[CMD_QUEUE_SET_FOCUS_AREA].data = mFocusAreasStr;
+			mQueueElement[CMD_QUEUE_SET_FOCUS_AREA].data = (int)&mFocusAreasStr;
 			OSAL_QueueSetElem(&mQueueCommand, &mQueueElement[CMD_QUEUE_SET_FOCUS_AREA]);
 #else
 			parse_focus_areas(new_focus_areas_str);
@@ -3158,9 +2684,7 @@ status_t CameraHardware::setParameters(const char* p)
 	// gps latitude
     const char *new_gps_latitude_str = params.get(CameraParameters::KEY_GPS_LATITUDE);
 	if (new_gps_latitude_str) {
-		LOGV("%s, new gps latitude = %s", __FUNCTION__, new_gps_latitude_str);
 		mCallbackNotifier.setGPSLatitude(atof(new_gps_latitude_str));
-		LOGV("%s, new gps latitude = %lf", __FUNCTION__, atof(new_gps_latitude_str));
         mParameters.set(CameraParameters::KEY_GPS_LATITUDE, new_gps_latitude_str);
     } else {
     	mCallbackNotifier.setGPSLatitude(0.0);
@@ -3199,7 +2723,6 @@ status_t CameraHardware::setParameters(const char* p)
 
     // gps processing method
     const char *new_gps_processing_method_str = params.get(CameraParameters::KEY_GPS_PROCESSING_METHOD);
-	LOGV("%s, new gps processing method = %s", __FUNCTION__, new_gps_processing_method_str);
 	if (new_gps_processing_method_str) {
 		mCallbackNotifier.setGPSMethod(new_gps_processing_method_str);
         mParameters.set(CameraParameters::KEY_GPS_PROCESSING_METHOD, new_gps_processing_method_str);
@@ -3259,6 +2782,7 @@ status_t CameraHardware::setFd(int fd)
 	mCallbackNotifier.setFd(fd);
 	return NO_ERROR;
 }
+
 void CameraHardware::setNewCrop(Rect * rect)
 {
 	F_LOG;
@@ -3273,27 +2797,30 @@ status_t CameraHardware::sendCommand(int32_t cmd, int32_t arg1, int32_t arg2)
 
 	switch (cmd)
 	{
-	case CAMERA_CMD_SET_CEDARX_RECORDER:
-		mUseHwEncoder = true;
-		mV4L2CameraDevice->setHwEncoder(true);
-		return OK;
-	case CAMERA_CMD_START_FACE_DETECTION:
-	{
-		const char *face = mParameters.get(CameraParameters::KEY_MAX_NUM_DETECTED_FACES_HW);
-		if (face == NULL || (atoi(face) <= 0))
-		{
-			return -EINVAL;
-		}
+		case CAMERA_CMD_SET_CEDARX_RECORDER:
+			mUseHwEncoder = true;
+			mV4L2CameraDevice->setHwEncoder(true);
+			return OK;
+		case CAMERA_CMD_START_FACE_DETECTION:
+		{	
+			const char *face = mParameters.get(CameraParameters::KEY_MAX_NUM_DETECTED_FACES_HW);
+			if (face == NULL || (atoi(face) <= 0))
+			{
+				return -EINVAL;
+			}
 			pthread_mutex_lock(&mCommandMutex);
-		mQueueElement[CMD_QUEUE_START_FACE_DETECTE].cmd = CMD_QUEUE_START_FACE_DETECTE;
-		OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_START_FACE_DETECTE]);
-		pthread_cond_signal(&mCommandCond);
+			
+			mQueueElement[CMD_QUEUE_START_FACE_DETECTE].cmd = CMD_QUEUE_START_FACE_DETECTE;
+			OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_START_FACE_DETECTE]);
+			pthread_cond_signal(&mCommandCond);
+			
 			pthread_mutex_unlock(&mCommandMutex);
 
 			// start face detection thread
 		    mFaceDetectionThread->startThread();
-		return OK;
-	}
+					
+			return OK;
+		}
 		case CAMERA_CMD_STOP_FACE_DETECTION:
             // stop face detection thread
 			pthread_mutex_lock(&mFaceDetectionMutex);
@@ -3303,102 +2830,31 @@ status_t CameraHardware::sendCommand(int32_t cmd, int32_t arg1, int32_t arg2)
 				pthread_cond_signal(&mFaceDetectionCond);
 			}
 			pthread_mutex_unlock(&mFaceDetectionMutex);
+			
 			pthread_mutex_lock(&mCommandMutex);
-		mQueueElement[CMD_QUEUE_STOP_FACE_DETECTE].cmd = CMD_QUEUE_STOP_FACE_DETECTE;
-		OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_STOP_FACE_DETECTE]);
-		pthread_cond_signal(&mCommandCond);
+			mQueueElement[CMD_QUEUE_STOP_FACE_DETECTE].cmd = CMD_QUEUE_STOP_FACE_DETECTE;
+			OSAL_Queue(&mQueueCommand, &mQueueElement[CMD_QUEUE_STOP_FACE_DETECTE]);
+			pthread_cond_signal(&mCommandCond);
 			pthread_mutex_unlock(&mCommandMutex);
-		return OK;
-	case CAMERA_CMD_PING:
-		return OK;
-	case CAMERA_CMD_ENABLE_FOCUS_MOVE_MSG:
-	{
-		bool enable = static_cast<bool>(arg1);
-        if (enable) {
-			enableMsgType(CAMERA_MSG_FOCUS_MOVE);
-        } else {
-			disableMsgType(CAMERA_MSG_FOCUS_MOVE);
-        }
-		return OK;
-	}
-	case CAMERA_CMD_SET_DISPLAY_ORIENTATION:
-		{
-		LOGD("CAMERA_CMD_SET_DISPLAY_ORIENTATION, to do ...");
-		return OK;
-		}
-		case CAMERA_CMD_START_SMART_DETECTION:
-		{	
-			ALOGD("CAMERA_CMD_START_SMART_DETECTION");
-			enableSmartMsgType(CAMERA_SMART_MSG_STATUS);
 
-			if (!mSmartDetectionEnable) 
-			{
-			    status_t result = doStartSmart();
-			    if (mSmartData == NULL)
-			        mSmartData = (unsigned char*)malloc(1920*1080);
-				if (mSmartDetection == NULL)
-				{
-				    //create ApperceivePeopleDev object
-				    CreateApperceivePeopleDev(&mSmartDetection);
-					if (mSmartDetection == NULL)
-					{
-					    ALOGE("create ApperceivePeopleDev failed");
-					}
-					#if 1
-					mSmartMode = arg1;
-					if (mSmartMode == 0x03)
-					{
-					    mSmartDiscardFrameNum = 5;
-					}
-					else
-					{
-					    mSmartDiscardFrameNum = 0;
-					}
-					#endif
-					mSmartDetection->ioctrl(mSmartDetection, APPERCEIVEPEOPLE_OPS_CMD_REGISTE_USER, (unsigned long)this, 0, NULL, mSmartMode);
-				    mSmartDetection->setCallback(mSmartDetection, ApperceiveNotifyCb);
-				}
-				mSmartDetectionEnable = true;
-				// start smart thread
-				ALOGD("mSmartThread start");
-			    mSmartThread->startThread();
-				pthread_cond_signal(&mSmartCond);
-			}
-			
+			return OK;
+		case CAMERA_CMD_PING:
+			return OK;
+		case CAMERA_CMD_ENABLE_FOCUS_MOVE_MSG:
+		{
+			bool enable = static_cast<bool>(arg1);
+		        if (enable) {
+					enableMsgType(CAMERA_MSG_FOCUS_MOVE);
+		        } else {
+					disableMsgType(CAMERA_MSG_FOCUS_MOVE);
+		        }
 			return OK;
 		}
-		case CAMERA_CMD_STOP_SMART_DETECTION:
-
-			ALOGD("CAMERA_CMD_STOP_SMART_DETECTION");		
-			disableSmartMsgType(CAMERA_SMART_MSG_STATUS);
-			if (mSmartDetectionEnable)
-			{
-				pthread_mutex_lock(&mSmartMutex);
-				if (mSmartThread->isThreadStarted())
-				{
-					mSmartThread->stopThread();
-					pthread_cond_signal(&mSmartCond);
-				}
-				pthread_mutex_unlock(&mSmartMutex);
-				mSmartDiscardFrameNum = 0;
-		
-				doStopSmart();
-				mSmartDetectionEnable = false;
-				
-				if (mSmartDetection != NULL)
-			    {
-			        DestroyApperceivePeopleDev(mSmartDetection);
-					mSmartDetection = NULL;
-			    }
-
-				if (mSmartData != NULL)
-				{
-				    free(mSmartData);
-					mSmartData = NULL;
-				}
-			}
-
+		case CAMERA_CMD_SET_DISPLAY_ORIENTATION:
+		{
+			LOGD("CAMERA_CMD_SET_DISPLAY_ORIENTATION, to do ...");
 			return OK;
+		}
 		default:
 		    break;
 	}
@@ -3425,9 +2881,9 @@ status_t CameraHardware::dumpCamera(int fd)
  * Facedetection management
  ***************************************************************************/
 
-int CameraHardware::getCurrentFaceFrame(void* frame, int* width, int* height)
+int CameraHardware::getCurrentFaceFrame(void * frame)
 {
-	return mV4L2CameraDevice->getCurrentFaceFrame(frame, width, height);
+	return mV4L2CameraDevice->getCurrentFaceFrame(frame);
 }
 
 int CameraHardware::faceDetection(camera_frame_metadata_t *face)
@@ -3468,8 +2924,11 @@ int CameraHardware::faceDetection(camera_frame_metadata_t *face)
 
 		pthread_mutex_unlock(&mFaceDetectionStateMutex);
     }
+	
 	return mCallbackNotifier.faceDetectionMsg(face);
 }
+
+
 int CameraHardware::smileDetection(camera_face_smile_status_t *smile)
 {	
         int number_of_smiles = smile->number_of_smiles;
@@ -3536,15 +2995,7 @@ int CameraHardware::blinkDetection(camera_face_blink_status_t *blink)
 	return NO_ERROR;
 }
 
-int CameraHardware::smartDetection(int type)
-{
-    ALOGD("smartDetection type %d", type);
-    //pthread_mutex_lock(&mSmartMutex);	
-	//pthread_cond_signal(&mSmartCond);
-	//pthread_mutex_unlock(&mSmartMutex);
 
-    return mCallbackNotifier.smartDetectionMsg(type);
-}
 
 /****************************************************************************
  * Preview management.
@@ -3588,12 +3039,8 @@ status_t CameraHardware::doStartPreview()
 		camera_dev->setAutoFocusInit();
 	}
 
-	//make facedetection oriention arrary
-	makeFDOrientionArray();
 	const char * valstr = mParameters.get(CameraParameters::KEY_RECORDING_HINT);
 	bool video_hint = (strcmp(valstr, CameraParameters::TRUE) == 0);
-	if(strcmp(mCallingProcessName, "com.android.cts.verifier") == 0) //Add for CTS
-		video_hint = 1;
 
 	// preview size
 	int preview_width = 0, preview_height = 0;
@@ -3613,8 +3060,8 @@ status_t CameraHardware::doStartPreview()
 	// capture size
 	if (video_hint)
 	{
-		mCaptureWidth = preview_width;
-		mCaptureHeight= preview_height;
+		mCaptureWidth = mVideoCaptureWidth;
+		mCaptureHeight= mVideoCaptureHeight;
 	}
 	else
 	{
@@ -3658,18 +3105,19 @@ status_t CameraHardware::doStartPreview()
 			LOGE("unknown preview format");
 		}
 	}
-	
-	LOGD("Starting camera, Size:%dx%d , picture format:%s",
-		 mCaptureWidth, mCaptureHeight, preview_format);
-	camera_dev->showformat(org_fmt, "preview");
+	if (!mHalCameraInfo.is_uvc){
+		mCaptureWidth = preview_width;
+		mCaptureHeight= preview_height;
+	}
+	LOGD("Starting camera: %dx%d -> %.4s(%s)",
+         mCaptureWidth, mCaptureHeight, reinterpret_cast<const char*>(&org_fmt), preview_format);
     res = camera_dev->startDevice(mCaptureWidth, mCaptureHeight, org_fmt, video_hint);
     if (res != NO_ERROR) 
 	{
         mPreviewWindow.stopPreview();
         return res;
     }
-	if (mCameraConfig->supportFocusMode())
-	setAutoFocusRange();
+	
 	res = camera_dev->startDeliveringFrames();
     if (res != NO_ERROR) 
 	{
@@ -3691,7 +3139,6 @@ status_t CameraHardware::doStopPreview()
 		if (mV4L2CameraDevice->isStarted()) 
 		{
 			mV4L2CameraDevice->stopDeliveringFrames();
-			mV4L2CameraDevice->stopPreviewThread();
 			res = mV4L2CameraDevice->stopDevice();
 		}
 
@@ -3714,13 +3161,12 @@ status_t CameraHardware::cleanupCamera()
 	F_LOG;
 
     status_t res = NO_ERROR;
-	//add for cts by clx
-      mParameters.set(CameraParameters::KEY_AUTO_EXPOSURE_LOCK, false);
-	  
+
 	mParameters.set(KEY_SNAP_PATH, "");
 	mCallbackNotifier.setSnapPath("");
 
 	mParameters.set(KEY_PICTURE_MODE, "normal");
+
 	// reset preview format to yuv420sp
 	mParameters.set(CameraParameters::KEY_PREVIEW_FORMAT, CameraParameters::PIXEL_FORMAT_YUV420SP);
 
@@ -3734,34 +3180,6 @@ status_t CameraHardware::cleanupCamera()
 	mVideoCaptureWidth = 0;
 	mVideoCaptureHeight = 0;
 	mUseHwEncoder = false;
-	// stop smart detection	
-	disableSmartMsgType(CAMERA_SMART_MSG_STATUS);
-	if (mSmartDetectionEnable)
-	{
-		pthread_mutex_lock(&mSmartMutex);
-		if (mSmartThread->isThreadStarted())
-		{
-			mSmartThread->stopThread();
-			pthread_cond_signal(&mSmartCond);
-		}
-		pthread_mutex_unlock(&mSmartMutex);
-		mSmartDiscardFrameNum = 0;
-
-		doStopSmart();
-		mSmartDetectionEnable = false;
-		
-		if (mSmartDetection != NULL)
-	    {
-	        DestroyApperceivePeopleDev(mSmartDetection);
-			mSmartDetection = NULL;
-	    }
-
-		if (mSmartData != NULL)
-		{
-		    free(mSmartData);
-			mSmartData = NULL;
-		}
-	}
 	
 	// stop focus thread
 	pthread_mutex_lock(&mAutoFocusMutex);
@@ -3783,6 +3201,7 @@ status_t CameraHardware::cleanupCamera()
 		}
 		pthread_mutex_unlock(&mAutoFocusMutex);
 	}
+
 	usleep(100000);	// tmp for CTS
 	
     /* If preview is running - stop it. */
@@ -3793,9 +3212,6 @@ status_t CameraHardware::cleanupCamera()
 
     /* Stop and disconnect the camera device. */
     V4L2CameraDevice* const camera_dev = mV4L2CameraDevice;
-	//stop flash
-	if (mCameraConfig->supportFlashMode())
-		camera_dev->setFlashMode(V4L2_FLASH_LED_MODE_NONE);	
     if (camera_dev != NULL) 
 	{
         if (camera_dev->isStarted()) 
@@ -3822,35 +3238,6 @@ status_t CameraHardware::cleanupCamera()
 		mIsCameraIdle = true;
 	}
 
-	if (mBlinkDetection != NULL)
-	{
-		DestroyEyeBlinkDetectionDev(mBlinkDetection);
-		mBlinkDetection = NULL;
-	}
-
-	if (mSmileDetection != NULL)
-	{
-		DestroySmileDetectionDev(mSmileDetection);
-		mSmileDetection = NULL;
-	}
-
-	if (mFaceDetection != NULL)
-	{
-		DestroyFaceDetectionDev(mFaceDetection);
-		mFaceDetection = NULL;
-	}
-
-	if (mFrameData != NULL)
-	{
-	    free(mFrameData);
-		mFrameData = NULL;
-	}
-
-	if (mFrameFaceData.frameData != NULL)
-	{
-	    free(mFrameFaceData.frameData);
-		mFrameFaceData.frameData = NULL;
-	}
     return NO_ERROR;
 }
 
@@ -3948,26 +3335,6 @@ int CameraHardware::preview_enabled(struct camera_device* dev)
     return ec->isPreviewEnabled();
 }
 
-int CameraHardware::enable_preview(struct camera_device* dev)
-{
-    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
-    if (ec == NULL) {
-        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
-        return -EINVAL;
-    }
-    return ec->enablePreview();
-}
-
-int CameraHardware::disable_preview(struct camera_device* dev)
-{
-    CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
-    if (ec == NULL) {
-        LOGE("%s: Unexpected NULL camera device", __FUNCTION__);
-        return -EINVAL;
-    }
-    return ec->disablePreview();
-}
-
 int CameraHardware::store_meta_data_in_buffers(struct camera_device* dev,
                                                int enable)
 {
@@ -4086,6 +3453,7 @@ int CameraHardware::set_fd(struct camera_device* dev, int fd)
 	int ret = ec->setFd(fd);	
     return ret;
 }
+
 char* CameraHardware::get_parameters(struct camera_device* dev)
 {
     CameraHardware* ec = reinterpret_cast<CameraHardware*>(dev->priv);
@@ -4150,10 +3518,6 @@ int CameraHardware::close(struct hw_device_t* device)
     return ec->closeCamera();
 }
 
-HALCameraInfo* CameraHardware::get_halinfo()
-{
-    return &mHalCameraInfo;
-}
 // -------------------------------------------------------------------------
 // extended interfaces here <***** star *****>
 // -------------------------------------------------------------------------
@@ -4171,8 +3535,6 @@ camera_device_ops_t CameraHardware::mDeviceOps = {
     CameraHardware::start_preview,
     CameraHardware::stop_preview,
     CameraHardware::preview_enabled,
-    CameraHardware::enable_preview,
-    CameraHardware::disable_preview,
     CameraHardware::store_meta_data_in_buffers,
     CameraHardware::start_recording,
     CameraHardware::stop_recording,
diff --git a/hardware/camera/CameraHardware2.h b/hardware/camera/CameraHardware2.h
index ca06c68..b348423 100755
--- a/hardware/camera/CameraHardware2.h
+++ b/hardware/camera/CameraHardware2.h
@@ -13,6 +13,7 @@
 
 #include <utils/Mutex.h>
 
+//#include <videodev2.h>
 #include <camera/CameraParameters.h>
 
 #include "V4L2CameraDevice2.h"
@@ -22,9 +23,7 @@
 #include "libfacedetection/FaceDetectionApi.h"
 #include "libfacedetection/SmileEyeBlinkAPI.h"
 #include "libfacedetection/ApperceivePeopleApi.h"
-#include "CameraPlatform.h"
-
-#ifdef __PLATFORM_A64__
+#ifdef __PLATFORM_H64__
 #include <sunxi_camera.h>
 #else
 #include <videodev2_34.h>
@@ -42,7 +41,6 @@ namespace android {
 #define PICTURE_MODE_NORMAL				"normal"
 #define PICTURE_MODE_BLINK				"blink"
 #define PICTURE_MODE_SMILE				"smile"
-#define PICTURE_MODE_SCENE_MODE		    "scene-mode"
 #define PICTURE_MODE_CONTINUOUS			"continuous"
 #define PICTURE_MODE_CONTINUOUS_FAST	"continuous-fast"
 #define KEY_CANCEL_CONTINUOUS_PICTURE	"cancel_continuous_picture"		// "true" for stopping
@@ -52,6 +50,8 @@ namespace android {
 
 #define KEY_IS_IMAGECAPTURE_INTENT		"is-imagecapture-intent"
 #define KEY_CAPTURE_FORMAT              "capture-format"
+
+
 typedef enum face_detection_states_t {
 	FACE_DETECTION_UNINITIALIZED    = 0,
 	FACE_DETECTION_INITIALIZED      = 1 << 0,
@@ -61,6 +61,8 @@ typedef enum face_detection_states_t {
 	FACE_DETECTION_STOPPED          = 1 << 4,
 	FACE_DETECTION_STATE_ERROR      = 1 << 5,
 }face_detection_states;
+
+
 /* Encapsulates functionality common to all V4L2Cameras.
  *
  * Note that HALCameraFactory instantiates object of this class just once,
@@ -172,10 +174,6 @@ protected:
      */
     virtual int isPreviewEnabled();
 
-	virtual status_t enablePreview();
-
-	virtual status_t disablePreview();
-
     /* Actual handler for camera_device_ops_t::store_meta_data_in_buffers callback.
      * NOTE: When this method is called the object is locked.
      * Note that failures in this method are reported as negave EXXX statuses.
@@ -236,6 +234,7 @@ protected:
     virtual status_t setParameters(const char* parms);
 
 	virtual status_t setFd(int fd);
+
     /* Actual handler for camera_device_ops_t::get_parameters callback.
      * NOTE: When this method is called the object is locked.
      * Return:
@@ -269,22 +268,6 @@ protected:
      */
     virtual status_t dumpCamera(int fd);
 
-    /* Actual handler for face detection msg_type callback.
-     * NOTE: When this method is called the object is locked.
-     */
-    virtual void enableSmartMsgType(int32_t msg_type);
-
-    /* Actual handler for face detection msg_type callback.
-     * NOTE: When this method is called the object is locked.
-     */
-    virtual void disableSmartMsgType(int32_t msg_type);
-
-    /* Actual handler for face detection callback.
-     * NOTE: When this method is called the object is locked.
-     * Return:
-     *  0 if message(s) is (are) disabled, != 0 if enabled.
-     */
-    virtual int isSmartMsgTypeEnabled(int32_t msg_type);
     /****************************************************************************
      * Preview management.
      ***************************************************************************/
@@ -309,8 +292,6 @@ public:
 
 	status_t doTakePicture();
 	status_t doTakePictureEnd();
-	status_t doStartSmart();
-	status_t doStopSmart();
 
     /****************************************************************************
      * Private API.
@@ -351,10 +332,6 @@ private:
 
     static int preview_enabled(struct camera_device* dev);
 
-	static int enable_preview(struct camera_device* dev);
-
-	static int disable_preview(struct camera_device* dev);
-
     static int store_meta_data_in_buffers(struct camera_device* dev, int enable);
 
     static int start_recording(struct camera_device* dev);
@@ -377,6 +354,7 @@ private:
     static int set_parameters(struct camera_device* dev, const char* parms);
 
 	static int set_fd(struct camera_device* dev, int fd);
+
     static char* get_parameters(struct camera_device* dev);
 
     static void put_parameters(struct camera_device* dev, char* params);
@@ -435,8 +413,6 @@ public:
     struct FrameFaceData                     mFrameFaceData;     
     struct FacePosition                      mFacePosition;
     unsigned char*                           mFrameData;
-	
-	unsigned char*                           mSmartData;
 
 	int mPreviewRotation;                 
     int mPreviewWidth;    
@@ -447,7 +423,6 @@ public:
 	
 	bool mSmileDetectionEnable;
 	bool mBlinkDetectionEnable;
-	bool mSmartDetectionEnable;
 
 	//face_detection_states mSmileDetectionState;
 	//face_detection_states mBlinkDetectionState;
@@ -455,11 +430,11 @@ public:
 	bool mBlinkPictureStarted;
 	bool mBlinkPictureResult;
 	bool mSmilePictureResult;
+
 	// -------------------------------------------------------------------------
 	// extended interfaces here <***** star *****>
 	// -------------------------------------------------------------------------
 public:
-	HALCameraInfo* get_halinfo();
 	status_t setCameraHardwareInfo(HALCameraInfo * halInfo);
 	void initDefaultParameters();
 
@@ -467,11 +442,10 @@ public:
 	
 	void setNewCrop(Rect * rect);
 	int setAutoFocusRange();
-	int getCurrentFaceFrame(void* frame, int* width, int* height);
+	int getCurrentFaceFrame(void * frame);
 	int faceDetection(camera_frame_metadata_t *face);
 	int smileDetection(camera_face_smile_status_t *smile);
 	int blinkDetection(camera_face_blink_status_t *blink);
-	int smartDetection(int type);
     int parse_focus_areas(const char * str, bool is_face = false);
 	bool checkFocusArea(const char * area);
 	bool checkFocusMode(const char * mode);
@@ -480,14 +454,10 @@ public:
 	bool autoFocusThread();
 	bool faceDetectionThread();
 
-	bool smartThread();
 	void setVideoCaptureSize(int video_w, int video_h);
-	void getCurrentOriention(int * oriention, int compensation = 0,bool reverse = 0,int re_direction = 0);
+	void getCurrentOriention(int * oriention);
 
 	bool isCameraIdle();
-	void makeFDOrientionArray();
-	void getHWOrientionInfo(void *);
-	int setExifInfo(struct isp_exif_attribute exifinfo);
 	int getPriviewSize(int* preview_width,int* preview_height,int capture_width,int capture_height);
 
 protected:
@@ -519,9 +489,7 @@ protected:
 	FaceDetectionDev *				mFaceDetection;
 	SmileDetectionDev *				mSmileDetection;
 	EyeBlinkDetectionDev *          mBlinkDetection;
-	ApperceivePeopleDev *           mSmartDetection;
 	
-	int								mFDOriention[4];
 	Rect							mFrameRectCrop;		// current frame buffer crop for focus
 	char							mFocusAreasStr[32];
 	struct v4l2_win_coordinate		mLastFocusAreas;
@@ -536,8 +504,10 @@ protected:
 		
 		CMD_QUEUE_START_FACE_DETECTE,
 		CMD_QUEUE_STOP_FACE_DETECTE,
+
 		CMD_QUEUE_START_SMILE_DETECTE,
 		CMD_QUEUE_STOP_SMILE_DETECTE,
+
 		CMD_QUEUE_START_BLINK_DETECTE,
 		CMD_QUEUE_STOP_BLINK_DETECTE,
 
@@ -638,7 +608,9 @@ protected:
 	int								mOriention;
 
 	int								mZoomRatio;
+
 	bool                            mIsImageCaptureIntent;
+
 	class DoFaceDetectionThread : public Thread {
         CameraHardware* mCameraHardware;
 		ThreadState		mThreadStatus;
@@ -650,7 +622,7 @@ protected:
 		}
         void startThread() {
 			mThreadStatus = THREAD_STATE_RUNNING;
-			run("faceDetectionThread", PRIORITY_NORMAL);
+			run("CameraFaceDetectionThread", PRIORITY_NORMAL);
         }
 		void stopThread() {
 			mThreadStatus = THREAD_STATE_EXIT;
@@ -667,35 +639,7 @@ protected:
     };
 	sp<DoFaceDetectionThread>	    mFaceDetectionThread;
 	
-public: 
-	class DoSmartThread : public Thread {
-        CameraHardware* mCameraHardware;
-		ThreadState		mThreadStatus;
-    public:
-        DoSmartThread(CameraHardware* hw) :
-			Thread(false),
-			mCameraHardware(hw),
-			mThreadStatus(THREAD_STATE_NULL) {
-		}
-        void startThread() {
-			mThreadStatus = THREAD_STATE_RUNNING;
-			run("smartThread", PRIORITY_NORMAL);
-        }
-		void stopThread() {
-			mThreadStatus = THREAD_STATE_EXIT;
-        }
-		ThreadState getThreadStatus() {
-			return mThreadStatus;
-		}
-		bool isThreadStarted() {
-			return (mThreadStatus == THREAD_STATE_PAUSED) || (mThreadStatus == THREAD_STATE_RUNNING);
-		}
-        virtual bool threadLoop() {
-			return mCameraHardware->smartThread();
-        }
-    };
-	sp<DoSmartThread>	    mSmartThread;
-	
+public:	
 	pthread_mutex_t 				mFaceDetectionMutex;
 	pthread_cond_t					mFaceDetectionCond;
 	bool							mFaceDetectionThreadExit;
@@ -704,12 +648,7 @@ public:
 
 	face_detection_states mSmileDetectionState;
 	face_detection_states mBlinkDetectionState;
-
-	pthread_mutex_t 				mSmartMutex;
-	pthread_cond_t					mSmartCond;
-	bool							mSmartThreadExit;
-	int                             mSmartMode;  
-	int                             mSmartDiscardFrameNum;
+	
 };
 
 }; /* namespace android */
diff --git a/hardware/camera/CameraList.cpp b/hardware/camera/CameraList.cpp
new file mode 100755
index 0000000..6a8fbbd
--- /dev/null
+++ b/hardware/camera/CameraList.cpp
@@ -0,0 +1,103 @@
+
+//#include "CameraDebug.h"
+//#if DBG_CAMERA_CONFIG
+//#define LOG_NDEBUG 0
+//#endif
+#define LOG_TAG "CameraList"
+#include <cutils/log.h>
+
+#include "CameraList.h"
+
+CameraList::CameraList()
+	:mhKeyFile(0)
+{
+	mhKeyFile = ::fopen(CAMERA_LIST_KEY_CONFIG_PATH, "rb");
+	if (mhKeyFile <= 0)
+	{
+		LOGV("open file %s failed", CAMERA_LIST_KEY_CONFIG_PATH);
+		return;
+	}
+	else
+	{
+		LOGV("open file %s OK", CAMERA_LIST_KEY_CONFIG_PATH);
+	}
+
+	readKey(kCAMERA_LIST, mCameraDeviceList);
+	LOGV("CameraList: %s", mCameraDeviceList);
+}
+
+CameraList::~CameraList()
+{	
+	if (mhKeyFile != 0)
+	{
+		::fclose(mhKeyFile);
+		mhKeyFile = 0;
+		LOGD("Close file %s OK",CAMERA_LIST_KEY_CONFIG_PATH);
+	}
+}
+
+bool CameraList::usedKey(char *value)
+{
+	return strcmp(value, "1") ? false : true;
+}
+
+void CameraList::getValue(char *line, char *value)
+{
+	char * ptemp = line;
+	while(*ptemp)
+	{
+		if (*ptemp++ == '=')
+		{
+			break;
+		}
+	}
+
+	char *pval = ptemp;
+	char *seps = " \n\r\t";
+	int offset = 0;
+	//pval = strtok(pval, seps);
+	while (pval != NULL)
+	{
+		strncpy(value + offset, pval, strlen(pval));
+		offset += strlen(pval);
+		pval = strtok(NULL, seps);
+	}
+	*(value + offset) = 0;
+}
+
+bool CameraList::readKey(char *key, char *value)
+{
+	bool bRet = false;
+	char str[KEY_LIST_LENGTH];
+
+	if (key == 0 || value == 0)
+	{
+		LOGV("error input para");
+		return false;
+	}
+
+	if (mhKeyFile == 0)
+	{
+		LOGV("error key file handle");
+		return false;
+	}
+
+	fseek(mhKeyFile, 0L, SEEK_SET);
+
+	memset(str, 0, KEY_LIST_LENGTH);
+	while (fgets(str, KEY_LIST_LENGTH , mhKeyFile))
+	{
+		if (!strncmp(key, str, strlen(key)))
+		{
+			getValue(str, value);
+
+			bRet = true;
+			break;
+		}
+		memset(str, 0, KEY_LIST_LENGTH);
+	}	
+
+	return bRet;
+}
+
+
diff --git a/hardware/camera/CameraList.h b/hardware/camera/CameraList.h
new file mode 100755
index 0000000..0e3fd48
--- /dev/null
+++ b/hardware/camera/CameraList.h
@@ -0,0 +1,49 @@
+#ifndef __CAMERA_LIST_H__
+#define __CAMERA_LIST_H__
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <string.h>
+
+#define CAMERA_LIST_KEY_CONFIG_PATH	"/system/etc/cameralist.cfg"
+
+#define KEY_LIST_LENGTH	8192
+
+#define kCAMERA_LIST					"key_camera_list"
+//#define kCAMERA_EXIF_MODEL					"key_camera_exif_model"
+
+#define DBG_ENABLE 1
+
+#if  DBG_ENABLE
+	 #define LOGE(...)  __android_log_print(ANDROID_LOG_ERROR,LOG_TAG,__VA_ARGS__)
+	 #define LOGD(...)  __android_log_print(ANDROID_LOG_DEBUG,LOG_TAG,__VA_ARGS__) 
+	 #define LOGI(...)  __android_log_print(ANDROID_LOG_INFO,LOG_TAG,__VA_ARGS__) 
+	 #define LOGW(...)  __android_log_print(ANDROID_LOG_WARN,LOG_TAG,__VA_ARGS__)    
+	 #define LOGF(...)  __android_log_print(ANDROID_LOG_FATAL,LOG_TAG,__VA_ARGS__) 
+	 #define LOGV(...)  __android_log_print(ANDROID_LOG_VERBOSE,LOG_TAG,__VA_ARGS__) 
+#else
+	 #define LOGE(...)  __android_log_print(ANDROID_LOG_ERROR,LOG_TAG,__VA_ARGS__)
+	 #define LOGD(...)
+	 #define LOGI(...)
+	 #define LOGW(...)
+	 #define LOGF(...)
+	 #define LOGV(...)
+#endif
+
+class CameraList
+{
+public:
+	CameraList();
+	~CameraList();
+	char mCameraDeviceList[KEY_LIST_LENGTH];
+
+private:
+	bool readKey(char *key, char *value);
+	void getValue(char *line, char *value);
+	bool usedKey(char *value);
+
+	FILE * mhKeyFile;
+
+};
+
+#endif // __CAMERA_LIST_H__
diff --git a/hardware/camera/CameraPlatform.h b/hardware/camera/CameraPlatform.h
deleted file mode 100755
index df20529..0000000
--- a/hardware/camera/CameraPlatform.h
+++ /dev/null
@@ -1,112 +0,0 @@
-#ifndef __HAL_CAMERA_PLATFORM_H__
-#define __HAL_CAMERA_PLATFORM_H_
-
-
-
-#ifdef __A80__
-#define __PLATFORM_A80__
-#define BUFFER_PHY_OFFSET 0
-#define GPU_BUFFER_ALIGN
-
-//#define __OPEN_FACEDECTION__
-//#define __OPEN_SMILEDECTION__
-//#define __OPEN_BLINKDECTION__
-//#define __OPEN_APPERCEIVEPEOPLE__
-
-#define __CEDARX_FRAMEWORK_2__
-
-#define USE_ION_MEM_ALLOCATOR
-#endif
-
-#ifdef __A83__
-#define __PLATFORM_A83__
-#define BUFFER_PHY_OFFSET 0
-#define GPU_BUFFER_ALIGN ALIGN_4K
-
-#define __CEDARX_FRAMEWORK_2__
-
-#define __OPEN_FACEDECTION__
-#define __OPEN_SMILEDECTION__
-#define __OPEN_SMARTDECTION__
-//#define __OPEN_BLINKDECTION__
-
-
-#define USE_ION_MEM_ALLOCATOR
-#define WATI_FACEDETECT
-#endif
-
-#ifdef __A33__
-#define __PLATFORM_A33__
-#define BUFFER_PHY_OFFSET 0
-#define GPU_BUFFER_ALIGN
-
-#define __CEDARX_FRAMEWORK_2__
-
-//#define __OPEN_FACEDECTION__
-//#define __OPEN_SMILEDECTION__
-//#define __OPEN_SMARTDECTION__
-//#define __OPEN_BLINKDECTION__
-
-
-#define USE_ION_MEM_ALLOCATOR
-//#define WATI_FACEDETECT
-#endif
-
-#ifdef __A64__
-#define __PLATFORM_A64__
-#define BUFFER_PHY_OFFSET 0
-#define GPU_BUFFER_ALIGN
-
-#define __CEDARX_FRAMEWORK_2__
-
-//#define __OPEN_FACEDECTION__
-//#define __OPEN_SMILEDECTION__
-//#define __OPEN_SMARTDECTION__
-//#define __OPEN_BLINKDECTION__
-
-
-#define USE_ION_MEM_ALLOCATOR
-//#define WATI_FACEDETECT
-#endif
-
-
-#ifdef USE_ION_MEM_ALLOCATOR
-extern "C" int ion_alloc_open();
-extern "C" int ion_alloc_close();
-extern "C" int ion_alloc_alloc(int size);
-extern "C" void ion_alloc_free(void * pbuf);
-extern "C" int ion_alloc_vir2phy(void * pbuf);
-extern "C" int ion_alloc_phy2vir(void * pbuf);
-extern "C" void ion_flush_cache(void* startAddr, int size);
-extern "C" void ion_flush_cache_all();
-
-#define camera_phy_alloc_open()      ion_alloc_open() 
-#define camera_phy_alloc_close()     ion_alloc_close()
-#define camera_phy_alloc_alloc(x)    ion_alloc_alloc(x)
-#define camera_phy_alloc_free(x)     ion_alloc_free(x)
-#define camera_phy_alloc_vir2phy(x)  ion_alloc_vir2phy(x)
-#define camera_phy_alloc_phy2vir(x)  ion_alloc_phy2vir(x)
-#define camera_phy_flush_cache(x,y)  ion_flush_cache(x,y)
-#define camera_phy_flush_cache_all() ion_flush_cache_all
- 
-#elif USE_SUNXI_MEM_ALLOCATOR
-extern "C" int sunxi_alloc_open();
-extern "C" int sunxi_alloc_close();
-extern "C" int sunxi_alloc_alloc(int size);
-extern "C" void sunxi_alloc_free(void * pbuf);
-extern "C" int sunxi_alloc_vir2phy(void * pbuf);
-extern "C" int sunxi_alloc_phy2vir(void * pbuf);
-extern "C" void sunxi_flush_cache(void * startAddr, int size);
-extern "C" void sunxi_flush_cache_all();
-
-#define camera_phy_alloc_open        sunxi_alloc_open() 
-#define camera_phy_alloc_close       sunxi_alloc_close()
-#define camera_phy_alloc_alloc(x)    sunxi_alloc_alloc(x)
-#define camera_phy_alloc_free(x)     sunxi_alloc_free(x)
-#define camera_phy_alloc_vir2phy(x)  sunxi_alloc_vir2phy(x)
-#define camera_phy_alloc_phy2vir(x)  int sunxi_alloc_phy2vir(x);
-#define camera_phy_flush_cache(x,y)  sunxi_flush_cache(x,y);
-#define camera_phy_flush_cache_all() sunxi_flush_cache_all()
-#endif
-
-#endif
diff --git a/hardware/camera/HALCameraFactory.cpp b/hardware/camera/HALCameraFactory.cpp
index d9ab2f6..ab2c361 100755
--- a/hardware/camera/HALCameraFactory.cpp
+++ b/hardware/camera/HALCameraFactory.cpp
@@ -60,8 +60,7 @@ HALCameraFactory::HALCameraFactory()
 	F_LOG;
 
 	LOGD("camera hal version: %s", CAMERA_HAL_VERSION);
-
-	memset(&mHalCameraInfo,0,sizeof(mHalCameraInfo));
+	memset(&mHalCameraInfo, 0, MAX_NUM_OF_CAMERAS * sizeof(mHalCameraInfo));
 
     /* Make sure that array is allocated. */
     if (mHardwareCameras == NULL) {
@@ -170,7 +169,7 @@ int HALCameraFactory::getCameraHardwareNum()
 			mHalCameraInfo[i].device_id		= mCameraConfig[i]->getDeviceID();
 			mHalCameraInfo[i].facing		= mCameraConfig[i]->cameraFacing();
 			mHalCameraInfo[i].orientation	= mCameraConfig[i]->getCameraOrientation();
-			mHalCameraInfo[i].fast_picture_mode	= mCameraConfig[i]->supportFastPictureMode();
+			mHalCameraInfo[i].fast_picture_mode	= false;//mCameraConfig[i]->supportFastPictureMode();
 			mHalCameraInfo[i].is_uvc		= false;
 		}
 	}
@@ -181,7 +180,7 @@ int HALCameraFactory::getCameraHardwareNum()
 		mHalCameraInfo[0].device_id		= mCameraConfig[0]->getDeviceID();
 		mHalCameraInfo[0].facing		= mCameraConfig[0]->cameraFacing();
 		mHalCameraInfo[0].orientation	= mCameraConfig[0]->getCameraOrientation();
-		mHalCameraInfo[0].fast_picture_mode	= mCameraConfig[0]->supportFastPictureMode();
+		mHalCameraInfo[0].fast_picture_mode	= false;//mCameraConfig[0]->supportFastPictureMode();
 		mHalCameraInfo[0].is_uvc		= false;
 
 		// There may be another USB camera. Then, the device node would be "/dev/video0" or "/dev/video1".
@@ -222,7 +221,7 @@ int HALCameraFactory::getCameraHardwareNum()
 		
 		if (mRemovableCamerasNum == 1)
 		{
-			mHalCameraInfo[0].facing		= CAMERA_FACING_FRONT;
+			mHalCameraInfo[0].facing		= CAMERA_FACING_BACK;
 			mHalCameraInfo[0].orientation	= orientation;
 			mHalCameraInfo[0].fast_picture_mode	= false;
 			mHalCameraInfo[0].is_uvc		= true;
@@ -253,7 +252,7 @@ int HALCameraFactory::getCameraHardwareNum()
 
 int HALCameraFactory::getCameraInfo(int camera_id, struct camera_info* info)
 {
-    //LOGV("%s: id = %d", __FUNCTION__, camera_id);
+    LOGV("%s: id = %d", __FUNCTION__, camera_id);
 
 	int total_num_of_cameras = mAttachedCamerasNum + mRemovableCamerasNum;
 	char calling_process[256];
@@ -271,7 +270,6 @@ int HALCameraFactory::getCameraInfo(int camera_id, struct camera_info* info)
 
 	info->orientation	= mHalCameraInfo[camera_id].orientation;
 	info->facing		= mHalCameraInfo[camera_id].facing;
-	info->static_camera_characteristics = NULL;
 
 	// single camera
 	if (total_num_of_cameras == 1)
@@ -342,7 +340,7 @@ int HALCameraFactory::cameraDeviceOpen(int camera_id, hw_device_t** device)
 	if (mHardwareCameras[camera_id]->connectCamera(device) != NO_ERROR)
 	{
 		LOGE("%s: Unable to connect camera", __FUNCTION__);
-		return -EUSERS;
+		return -EINVAL;
 	}
 	
 	if (mHardwareCameras[camera_id]->Initialize() != NO_ERROR) 
diff --git a/hardware/camera/Libve_Decoder.c b/hardware/camera/Libve_Decoder.c
new file mode 100755
index 0000000..79f27ef
--- /dev/null
+++ b/hardware/camera/Libve_Decoder.c
@@ -0,0 +1,1437 @@
+#include "Libve_Decoder.h"
+//#include <CDX_Debug.h>
+#define LOG_TAG    "Libev_decorder"
+#include<android/log.h>
+#include <stdio.h>
+#include <time.h>
+
+#define USE_ION_MEM_ALLOCATOR
+
+#if  DBG_ENABLE
+     #define LOGE(...)  __android_log_print(ANDROID_LOG_ERROR,LOG_TAG,__VA_ARGS__)
+     #define LOGD(...)  __android_log_print(ANDROID_LOG_DEBUG,LOG_TAG,__VA_ARGS__)
+     #define LOGI(...)  __android_log_print(ANDROID_LOG_INFO,LOG_TAG,__VA_ARGS__)
+     #define LOGW(...)  __android_log_print(ANDROID_LOG_WARN,LOG_TAG,__VA_ARGS__)
+     #define LOGF(...)  __android_log_print(ANDROID_LOG_FATAL,LOG_TAG,__VA_ARGS__)
+     #define LOGV(...)  __android_log_print(ANDROID_LOG_VERBOSE,LOG_TAG,__VA_ARGS__)
+#else
+     #define LOGE(...)  __android_log_print(ANDROID_LOG_ERROR,LOG_TAG,__VA_ARGS__)
+     #define LOGD(...)
+     #define LOGI(...)
+     #define LOGW(...)
+     #define LOGF(...)
+     #define LOGV(...)
+#endif
+
+#ifdef USE_ION_MEM_ALLOCATOR
+extern int ion_alloc_open();
+extern int ion_alloc_close();
+extern int ion_alloc_alloc(int size);
+extern void ion_alloc_free(void * pbuf);
+extern int ion_alloc_vir2phy(void * pbuf);
+extern int ion_alloc_phy2vir(void * pbuf);
+extern void ion_flush_cache(void* startAddr, int size);
+extern void ion_flush_cache_all();
+
+
+#else USE_SUNXI_MEM_ALLOCATOR
+extern  int sunxi_alloc_open();
+extern int sunxi_alloc_close();
+extern int sunxi_alloc_alloc(int size);
+extern  void sunxi_alloc_free(void * pbuf);
+extern  int sunxi_alloc_vir2phy(void * pbuf);
+extern  int sunxi_alloc_phy2vir(void * pbuf);
+extern  void sunxi_flush_cache(void* startAddr, int size);
+extern  void sunxi_flush_cache_all();
+
+#endif
+
+
+static long long GetNowUs() {
+    struct timeval tv;
+    gettimeofday(&tv, NULL);
+
+    return (long long)tv.tv_sec * 1000000ll + tv.tv_usec;
+}
+
+static void savefile(char *addr,void *p,int length)
+{
+    int fd;
+    fd = open(addr,O_CREAT|O_RDWR|O_TRUNC,0);
+    if(!fd) {
+        LOGD("Open file error");
+        //return false;
+    }
+    if(write(fd,p,length))  {
+        LOGD("write file successfully");
+        close(fd);
+        //return true;
+    }
+    else {
+        LOGD("write file fail");
+        close(fd);
+        //return false;
+    }
+
+}
+/*
+//convert MB to yv12  by DE
+int HardwarePictureScaler(ScalerParameter *cdx_scaler_para,__disp_pixel_fmt_t informat)
+{
+    unsigned long arg[4] = {0,0,0,0};
+    int scaler_hdl;
+    __disp_scaler_para_t scaler_para;
+    int dispfh;
+
+    dispfh = open("/dev/disp", O_RDWR);
+    if(dispfh == -1){
+        LOGE("Open /dev/disp fail");
+        return -1;
+    }
+
+    scaler_hdl = ioctl(dispfh, DISP_CMD_SCALER_REQUEST, (unsigned long) arg);
+    if(scaler_hdl == -1){
+        LOGE("request scaler fail");
+        return -1;
+    }
+
+    memset(&scaler_para, 0, sizeof(__disp_scaler_para_t));
+    scaler_para.input_fb.addr[0] = (unsigned int)cdx_scaler_para->addr_y_in;//
+    scaler_para.input_fb.addr[1] = (unsigned int)cdx_scaler_para->addr_c_in;//
+    scaler_para.input_fb.size.width = cdx_scaler_para->width_in;//
+    scaler_para.input_fb.size.height = cdx_scaler_para->height_in;//
+    scaler_para.input_fb.format =  informat;
+    scaler_para.input_fb.seq = DISP_SEQ_UVUV;
+    scaler_para.input_fb.mode = DISP_MOD_MB_UV_COMBINED;
+    scaler_para.input_fb.br_swap = 0;
+    scaler_para.input_fb.cs_mode = DISP_BT601;
+    scaler_para.source_regn.x = 0;
+    scaler_para.source_regn.y = 0;
+    scaler_para.source_regn.width = cdx_scaler_para->width_in;//
+    scaler_para.source_regn.height = cdx_scaler_para->height_in;//
+    scaler_para.output_fb.addr[0] = cdx_scaler_para->addr_y_out;//
+    scaler_para.output_fb.addr[1] = cdx_scaler_para->addr_u_out;//
+    scaler_para.output_fb.addr[2] = cdx_scaler_para->addr_v_out;//
+    scaler_para.output_fb.size.width = cdx_scaler_para->width_out;//
+    scaler_para.output_fb.size.height = cdx_scaler_para->height_out;//
+    scaler_para.output_fb.format = DISP_FORMAT_YUV420;
+    scaler_para.output_fb.seq = DISP_SEQ_P3210;
+    scaler_para.output_fb.mode = DISP_MOD_NON_MB_PLANAR;
+    scaler_para.output_fb.br_swap = 0;
+    scaler_para.output_fb.cs_mode = DISP_BT601;
+
+    LOGV( "scaler parameter check: w:%d h:%d y_in:0x%x c_in:0x%x out_0:0x%x out_1:0x%x out_2:0x%x format:0x%x",
+            cdx_scaler_para->width_in,cdx_scaler_para->height_in,cdx_scaler_para->addr_y_in,cdx_scaler_para->addr_c_in,
+            scaler_para.output_fb.addr[0],scaler_para.output_fb.addr[1],scaler_para.output_fb.addr[2],scaler_para.output_fb.format);
+
+    arg[1] = scaler_hdl;
+    arg[2] = (unsigned long) &scaler_para;
+    ioctl(dispfh, DISP_CMD_SCALER_EXECUTE, (unsigned long) arg);
+
+    arg[1] = scaler_hdl;
+    ioctl(dispfh, DISP_CMD_SCALER_RELEASE, (unsigned long) arg);
+
+    close(dispfh);
+
+    return 0;
+}
+*/
+
+static void YUYVToNV12(const void* y,const void *u, void *nv12, int width, int height)
+{
+    int i,j;
+    int phy;
+    u8* Y   = (u8*)nv12;
+    u8* UV  = (u8*)Y + width * height;
+    u8* yuyv    =(u8*)malloc(2*width * height*sizeof(u8));
+
+    memset(yuyv,0,2*width * height);
+    memcpy(nv12,y,width * height);
+    memcpy(yuyv+width * height,u,width * height);
+
+    for(i = 0; i < height; i += 2)
+    {
+        for (j = 0; j < width; j++)
+        {
+            *(uint8_t*)((uint8_t*)Y + i * width + j) = *(uint8_t*)((uint8_t*)yuyv + i * width * 2 + j * 2);
+            *(uint8_t*)((uint8_t*)Y + (i + 1) * width + j) = *(uint8_t*)((uint8_t*)yuyv + (i + 1) * width * 2 + j * 2);
+            *(uint8_t*)((uint8_t*)UV + ((i * width) >> 1) + j) = *(uint8_t*)((uint8_t*)yuyv + i * width * 2 + j * 2 + 1);
+        }
+    }
+    free(yuyv);
+}
+
+//convert MB32*32  to  yuv 
+static void map32x32_to_yuv(unsigned char* srcY, unsigned char* tarY,unsigned int coded_width,unsigned int coded_height)
+{
+    unsigned int i,j,l,m,n;
+    unsigned int mb_width,mb_height,twomb_line, twomb_width, recon_width;
+    unsigned long offset;
+    unsigned char *ptr;
+    unsigned char *dst_asm,*src_asm;
+    unsigned vdecbuf_width, vdecbuf_height;
+    int nWidthMatchFlag;
+    int nLeftValidLine;  //in the bottom macroblock(32*32), the valid line is < 32.
+    ptr = srcY;
+//  mb_width = (coded_width+15)>>4;
+//  mb_height = (coded_height+15)>>4;
+//  twomb_line = (mb_height+1)>>1;
+//  recon_width = (mb_width+1)&0xfffffffe;
+
+    mb_width = ((coded_width+31)&~31) >>4;
+    mb_height = ((coded_height+31)&~31) >>4;
+    twomb_line = (mb_height+1)>>1;
+    recon_width = (mb_width+1)&0xfffffffe;
+    twomb_width = (mb_width+1)>>1;
+    if(twomb_line < 1 || twomb_width < 1)
+    {
+        LOGE("fatal error! twomb_line=%d, twomb_width=%d", twomb_line, twomb_width);
+    }
+    vdecbuf_width = twomb_width*32;
+    vdecbuf_height = twomb_line*32;
+    if(vdecbuf_width > coded_width)
+    {
+        nWidthMatchFlag = 0;
+        if((vdecbuf_width - coded_width) != 16)
+        {
+            LOGW("(f:%s, l:%d) fatal error! vdecbuf_width=%d, gpubuf_width=%d,  the program will crash!", __FUNCTION__, __LINE__, vdecbuf_width, coded_width);
+        }
+        else
+        {
+            //LOGV("(f:%s, l:%d) Be careful! vdecbuf_width=%d, gpubuf_width=%d", __FUNCTION__, __LINE__, vdecbuf_width, coded_width);
+        }
+    }
+    else if(vdecbuf_width == coded_width)
+    {
+        nWidthMatchFlag = 1;
+    }
+    else
+    {
+        LOGW("(f:%s, l:%d) fatal error! vdecbuf_width=%d <= gpubuf_width=%d, the program will crash!", __FUNCTION__, __LINE__, vdecbuf_width, coded_width);
+        nWidthMatchFlag = 0;
+    }
+    for(i=0;i<twomb_line-1;i++)   //twomb line number
+    {
+        for(j=0;j<twomb_width-1;j++)   //macroblock(32*32) number in one line
+        {
+            for(l=0;l<32;l++)
+            {
+                //first mb
+                m=i*32 + l;     //line num
+                n= j*32;        //byte num in one line
+                offset = m*coded_width + n;
+                //memcpy(tarY+offset,ptr,32);
+                dst_asm = tarY+offset;
+                src_asm = ptr;
+                asm volatile (
+                        "vld1.8         {d0 - d3}, [%[src_asm]]              \n\t"
+                        "vst1.8         {d0 - d3}, [%[dst_asm]]              \n\t"
+                        : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                        :  //[srcY] "r" (srcY)
+                        : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                        );
+
+                ptr += 32;  //32 byte in one process.
+            }
+        }
+        //process last macroblock of one line, gpu buf must be 16byte align or 32 byte align
+        { //last mb of one line
+            for(l=0;l<32;l++)
+            {
+                //first mb
+                m=i*32 + l;     //line num
+                n= j*32;        //byte num in one line
+                offset = m*coded_width + n;
+                //memcpy(tarY+offset,ptr,32);
+                dst_asm = tarY+offset;
+                src_asm = ptr;
+                if(nWidthMatchFlag)
+                {
+                    asm volatile (
+                            "vld1.8         {d0 - d3}, [%[src_asm]]              \n\t"
+                            "vst1.8         {d0 - d3}, [%[dst_asm]]              \n\t"
+                            : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                            :  //[srcY] "r" (srcY)
+                            : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                            );
+                }
+                else
+                {
+                    asm volatile (
+                            "vld1.8         {d0,d1}, [%[src_asm]]              \n\t"
+                            "vst1.8         {d0,d1}, [%[dst_asm]]              \n\t"
+                            : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                            :  //[srcY] "r" (srcY)
+                            : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                            );
+                }
+
+                ptr += 32;  //32 byte in one process.
+            }
+        }
+    }
+    //last twomb line, we process it alone
+    nLeftValidLine = coded_height - (twomb_line-1)*32;
+    if(nLeftValidLine!=32)
+    {
+        //LOGV("(f:%s, l:%d)hehehaha,gpuBufHeight[%d] is not 32 align", __FUNCTION__, __LINE__, nLeftValidLine);
+    }
+    for(j=0;j<twomb_width-1;j++)   //macroblock(32*32) number in one line
+    {
+        for(l=0;l<nLeftValidLine;l++)
+        {
+            //first mb
+            m=i*32 + l;     //line num
+            n= j*32;        //byte num in one line
+            offset = m*coded_width + n;
+            //memcpy(tarY+offset,ptr,32);
+            dst_asm = tarY+offset;
+            src_asm = ptr;
+            asm volatile (
+                    "vld1.8         {d0 - d3}, [%[src_asm]]              \n\t"
+                    "vst1.8         {d0 - d3}, [%[dst_asm]]              \n\t"
+                    : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                    :  //[srcY] "r" (srcY)
+                    : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                    );
+
+            ptr += 32;  //32 byte in one process.
+        }
+        ptr += (32-nLeftValidLine)*32;
+    }
+    //process last macroblock of last line, gpu buf must be 16byte align or 32 byte align
+    { //last mb of last line
+        for(l=0;l<nLeftValidLine;l++)
+        {
+            //first mb
+            m=i*32 + l;     //line num
+            n= j*32;        //byte num in one line
+            offset = m*coded_width + n;
+            //memcpy(tarY+offset,ptr,32);
+            dst_asm = tarY+offset;
+            src_asm = ptr;
+            if(nWidthMatchFlag)
+            {
+                asm volatile (
+                        "vld1.8         {d0 - d3}, [%[src_asm]]              \n\t"
+                        "vst1.8         {d0 - d3}, [%[dst_asm]]              \n\t"
+                        : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                        :  //[srcY] "r" (srcY)
+                        : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                        );
+            }
+            else
+            {
+                asm volatile (
+                        "vld1.8         {d0,d1}, [%[src_asm]]              \n\t"
+                        "vst1.8         {d0,d1}, [%[dst_asm]]              \n\t"
+                        : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                        :  //[srcY] "r" (srcY)
+                        : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                        );
+            }
+
+            ptr += 32;  //32 byte in one process.
+        }
+        ptr += (32-nLeftValidLine)*32;
+    }
+}
+
+static void map32x32_to_yuv_nv21(unsigned char* srcY, unsigned char* tarY,unsigned int coded_width,unsigned int coded_height)
+{
+    unsigned int i,j,l,m,n;
+    unsigned int mb_width,mb_height,twomb_line, twomb_width, recon_width;
+    unsigned long offset;
+    unsigned char *ptr;
+    unsigned char *dst_asm,*src_asm;
+    unsigned vdecbuf_width, vdecbuf_height;
+    int nWidthMatchFlag;
+    int nLeftValidLine;  //in the bottom macroblock(32*32), the valid line is < 32.
+    ptr = srcY;
+//  mb_width = (coded_width+15)>>4;
+//  mb_height = (coded_height+15)>>4;
+//  twomb_line = (mb_height+1)>>1;
+//  recon_width = (mb_width+1)&0xfffffffe;
+
+    mb_width = ((coded_width+31)&~31) >>4;
+    mb_height = ((coded_height+31)&~31) >>4;
+    twomb_line = (mb_height+1)>>1;
+    recon_width = (mb_width+1)&0xfffffffe;
+    twomb_width = (mb_width+1)>>1;
+    if(twomb_line < 1 || twomb_width < 1)
+    {
+        LOGE("fatal error! twomb_line=%d, twomb_width=%d", twomb_line, twomb_width);
+    }
+    vdecbuf_width = twomb_width*32;
+    vdecbuf_height = twomb_line*32;
+    if(vdecbuf_width > coded_width)
+    {
+        nWidthMatchFlag = 0;
+        if((vdecbuf_width - coded_width) != 16)
+        {
+            LOGW("(f:%s, l:%d) fatal error! vdecbuf_width=%d, gpubuf_width=%d,  the program will crash!", __FUNCTION__, __LINE__, vdecbuf_width, coded_width);
+        }
+        else
+        {
+            //LOGV("(f:%s, l:%d) Be careful! vdecbuf_width=%d, gpubuf_width=%d", __FUNCTION__, __LINE__, vdecbuf_width, coded_width);
+        }
+    }
+    else if(vdecbuf_width == coded_width)
+    {
+        nWidthMatchFlag = 1;
+    }
+    else
+    {
+        LOGW("(f:%s, l:%d) fatal error! vdecbuf_width=%d <= gpubuf_width=%d, the program will crash!", __FUNCTION__, __LINE__, vdecbuf_width, coded_width);
+        nWidthMatchFlag = 0;
+    }
+    for(i=0;i<twomb_line-1;i++)   //twomb line number
+    {
+        for(j=0;j<twomb_width-1;j++)   //macroblock(32*32) number in one line
+        {
+            for(l=0;l<32;l++)
+            {
+                //first mb
+                m=i*32 + l;     //line num
+                n= j*32;        //byte num in one line
+                offset = m*coded_width + n;
+                //memcpy(tarY+offset,ptr,32);
+                dst_asm = tarY+offset;
+                src_asm = ptr;
+                asm volatile (
+/*                      "vld1.8         {d0 - d3}, [%[src_asm]]              \n\t"
+                        "vst1.8         {d0 - d3}, [%[dst_asm]]              \n\t"
+*/
+                    "vld2.8         {d0 - d1}, [%[src_asm]]!              \n\t"
+                    "vld2.8         {d2 - d3}, [%[src_asm]]               \n\t"
+                    "vswp           d0, d1                                \n\t"
+                    "vswp           d2, d3                                \n\t"
+                    "vst2.8         {d0 - d1}, [%[dst_asm]]!              \n\t"
+                    "vst2.8         {d2 - d3}, [%[dst_asm]]               \n\t"
+
+                        : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                        :  //[srcY] "r" (srcY)
+                        : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                        );
+
+                ptr += 32;  //32 byte in one process.
+            }
+        }
+        //process last macroblock of one line, gpu buf must be 16byte align or 32 byte align
+        { //last mb of one line
+            for(l=0;l<32;l++)
+            {
+                //first mb
+                m=i*32 + l;     //line num
+                n= j*32;        //byte num in one line
+                offset = m*coded_width + n;
+                //memcpy(tarY+offset,ptr,32);
+                dst_asm = tarY+offset;
+                src_asm = ptr;
+                if(nWidthMatchFlag)
+                {
+                    asm volatile (
+//                          "vld1.8         {d0 - d3}, [%[src_asm]]              \n\t"
+//                          "vst1.8         {d0 - d3}, [%[dst_asm]]              \n\t"
+                    "vld2.8         {d0 - d1}, [%[src_asm]]!              \n\t"
+                    "vld2.8         {d2 - d3}, [%[src_asm]]               \n\t"
+                    "vswp           d0, d1                                \n\t"
+                    "vswp           d2, d3                                \n\t"
+                    "vst2.8         {d0 - d1}, [%[dst_asm]]!              \n\t"
+                    "vst2.8         {d2 - d3}, [%[dst_asm]]               \n\t"
+
+                            : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                            :  //[srcY] "r" (srcY)
+                            : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                            );
+                }
+                else
+                {
+                    asm volatile (
+                            "vld1.8         {d0,d1}, [%[src_asm]]              \n\t"
+                            "vst1.8         {d0,d1}, [%[dst_asm]]              \n\t"
+                            : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                            :  //[srcY] "r" (srcY)
+                            : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                            );
+                }
+
+                ptr += 32;  //32 byte in one process.
+            }
+        }
+    }
+    //last twomb line, we process it alone
+    nLeftValidLine = coded_height - (twomb_line-1)*32;
+    if(nLeftValidLine!=32)
+    {
+        //LOGV("(f:%s, l:%d)hehehaha,gpuBufHeight[%d] is not 32 align", __FUNCTION__, __LINE__, nLeftValidLine);
+    }
+    for(j=0;j<twomb_width-1;j++)   //macroblock(32*32) number in one line
+    {
+        for(l=0;l<nLeftValidLine;l++)
+        {
+            //first mb
+            m=i*32 + l;     //line num
+            n= j*32;        //byte num in one line
+            offset = m*coded_width + n;
+            //memcpy(tarY+offset,ptr,32);
+            dst_asm = tarY+offset;
+            src_asm = ptr;
+            asm volatile (
+//                  "vld1.8         {d0 - d3}, [%[src_asm]]              \n\t"
+//                  "vst1.8         {d0 - d3}, [%[dst_asm]]              \n\t"
+            "vld2.8         {d0 - d1}, [%[src_asm]]!              \n\t"
+            "vld2.8         {d2 - d3}, [%[src_asm]]               \n\t"
+            "vswp           d0, d1                                \n\t"
+            "vswp           d2, d3                                \n\t"
+            "vst2.8         {d0 - d1}, [%[dst_asm]]!              \n\t"
+            "vst2.8         {d2 - d3}, [%[dst_asm]]               \n\t"
+
+                    : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                    :  //[srcY] "r" (srcY)
+                    : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                    );
+
+            ptr += 32;  //32 byte in one process.
+        }
+        ptr += (32-nLeftValidLine)*32;
+    }
+    //process last macroblock of last line, gpu buf must be 16byte align or 32 byte align
+    { //last mb of last line
+        for(l=0;l<nLeftValidLine;l++)
+        {
+            //first mb
+            m=i*32 + l;     //line num
+            n= j*32;        //byte num in one line
+            offset = m*coded_width + n;
+            //memcpy(tarY+offset,ptr,32);
+            dst_asm = tarY+offset;
+            src_asm = ptr;
+            if(nWidthMatchFlag)
+            {
+                asm volatile (
+//                      "vld1.8         {d0 - d3}, [%[src_asm]]              \n\t"
+//                      "vst1.8         {d0 - d3}, [%[dst_asm]]              \n\t"
+                "vld2.8         {d0 - d1}, [%[src_asm]]!              \n\t"
+                "vld2.8         {d2 - d3}, [%[src_asm]]               \n\t"
+                "vswp           d0, d1                                \n\t"
+                "vswp           d2, d3                                \n\t"
+                "vst2.8         {d0 - d1}, [%[dst_asm]]!              \n\t"
+                "vst2.8         {d2 - d3}, [%[dst_asm]]               \n\t"
+
+                        : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                        :  //[srcY] "r" (srcY)
+                        : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                        );
+            }
+            else
+            {
+                asm volatile (
+                        "vld1.8         {d0,d1}, [%[src_asm]]              \n\t"
+                        "vst1.8         {d0,d1}, [%[dst_asm]]              \n\t"
+                        : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                        :  //[srcY] "r" (srcY)
+                        : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                        );
+            }
+
+            ptr += 32;  //32 byte in one process.
+        }
+        ptr += (32-nLeftValidLine)*32;
+    }
+}
+
+static void map32x32_to_yuv_skip_oneline(unsigned char* srcY, unsigned char* tarY,unsigned int coded_width,unsigned int coded_height)
+{
+    unsigned int i,j,l,m,n;
+    unsigned int mb_width,mb_height,twomb_line, twomb_width, recon_width;
+    unsigned long offset;
+    unsigned char *ptr;
+    unsigned char *dst_asm,*src_asm;
+    unsigned vdecbuf_width, vdecbuf_height;
+    int nWidthMatchFlag;
+    int nLeftValidLine;  //in the bottom macroblock(32*32), the valid line is < 32.
+    ptr = srcY;
+//  mb_width = (coded_width+15)>>4;
+//  mb_height = (coded_height+15)>>4;
+//  twomb_line = (mb_height+1)>>1;
+//  recon_width = (mb_width+1)&0xfffffffe;
+
+    mb_width = ((coded_width+31)&~31) >>4;
+    mb_height = ((coded_height+31)&~31) >>4;
+    twomb_line = (mb_height+1)>>1;
+    recon_width = (mb_width+1)&0xfffffffe;
+    twomb_width = (mb_width+1)>>1;
+    if(twomb_line < 1 || twomb_width < 1)
+    {
+        LOGE("fatal error! twomb_line=%d, twomb_width=%d", twomb_line, twomb_width);
+    }
+    vdecbuf_width = twomb_width*32;
+    vdecbuf_height = twomb_line*32;
+    if(vdecbuf_width > coded_width)
+    {
+        nWidthMatchFlag = 0;
+        if((vdecbuf_width - coded_width) != 16)
+        {
+            LOGW("(f:%s, l:%d) fatal error! vdecbuf_width=%d, gpubuf_width=%d,  the program will crash!", __FUNCTION__, __LINE__, vdecbuf_width, coded_width);
+        }
+        else
+        {
+            //LOGV("(f:%s, l:%d) Be careful! vdecbuf_width=%d, gpubuf_width=%d", __FUNCTION__, __LINE__, vdecbuf_width, coded_width);
+        }
+    }
+    else if(vdecbuf_width == coded_width)
+    {
+        nWidthMatchFlag = 1;
+    }
+    else
+    {
+        LOGW("(f:%s, l:%d) fatal error! vdecbuf_width=%d <= gpubuf_width=%d, the program will crash!", __FUNCTION__, __LINE__, vdecbuf_width, coded_width);
+        nWidthMatchFlag = 0;
+    }
+    for(i=0;i<twomb_line-1;i++)   //twomb line number
+    {
+        for(j=0;j<twomb_width-1;j++)   //macroblock(32*32) number in one line
+        {
+            for(l=0;l<16;l++)
+            {
+                //first mb
+                m=i*16 + l;     //line num,skip oneline
+                n= j*32;        //byte num in one line
+                offset = m*coded_width + n;
+                //memcpy(tarY+offset,ptr,32);
+                dst_asm = tarY+offset;
+                src_asm = ptr;
+                asm volatile (
+                        "vld1.8         {d0 - d3}, [%[src_asm]]              \n\t"
+                        "vst1.8         {d0 - d3}, [%[dst_asm]]              \n\t"
+                        : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                        :  //[srcY] "r" (srcY)
+                        : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                        );
+
+                ptr += 32;  //32 byte in one process.
+                ptr += 32;  //32 byte in one process.
+            }
+        }
+        //process last macroblock of one line, gpu buf must be 16byte align or 32 byte align
+        { //last mb of one line
+            for(l=0;l<16;l++)
+            {
+                //first mb
+                m=i*16 + l;     //line num
+                n= j*32;        //byte num in one line
+                offset = m*coded_width + n;
+                //memcpy(tarY+offset,ptr,32);
+                dst_asm = tarY+offset;
+                src_asm = ptr;
+                if(nWidthMatchFlag)
+                {
+                    asm volatile (
+                            "vld1.8         {d0 - d3}, [%[src_asm]]              \n\t"
+                            "vst1.8         {d0 - d3}, [%[dst_asm]]              \n\t"
+                            : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                            :  //[srcY] "r" (srcY)
+                            : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                            );
+                }
+                else
+                {
+                    asm volatile (
+                            "vld1.8         {d0,d1}, [%[src_asm]]              \n\t"
+                            "vst1.8         {d0,d1}, [%[dst_asm]]              \n\t"
+                            : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                            :  //[srcY] "r" (srcY)
+                            : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                            );
+                }
+
+                ptr += 32;  //32 byte in one process.
+                ptr += 32;  //32 byte in one process.
+            }
+        }
+    }
+    //last twomb line, we process it alone
+    nLeftValidLine = coded_height - (twomb_line-1)*32;
+    if(nLeftValidLine!=32)
+    {
+        //LOGV("(f:%s, l:%d)hehehaha,gpuBufHeight[%d] is not 32 align", __FUNCTION__, __LINE__, nLeftValidLine);
+    }
+    for(j=0;j<twomb_width-1;j++)   //macroblock(32*32) number in one line
+    {
+        for(l=0;l<nLeftValidLine/2;l++)
+        {
+            //first mb
+            m=i*16 + l;     //line num
+            n= j*32;        //byte num in one line
+            offset = m*coded_width + n;
+            //memcpy(tarY+offset,ptr,32);
+            dst_asm = tarY+offset;
+            src_asm = ptr;
+            asm volatile (
+                    "vld1.8         {d0 - d3}, [%[src_asm]]              \n\t"
+                    "vst1.8         {d0 - d3}, [%[dst_asm]]              \n\t"
+                    : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                    :  //[srcY] "r" (srcY)
+                    : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                    );
+
+            ptr += 32;  //32 byte in one process.
+            ptr += 32;  //32 byte in one process.
+        }
+        ptr += (32-nLeftValidLine)*32;
+    }
+    //process last macroblock of last line, gpu buf must be 16byte align or 32 byte align
+    { //last mb of last line
+        for(l=0;l<nLeftValidLine/2;l++)
+        {
+            //first mb
+            m=i*16 + l;     //line num
+            n= j*32;        //byte num in one line
+            offset = m*coded_width + n;
+            //memcpy(tarY+offset,ptr,32);
+            dst_asm = tarY+offset;
+            src_asm = ptr;
+            if(nWidthMatchFlag)
+            {
+                asm volatile (
+                        "vld1.8         {d0 - d3}, [%[src_asm]]              \n\t"
+                        "vst1.8         {d0 - d3}, [%[dst_asm]]              \n\t"
+                        : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                        :  //[srcY] "r" (srcY)
+                        : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                        );
+            }
+            else
+            {
+                asm volatile (
+                        "vld1.8         {d0,d1}, [%[src_asm]]              \n\t"
+                        "vst1.8         {d0,d1}, [%[dst_asm]]              \n\t"
+                        : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                        :  //[srcY] "r" (srcY)
+                        : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                        );
+            }
+
+            ptr += 32;  //32 byte in one process.
+            ptr += 32;  //32 byte in one process.
+        }
+        ptr += (32-nLeftValidLine)*32;
+    }
+}
+
+static void map32x32_to_yuv_skip_oneline_nv21(unsigned char* srcY, unsigned char* tarY,unsigned int coded_width,unsigned int coded_height)
+{
+    unsigned int i,j,l,m,n;
+    unsigned int mb_width,mb_height,twomb_line, twomb_width, recon_width;
+    unsigned long offset;
+    unsigned char *ptr;
+    unsigned char *dst_asm,*src_asm;
+    unsigned vdecbuf_width, vdecbuf_height;
+    int nWidthMatchFlag;
+    int nLeftValidLine;  //in the bottom macroblock(32*32), the valid line is < 32.
+    ptr = srcY;
+//  mb_width = (coded_width+15)>>4;
+//  mb_height = (coded_height+15)>>4;
+//  twomb_line = (mb_height+1)>>1;
+//  recon_width = (mb_width+1)&0xfffffffe;
+
+    mb_width = ((coded_width+31)&~31) >>4;
+    mb_height = ((coded_height+31)&~31) >>4;
+    twomb_line = (mb_height+1)>>1;
+    recon_width = (mb_width+1)&0xfffffffe;
+    twomb_width = (mb_width+1)>>1;
+    if(twomb_line < 1 || twomb_width < 1)
+    {
+        LOGE("fatal error! twomb_line=%d, twomb_width=%d", twomb_line, twomb_width);
+    }
+    vdecbuf_width = twomb_width*32;
+    vdecbuf_height = twomb_line*32;
+    if(vdecbuf_width > coded_width)
+    {
+        nWidthMatchFlag = 0;
+        if((vdecbuf_width - coded_width) != 16)
+        {
+            LOGW("(f:%s, l:%d) fatal error! vdecbuf_width=%d, gpubuf_width=%d,  the program will crash!", __FUNCTION__, __LINE__, vdecbuf_width, coded_width);
+        }
+        else
+        {
+            //LOGV("(f:%s, l:%d) Be careful! vdecbuf_width=%d, gpubuf_width=%d", __FUNCTION__, __LINE__, vdecbuf_width, coded_width);
+        }
+    }
+    else if(vdecbuf_width == coded_width)
+    {
+        nWidthMatchFlag = 1;
+    }
+    else
+    {
+        LOGW("(f:%s, l:%d) fatal error! vdecbuf_width=%d <= gpubuf_width=%d, the program will crash!", __FUNCTION__, __LINE__, vdecbuf_width, coded_width);
+        nWidthMatchFlag = 0;
+    }
+    for(i=0;i<twomb_line-1;i++)   //twomb line number
+    {
+        for(j=0;j<twomb_width-1;j++)   //macroblock(32*32) number in one line
+        {
+            for(l=0;l<16;l++)
+            {
+                //first mb
+                m=i*16 + l;     //line num,skip oneline
+                n= j*32;        //byte num in one line
+                offset = m*coded_width + n;
+                //memcpy(tarY+offset,ptr,32);
+                dst_asm = tarY+offset;
+                src_asm = ptr;
+                asm volatile (
+                        "vld2.8         {d0 - d1}, [%[src_asm]]!              \n\t"
+                        "vld2.8         {d2 - d3}, [%[src_asm]]               \n\t"
+                        "vswp           d0, d1                                \n\t"
+                        "vswp           d2, d3                                \n\t"
+                        "vst2.8         {d0 - d1}, [%[dst_asm]]!              \n\t"
+                        "vst2.8         {d2 - d3}, [%[dst_asm]]               \n\t"
+                        : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                        :  //[srcY] "r" (srcY)
+                        : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                        );
+
+                ptr += 32;  //32 byte in one process.
+                ptr += 32;  //32 byte in one process.
+            }
+        }
+        //process last macroblock of one line, gpu buf must be 16byte align or 32 byte align
+        { //last mb of one line
+            for(l=0;l<16;l++)
+            {
+                //first mb
+                m=i*16 + l;     //line num
+                n= j*32;        //byte num in one line
+                offset = m*coded_width + n;
+                //memcpy(tarY+offset,ptr,32);
+                dst_asm = tarY+offset;
+                src_asm = ptr;
+                if(nWidthMatchFlag)
+                {
+                    asm volatile (
+                        "vld2.8         {d0 - d1}, [%[src_asm]]!              \n\t"
+                        "vld2.8         {d2 - d3}, [%[src_asm]]               \n\t"
+                        "vswp           d0, d1                                \n\t"
+                        "vswp           d2, d3                                \n\t"
+                        "vst2.8         {d0 - d1}, [%[dst_asm]]!              \n\t"
+                        "vst2.8         {d2 - d3}, [%[dst_asm]]               \n\t"
+                            : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                            :  //[srcY] "r" (srcY)
+                            : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                            );
+                }
+                else
+                {
+                    asm volatile (
+                            "vld1.8         {d0,d1}, [%[src_asm]]              \n\t"
+                            "vst1.8         {d0,d1}, [%[dst_asm]]              \n\t"
+                            : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                            :  //[srcY] "r" (srcY)
+                            : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                            );
+                }
+
+                ptr += 32;  //32 byte in one process.
+                ptr += 32;  //32 byte in one process.
+            }
+        }
+    }
+    //last twomb line, we process it alone
+    nLeftValidLine = coded_height - (twomb_line-1)*32;
+    if(nLeftValidLine!=32)
+    {
+        //LOGV("(f:%s, l:%d)hehehaha,gpuBufHeight[%d] is not 32 align", __FUNCTION__, __LINE__, nLeftValidLine);
+    }
+    for(j=0;j<twomb_width-1;j++)   //macroblock(32*32) number in one line
+    {
+        for(l=0;l<nLeftValidLine/2;l++)
+        {
+            //first mb
+            m=i*16 + l;     //line num
+            n= j*32;        //byte num in one line
+            offset = m*coded_width + n;
+            //memcpy(tarY+offset,ptr,32);
+            dst_asm = tarY+offset;
+            src_asm = ptr;
+            asm volatile (
+                "vld2.8         {d0 - d1}, [%[src_asm]]!              \n\t"
+                "vld2.8         {d2 - d3}, [%[src_asm]]               \n\t"
+                "vswp           d0, d1                                \n\t"
+                "vswp           d2, d3                                \n\t"
+                "vst2.8         {d0 - d1}, [%[dst_asm]]!              \n\t"
+                "vst2.8         {d2 - d3}, [%[dst_asm]]               \n\t"
+                    : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                    :  //[srcY] "r" (srcY)
+                    : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                    );
+
+            ptr += 32;  //32 byte in one process.
+            ptr += 32;  //32 byte in one process.
+        }
+        ptr += (32-nLeftValidLine)*32;
+    }
+    //process last macroblock of last line, gpu buf must be 16byte align or 32 byte align
+    { //last mb of last line
+        for(l=0;l<nLeftValidLine/2;l++)
+        {
+            //first mb
+            m=i*16 + l;     //line num
+            n= j*32;        //byte num in one line
+            offset = m*coded_width + n;
+            //memcpy(tarY+offset,ptr,32);
+            dst_asm = tarY+offset;
+            src_asm = ptr;
+            if(nWidthMatchFlag)
+            {
+                asm volatile (
+                    "vld2.8         {d0 - d1}, [%[src_asm]]!              \n\t"
+                    "vld2.8         {d2 - d3}, [%[src_asm]]               \n\t"
+                    "vswp           d0, d1                                \n\t"
+                    "vswp           d2, d3                                \n\t"
+                    "vst2.8         {d0 - d1}, [%[dst_asm]]!              \n\t"
+                    "vst2.8         {d2 - d3}, [%[dst_asm]]               \n\t"
+                        : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                        :  //[srcY] "r" (srcY)
+                        : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                        );
+            }
+            else
+            {
+                asm volatile (
+                        "vld1.8         {d0,d1}, [%[src_asm]]              \n\t"
+                        "vst1.8         {d0,d1}, [%[dst_asm]]              \n\t"
+                        : [dst_asm] "+r" (dst_asm), [src_asm] "+r" (src_asm)
+                        :  //[srcY] "r" (srcY)
+                        : "cc", "memory", "d0", "d1", "d2", "d3", "d4", "d5", "d6", "d16", "d17", "d18", "d19", "d20", "d21", "d22", "d23", "d24", "d28", "d29", "d30", "d31"
+                        );
+            }
+
+            ptr += 32;  //32 byte in one process.
+            ptr += 32;  //32 byte in one process.
+        }
+        ptr += (32-nLeftValidLine)*32;
+    }
+}
+
+static void yuv420_mb_to_NV12(unsigned char* srcY, unsigned char* tarY,
+                                unsigned char* srcC, unsigned char* tarC,
+                                unsigned int width,unsigned int height)
+{
+    //convert y componet
+    map32x32_to_yuv(srcY, tarY, width, height);
+
+    //convert c componet
+    map32x32_to_yuv(srcC, tarC, width, height>>1);
+}
+
+static void yuv420_mb_to_NV21(unsigned char* srcY, unsigned char* tarY,
+                                unsigned char* srcC, unsigned char* tarC,
+                                unsigned int width,unsigned int height)
+{
+    //convert y componet
+    map32x32_to_yuv(srcY, tarY, width, height);
+
+    //convert c componet
+    //map32x32_to_yuv(srcC, tarC-1, width, height>>1);
+    map32x32_to_yuv_nv21(srcC, tarC, width, height>>1);
+    //map32x32_to_yuv_skip_oneline_nv21(srcC, tarC, width, height/2);
+}
+
+
+static void yuv422_mb_to_NV12(unsigned char* srcY, unsigned char* tarY,
+                                unsigned char* srcC, unsigned char* tarC,
+                                unsigned int width,unsigned int height)
+{
+    //convert y componet
+    map32x32_to_yuv(srcY, tarY, width, height);
+
+    //convert c componet
+    map32x32_to_yuv_skip_oneline(srcC, tarC, width, height);
+}
+
+static void yuv422_mb_to_NV21(unsigned char* srcY, unsigned char* tarY,
+                                unsigned char* srcC, unsigned char* tarC,
+                                unsigned int width,unsigned int height)
+{
+    //convert y componet
+    map32x32_to_yuv(srcY, tarY, width, height);
+
+    //convert c componet
+    map32x32_to_yuv_skip_oneline_nv21(srcC, tarC, width, height);
+}
+
+
+static void YUYVToNV21(const void* y,const void *u, void *nv21, int width, int height)
+{
+    int i,j;
+
+    uint8_t* Y  = (uint8_t*)nv21;
+    uint8_t* VU = (uint8_t*)Y + width * height;
+
+    uint8_t* yuyv = (uint8_t)malloc(2*width * height*sizeof(uint8_t));
+    memcpy(yuyv,y,width * height);
+    memcpy(yuyv+width * height,u,width * height);
+    
+    for(i = 0; i < height; i += 2)   {
+        for (j = 0; j < width; j++) {
+            *(uint8_t*)((uint8_t*)Y + i * width + j) = *(uint8_t*)((uint8_t*)yuyv + i * width * 2 + j * 2);
+            *(uint8_t*)((uint8_t*)Y + (i + 1) * width + j) = *(uint8_t*)((uint8_t*)yuyv + (i + 1) * width * 2 + j * 2);
+
+            if (j % 2)  {
+                if (j < width - 1) {
+                    *(uint8_t*)((uint8_t*)VU + ((i * width) >> 1) + j) = *(uint8_t*)((uint8_t*)yuyv + i * width * 2 + (j + 1) * 2 + 1);
+                }
+            }
+            else    {
+                if (j > 1) {
+                    *(uint8_t*)((uint8_t*)VU + ((i * width) >> 1) + j) = *(uint8_t*)((uint8_t*)yuyv + i * width * 2 + (j - 1) * 2 + 1);         
+                }
+            }
+        }
+    }
+    
+    free(yuyv);
+}
+
+static void YUYVToYU12(const void* yuyv, void *yu12, int width, int height)
+{
+    int i,j;
+    uint8_t* Y  = (uint8_t*)yu12;
+    uint8_t* U  = (uint8_t*)Y + width * height; 
+    uint8_t* V      = (uint8_t*)Y + width*height*5/4;
+
+    for(i = 0; i < height; i += 2)
+    {
+        for (j = 0; j < width; j++) {
+            *(uint8_t*)((uint8_t*)Y + i * width + j) = *(uint8_t*)((uint8_t*)yuyv + i * width * 2 + j * 2);
+
+            *(uint8_t*)((uint8_t*)Y + (i + 1) * width + j) = *(uint8_t*)((uint8_t*)yuyv + (i + 1) * width * 2 + j * 2);
+
+            *(uint8_t*)((uint8_t*)U + ((i * width)/4) + j) = *(uint8_t*)((uint8_t*)yuyv + i * width * 2 + j * 4 + 1);
+
+            *(uint8_t*)((uint8_t*)V + ((i * width)/4) + j) = *(uint8_t*)((uint8_t*)yuyv + i * width * 2 + j * 4 + 3);
+
+        }
+    }
+}
+
+static void YU12ToNV12(const void* yu12, void *nv12, int width, int height)
+{
+    int i;
+
+    char * src_u    = (char *)yu12+ width * height;
+    char * src_v    = (char *)yu12 + 5*width * height/4;
+    char * dst_uv  = (char *)nv12+ width * height;
+
+    memcpy(nv12, yu12, width * height);//copy Y
+    
+    for(i = 0; i < width * height/4; i ++)  {
+        * (dst_uv++) = * (src_u+i);
+        * (dst_uv++) = * (src_v+i);
+
+    }
+    //LOGE("Mic YU12 to NV12");
+}
+
+static void YU12ToNV21(const void* yu12, void *nv12, int width, int height)
+{
+    int i;
+
+    char * src_u    = (char *)yu12+ width * height;
+    char * src_v    = (char *)yu12 + 5*width * height/4;
+    char * dst_uv  = (char *)nv12+ width * height;
+
+    memcpy(nv12, yu12, width * height);//copy Y
+
+    for(i = 0; i < width * height/4; i ++)  {
+        * (dst_uv++) = * (src_v+i);
+        * (dst_uv++) = * (src_u+i); 
+     }
+    //LOGE("Mic YU12 to NV21");
+}
+
+static int MBToNV(const void* y,const void *u, void *nv12, int width, int height,cedarv_pixel_format_e informat, char *outformat)
+{
+    int ret;
+    ScalerParameter cdx_scaler_para;
+    cdx_scaler_para.addr_y_in = y;
+    cdx_scaler_para.addr_c_in=  u;
+
+    cdx_scaler_para.width_in = width;
+    cdx_scaler_para.height_in = height;
+
+    cdx_scaler_para.width_out = width;
+    cdx_scaler_para.height_out = height;
+
+    #ifdef USE_ION_MEM_ALLOCATOR
+    unsigned int temp_y =(unsigned int)ion_alloc_alloc(width*height*3/2);
+    unsigned int temp_u;
+    unsigned int temp_v;
+    int phy_add_y = ion_alloc_vir2phy((void*)temp_y);
+
+    cdx_scaler_para.addr_y_out = phy_add_y;
+    cdx_scaler_para.addr_u_out = phy_add_y+ width*height;
+    cdx_scaler_para.addr_v_out = phy_add_y+ width*height*5/4;
+
+    ion_flush_cache((void*)temp_y, width*height*3/2);
+
+    #else USE_SUNXI_MEM_ALLOCATOR
+    unsigned int temp_y =(unsigned int)sunxi_alloc_alloc(width*height*3/2);
+    unsigned int temp_u;
+    unsigned int temp_v;
+    int phy_add_y = sunxi_alloc_vir2phy((void*)temp_y);
+
+    cdx_scaler_para.addr_y_out = phy_add_y;
+    cdx_scaler_para.addr_u_out = phy_add_y+ width*height;
+    cdx_scaler_para.addr_v_out = phy_add_y+ width*height*5/4;
+
+    sunxi_flush_cache((void*)temp_y, width*height*3/2);
+
+    #endif
+
+    LOGV(" hardwarePictureScaler");
+    switch (informat){
+        case CEDARV_PIXEL_FORMAT_MB_UV_COMBINE_YUV422 :
+            //ret=HardwarePictureScaler(&cdx_scaler_para,DISP_FORMAT_YUV422);
+            break;
+        case CEDARV_PIXEL_FORMAT_MB_UV_COMBINE_YUV420 :
+            //ret=HardwarePictureScaler(&cdx_scaler_para,DISP_FORMAT_YUV420);
+            break;
+        default :
+            LOGE("The format can be supported now!!");
+    }
+
+    if(ret == 0){
+        LOGD(" hardwarePictureScaler finished!!");
+        memcpy(nv12,temp_y,width*height*1.5);
+        //savefile("/mnt/sdcard/h264.yuv",temp_y,width*height*1.5);
+        if(!strcmp(outformat,"NV12")){
+            YU12ToNV12(temp_y,nv12,width,height);
+            LOGE("Mic YU12 to NV12");
+            }
+        else if(!strcmp(outformat,"NV21")){
+            YU12ToNV21(temp_y,nv12,width,height);
+            LOGE("Mic YU12 to NV21");
+            }
+        else LOGE("the out format :%s can't be support now!!!",outformat);
+        //savefile("/mnt/sdcard/nv12.yuv",nv12,width*height*1.5);*/
+    }
+
+    #ifdef USE_ION_MEM_ALLOCATOR
+    ion_flush_cache((void*)nv12, width*height*3/2);
+    ion_alloc_free((void*)temp_y);
+
+    #else USE_SUNXI_MEM_ALLOCATOR
+    sunxi_flush_cache((void*)nv12, width*height*3/2);
+    sunxi_alloc_free((void*)temp_y);
+    #endif
+
+    return 0;
+}
+
+static int GetStreamData(void* in, u8* buf0, u32 buf_size0, u8* buf1, u32 buf_size1, cedarv_stream_data_info_t* data_info)
+{
+    LOGD("Starting get stream data!!");
+    if(data_info->lengh <= buf_size0) {
+            LOGV("The stream lengh is %d, the buf_size0 is %d",data_info->lengh,buf_size0);
+            memcpy(buf0, in, data_info->lengh);
+    }
+    else {
+        if(data_info->lengh <= (buf_size0+buf_size1)){          
+            LOGV("The stream lengh is %d, the buf_size0 is %d,the buf_size1 is %d",data_info->lengh,buf_size0,buf_size1);
+            memcpy(buf0, in, buf_size0);
+            memcpy(buf1,(in+buf_size0),(data_info->lengh -buf_size0));
+        }
+        else
+            return -1;
+    }
+    data_info->flags |= CEDARV_FLAG_FIRST_PART;
+    data_info->flags |= CEDARV_FLAG_LAST_PART;
+    data_info->flags |= CEDARV_FLAG_PTS_VALID;
+
+    return 0;
+}
+
+static int YUV_StreamOut(cedarv_picture_t *picture, void* out, char* format)
+{
+    u8* y_vir;
+    u8* u_vir;
+    u8* v_vir;
+    LOGV("Stream out!!");
+
+    u8* out_y = (u8*)out;
+    u8* out_c = (u8*)out + picture->display_width*picture->display_height;
+
+    LOGV("The picture->width is %d",picture->width);
+    LOGV("The picture->height is %d",picture->height);  
+    
+    y_vir=picture->y;
+    u_vir=picture->u;
+
+    LOGV("The picture y_vir addr is 0x%x",y_vir);
+    LOGV("The picture u_vir addr is 0x%x",u_vir);
+
+    //LOGE("Mic picture->pixel_format= %x",picture->pixel_format);
+
+    switch(picture->pixel_format){
+    case CEDARV_PIXEL_FORMAT_PLANNER_YUV420:
+        LOGV("The decorder format is CEDARV_PIXEL_FORMAT_PLANNER_YUV420");
+        //goto function
+        break;
+
+    case CEDARV_PIXEL_FORMAT_PLANNER_YVU420:
+        LOGV("The decorder format is CEDARV_PIXEL_FORMAT_PLANNER_YVU420");
+
+        #ifdef USE_ION_MEM_ALLOCATOR
+        y_vir=ion_alloc_phy2vir(picture->y);
+        #else USE_SUNXI_MEM_ALLOCATOR
+        y_vir=sunxi_alloc_phy2vir(picture->y);
+        #endif
+        YU12ToNV21(y_vir,out,picture->display_width,picture->display_height);
+        //memcpy(out,y_vir,(picture->display_width*picture->display_height)*3/2);
+        //goto function
+        //savefile("/mnt/sdcard/planner_yvu420.yuv",y_vir,(picture->display_width*picture->display_height)*3/2);
+        break;
+
+    case CEDARV_PIXEL_FORMAT_MB_UV_COMBINE_YUV422:
+        LOGV("The decorder format is CEDARV_PIXEL_FORMAT_MB_UV_COMBINE_YUV422");
+#if 0
+        //goto function
+
+        LOGV("MB_UV_COMBINE_YUV422 Changing to %s",format);
+        MBToNV((void*)y_vir,(void*)u_vir,out,picture->width,picture->height,CEDARV_PIXEL_FORMAT_MB_UV_COMBINE_YUV422,format);
+
+#else
+        LOGD("width: %d, height: %d", picture->display_width, picture->display_height);
+
+        #ifdef USE_ION_MEM_ALLOCATOR
+        y_vir=ion_alloc_phy2vir(picture->y);
+        u_vir=ion_alloc_phy2vir(picture->u);
+
+        #else USE_SUNXI_MEM_ALLOCATOR
+        y_vir=sunxi_alloc_phy2vir(picture->y);
+        u_vir=sunxi_alloc_phy2vir(picture->u);
+        #endif
+
+        if(!strcmp(format,"NV12")){
+            yuv422_mb_to_NV12(y_vir, out_y, u_vir, out_c,picture->display_width,picture->display_height);
+        }else if(!strcmp(format,"NV21")){
+            yuv422_mb_to_NV21(y_vir, out_y, u_vir, out_c,picture->display_width,picture->display_height);
+            //LOGE("the out format :%s support now!!!",format);
+        }else{
+            LOGE("the out format :%s can't be support now!!!",format);
+        }
+#endif
+        break;
+        
+    case CEDARV_PIXEL_FORMAT_MB_UV_COMBINE_YUV411:
+        LOGV("The decorder format is CEDARV_PIXEL_FORMAT_MB_UV_COMBINE_YUV411");
+        //goto function
+        break;
+    case CEDARV_PIXEL_FORMAT_MB_UV_COMBINE_YUV420:
+
+        LOGV("The decorder format is CEDARV_PIXEL_FORMAT_MB_UV_COMBINE_YUV420");
+#if 0       
+        //goto function
+        LOGV("MB_UV_COMBINE_YUV420 Changing to %s",format);
+        MBToNV((void*)y_vir,(void*)u_vir,out,picture->width,picture->height,CEDARV_PIXEL_FORMAT_MB_UV_COMBINE_YUV420,format);
+
+#else
+
+       #ifdef USE_ION_MEM_ALLOCATOR
+        y_vir=ion_alloc_phy2vir(picture->y);
+        u_vir=ion_alloc_phy2vir(picture->u);
+       #else USE_SUNXI_MEM_ALLOCATOR
+        y_vir=sunxi_alloc_phy2vir(picture->y);
+        u_vir=sunxi_alloc_phy2vir(picture->u);
+       #endif
+        yuv420_mb_to_NV21(y_vir, out_y, u_vir,out_c,picture->display_width,picture->display_height);
+#endif
+        break;  
+    default:
+        LOGE("The decorder format is no supported in out stream");
+        return -1;
+    }
+    return 0;
+}
+
+
+void Libve_dec(cedarv_decoder_t** decoder,const void *in,void *out,void *decorder_stream_info,void *decorder_data_info,char* outfmt,ve_mutex_t *decorder_mutex)
+{
+    int            ret;
+
+    u8*     buf0;
+    u8*     buf1;
+    u32     buf0size;   
+    u32     buf1size;
+
+    cedarv_stream_data_info_t   *data_info  =(cedarv_stream_data_info_t *)decorder_data_info;
+    cedarv_stream_info_t        *stream_info =(cedarv_stream_info_t*)decorder_stream_info;
+    cedarv_picture_t          picture;
+    
+    ret = (*decoder)->request_write(*decoder, data_info->lengh, &buf0, &buf0size, &buf1, &buf1size);
+    if(ret < 0){
+        //* request bit stream data buffer fail, may be the bit stream FIFO is full.
+        //* in this case, we should call decoder->decode(...) to decode stream data and release bit stream buffer.
+        //* here we just use a single thread to do the data parsing/decoding/picture requesting work, so it is
+        //* invalid to see that the bit stream FIFO is full.
+        LOGE("request bit stream buffer fail.\n");
+        goto fail;
+    }
+
+    LOGV("GetStreamData!!");
+    GetStreamData(in,buf0,buf0size,buf1,buf1size,data_info);
+
+    //* tell libcedarv stream data has been added.
+    (*decoder)->update_data(*decoder, data_info);       //* this decoder operation do not use hardware, so need not lock the mutex.
+
+    //* decode bit stream data.
+
+    decorder_mutex_lock(decorder_mutex);
+    ret = (*decoder)->decode(*decoder); 
+    decorder_mutex_unlock(decorder_mutex);  
+
+    if(ret == CEDARV_RESULT_ERR_NO_MEMORY || ret == CEDARV_RESULT_ERR_UNSUPPORTED){
+        LOGE("bit stream is unsupported.\n");
+        goto fail;
+    }
+    if(ret==CEDARV_RESULT_OK)
+        LOGV("Successfully return,decording!!");
+    if(ret==CEDARV_RESULT_FRAME_DECODED)
+        LOGV("One frame decorded!!");   
+    if(ret == CEDARV_RESULT_KEYFRAME_DECODED)
+        LOGV("One key frame decorded!!");   
+
+    if (ret == CEDARV_RESULT_FRAME_DECODED ||           \
+        ret == CEDARV_RESULT_KEYFRAME_DECODED ||    \
+        ret == CEDARV_RESULT_NO_FRAME_BUFFER)
+    {
+        //* request picture from libcedarv.
+
+        ret = (*decoder)->display_request(*decoder, &picture);      //* this decoder operation do not use hardware, so need not lock the mutex.
+        
+        LOGV("The return of display_request is %d",ret);
+
+        if(ret == 0){
+            //* get one picture from decoder success, do some process work on this picture.
+            LOGV("Copy data to out");
+
+            decorder_mutex_lock(decorder_mutex);
+            YUV_StreamOut(&picture,out,outfmt);
+            decorder_mutex_unlock(decorder_mutex);
+            stream_info->video_width = picture.width;
+            stream_info->video_height = picture.height;
+            //* release the picture to libcedarv.       
+            LOGV("decoder->display_release");
+            (*decoder)->display_release(*decoder, picture.id);      //* this decoder operation do not use hardware, so need not lock the mutex.
+        }
+
+    }
+
+    if(stream_info->init_data)
+        free(stream_info->init_data);
+    return ;
+fail:
+
+    LOGE("Fail operations");
+    decorder_mutex_lock(decorder_mutex);
+    (*decoder)->ioctrl(*decoder, CEDARV_COMMAND_STOP, 0);
+    decorder_mutex_unlock(decorder_mutex);
+
+    decorder_mutex_lock(decorder_mutex);
+    (*decoder)->close(*decoder);
+    libcedarv_exit(*decoder);
+    decorder_mutex_unlock(decorder_mutex);
+
+    if(stream_info->init_data)
+        free(stream_info->init_data);
+
+    cedarx_hardware_exit(0);
+    decorder_mutex_destroy(decorder_mutex);
+
+    return ;
+
+}
+
+int Libve_init(cedarv_decoder_t** decoder,cedarv_stream_info_t* stream_info,int scale,ve_mutex_t *decorder_mutex)
+{
+    int ret;
+    LOGD("Libve_init!!");
+
+#if VE_MUTEX_ENABLE
+    if (decorder_mutex_init(decorder_mutex, CEDARV_DECODE) < 0) {
+        LOGE("ve mutex init fail!!");
+        return -1;
+    }
+#endif
+
+    *decoder =NULL;
+    cedarx_hardware_init(0);    
+    decorder_mutex_lock(decorder_mutex);    
+    *decoder = libcedarv_init(&ret);    
+    decorder_mutex_unlock(decorder_mutex);
+
+    LOGD("libcedarv_init!!");
+    if(ret < 0){
+        LOGE("can not initialize the decoder library.\n");
+        return -1;
+    }
+    LOGV("decoder->set_vstream_info!!");
+    (*decoder)->set_vstream_info(*decoder, stream_info);        //* this decoder operation do not use hardware, so need not lock the mutex.
+
+    decorder_mutex_lock(decorder_mutex);
+    (*decoder)->ioctrl(*decoder, CEDARV_COMMAND_SET_PIXEL_FORMAT, 0);
+    decorder_mutex_unlock(decorder_mutex);
+
+    LOGD("decoder->open!!");
+    decorder_mutex_lock(decorder_mutex);
+    if(scale && stream_info->video_width == 1920 &&  stream_info->video_height ==1080)
+    {
+        (*decoder)->ioctrl(*decoder, CEDARV_COMMAND_SET_MAX_OUTPUT_WIDTH, stream_info->video_width/2);
+        (*decoder)->ioctrl(*decoder, CEDARV_COMMAND_SET_MAX_OUTPUT_HEIGHT, stream_info->video_height/2);
+    }
+    ret =(*decoder)->open(*decoder);
+    decorder_mutex_unlock(decorder_mutex);  
+
+    if(ret < 0){
+        LOGE("can not open decoder.\n");
+        if(stream_info->init_data)
+            free(stream_info->init_data);
+
+        decorder_mutex_lock(decorder_mutex);
+        libcedarv_exit(*decoder);
+        decorder_mutex_unlock(decorder_mutex);
+        
+        return (void*)-1;
+    }
+
+    decorder_mutex_lock(decorder_mutex);
+    (*decoder)->ioctrl(*decoder, CEDARV_COMMAND_PLAY, 0);
+    decorder_mutex_unlock(decorder_mutex);
+    
+    ret=0;
+
+    return ret;
+}
+
+int Libve_exit(cedarv_decoder_t** decoder,ve_mutex_t *decorder_mutex)
+{
+    LOGD("Libve_exit!!");
+
+    decorder_mutex_lock(decorder_mutex);
+    (*decoder)->ioctrl(*decoder, CEDARV_COMMAND_STOP, 0);
+    decorder_mutex_unlock(decorder_mutex);
+
+    decorder_mutex_lock(decorder_mutex);
+    (*decoder)->close(*decoder);
+    libcedarv_exit(*decoder);
+    decorder_mutex_unlock(decorder_mutex);  
+    cedarx_hardware_exit(0);
+#if VE_MUTEX_ENABLE
+    decorder_mutex_destroy(decorder_mutex);
+#endif
+
+    return 0;
+}
diff --git a/hardware/camera/Libve_Decoder.h b/hardware/camera/Libve_Decoder.h
new file mode 100755
index 0000000..b6dadd2
--- /dev/null
+++ b/hardware/camera/Libve_Decoder.h
@@ -0,0 +1,83 @@
+#ifndef __LIBVE_DECORDER_H__
+#define __LIBVE_DECORDER_H__
+/*
+#include "libve/libve.h"
+#include "libve/libve_adapter.h"
+#include "libve/libve_typedef.h"
+#include "libve/libcedarv.h"
+*/
+#include "libve_typedef.h"
+#include "cedarx_hardware.h"
+#include "libcedarv.h"
+#include "drv_display.h"
+//#include <libve/Drv_display.h>
+
+#include <sys/mman.h>
+#include <sys/ioctl.h>
+#include <fcntl.h>
+
+#include <pthread.h>
+#include "CDX_Resource_Manager.h"
+
+//#include "CameraDebug.h"
+
+#define DBG_ENABLE 0
+
+#define VE_MUTEX_ENABLE 1
+
+#if  VE_MUTEX_ENABLE
+#define decorder_mutex_lock(x) ve_mutex_lock(x)
+#define decorder_mutex_unlock(x) ve_mutex_unlock(x)
+#define decorder_mutex_init(x,y) ve_mutex_init(x,y)
+#define decorder_mutex_destroy(x) ve_mutex_destroy(x)
+
+#else
+#define decorder_mutex_lock(x)
+#define decorder_mutex_unlock(x)
+#define decorder_mutex_init(x,y)
+#define decorder_mutex_destroy(x)
+
+#endif
+ 
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+enum FORMAT_CONVERT_COLORFORMAT {
+	CONVERT_COLOR_FORMAT_NONE = 0,
+	CONVERT_COLOR_FORMAT_YUV420PLANNER,
+	CONVERT_COLOR_FORMAT_YVU420PLANNER,
+	CONVERT_COLOR_FORMAT_YUV420MB,
+	CONVERT_COLOR_FORMAT_YUV422MB,
+};
+
+typedef struct ScalerParameter{
+	int mode; //0: YV12 1:thumb yuv420p
+	int format_in;
+	int format_out;
+
+	int width_in;
+	int height_in;
+
+	int width_out;
+	int height_out;
+
+	void *addr_y_in;
+	void *addr_c_in;
+	unsigned int addr_y_out;
+	unsigned int addr_u_out;
+	unsigned int addr_v_out;
+}ScalerParameter;
+
+void Libve_dec(cedarv_decoder_t** decoder,const void *in,void *out,void *decorder_stream_info,void *decorder_data_info,char* outfmt,ve_mutex_t *decorder_mutex);
+int Libve_init(cedarv_decoder_t** decoder,cedarv_stream_info_t*stream_info,int scale,ve_mutex_t *decorder_mutex);
+int Libve_exit(cedarv_decoder_t** decoder,ve_mutex_t *decorder_mutex);
+//int HardwarePictureScaler(ScalerParameter *cdx_scaler_para,__disp_pixel_fmt_t informat);
+
+#ifdef __cplusplus
+}
+#endif
+
+
+#endif  /* __LIBVE_DECORDER_H__ */
+
diff --git a/hardware/camera/Libve_Decoder2.c b/hardware/camera/Libve_Decoder2.c
new file mode 100755
index 0000000..3360a84
--- /dev/null
+++ b/hardware/camera/Libve_Decoder2.c
@@ -0,0 +1,163 @@
+#include "Libve_Decoder2.h"
+
+#include<android/log.h>
+#include <stdio.h>
+#include <time.h>
+//#include "vdecoder.h"
+
+#define LOG_TAG    "Libev_decorder2"
+
+#define USE_ION_MEM_ALLOCATOR
+
+#if  DBG_ENABLE
+     #define LOGE(...)  __android_log_print(ANDROID_LOG_ERROR,LOG_TAG,__VA_ARGS__)
+     #define LOGD(...)  __android_log_print(ANDROID_LOG_DEBUG,LOG_TAG,__VA_ARGS__)
+     #define LOGI(...)  __android_log_print(ANDROID_LOG_INFO,LOG_TAG,__VA_ARGS__)
+     #define LOGW(...)  __android_log_print(ANDROID_LOG_WARN,LOG_TAG,__VA_ARGS__)
+     #define LOGF(...)  __android_log_print(ANDROID_LOG_FATAL,LOG_TAG,__VA_ARGS__)
+     #define LOGV(...)  __android_log_print(ANDROID_LOG_VERBOSE,LOG_TAG,__VA_ARGS__)
+#else
+     #define LOGE(...)  __android_log_print(ANDROID_LOG_ERROR,LOG_TAG,__VA_ARGS__)
+     #define LOGD(...)
+     #define LOGI(...)
+     #define LOGW(...)
+     #define LOGF(...)
+     #define LOGV(...)
+#endif
+
+static int saveframe(char *str,void *p,int length,int is_oneframe)
+{  
+    FILE *fd;
+
+    if(is_oneframe){
+        fd = fopen(str,"wb");
+    }
+    else{
+        fd = fopen(str,"a");
+    }
+
+    if(!fd){
+        LOGE("Open file error");
+        return -1;
+    }
+    if(fwrite(p,1,length,fd)){
+       LOGD("Write file successfully");
+       fclose(fd);
+       return 0;
+    }
+    else {
+       LOGE("Write file fail");
+       fclose(fd);
+       return -1;
+    }
+}
+
+static int GetStreamData(void* in, char*  buf0, int buf_size0, char* buf1, int buf_size1, VideoStreamDataInfo* dataInfo)
+{
+    LOGD("Starting get stream data!!");
+    if(dataInfo->nLength <= buf_size0) {
+            LOGV("The stream lengh is %d, the buf_size0 is %d",data_info->lengh,buf_size0);
+            memcpy(buf0, in, dataInfo->nLength);
+    }
+    else {
+        if(dataInfo->nLength <= (buf_size0+buf_size1)){          
+            LOGV("The stream lengh is %d, the buf_size0 is %d,the buf_size1 is %d",dataInfo->nLength,buf_size0,buf_size1);
+            memcpy(buf0, in, buf_size0);
+            memcpy(buf1,(in+buf_size0),(dataInfo->nLength -buf_size0));
+        }
+        else
+            return -1;
+    }
+    dataInfo->bIsFirstPart = 1;
+    dataInfo->bIsLastPart  = 1;
+    dataInfo->pData       = buf0;
+    dataInfo->nPts        = -1;
+    dataInfo->nPcr        = -1;
+
+    return 0;
+}
+
+void Libve_dec2(VideoDecoder** mVideoDecoder, const void *in, void *out, VideoStreamInfo* pVideoInfo, VideoStreamDataInfo* dataInfo, VConfig* pVconfig)
+{
+    int   ret;
+    char* pBuf0;
+    char* pBuf1;
+    int size0;
+    int size1;
+    char* pData;
+
+    VideoPicture*     pPicture;
+
+    if(*mVideoDecoder == NULL)
+    {
+        LOGE("mVideoDecoder = NULL, return");
+        return;
+    }
+
+    ret = RequestVideoStreamBuffer(*mVideoDecoder, dataInfo->nLength, &pBuf0, &size0, &pBuf1, &size1,0);
+
+    if(ret < 0)
+    {
+        LOGE("FUNC:%s, LINE:%d, RequestVideoStreamBuffer fail!",__FUNCTION__,__LINE__);
+        return;
+    }
+
+    GetStreamData(in,pBuf0,size0,pBuf1,size1,dataInfo);
+
+    SubmitVideoStreamData(*mVideoDecoder, dataInfo, 0);
+
+    //* decode stream.
+    ret = DecodeVideoStream(*mVideoDecoder, 0 /*eos*/, 0/*key frame only*/, 0/*drop b frame*/, 0/*current time*/);
+
+    if(ret == VDECODE_RESULT_FRAME_DECODED || ret == VDECODE_RESULT_KEYFRAME_DECODED)
+    {
+        pPicture = RequestPicture(*mVideoDecoder, 0/*the major stream*/);
+
+        if(pPicture)
+        {
+            ion_flush_cache((void*)pPicture->pData0,pVideoInfo->nWidth*pVideoInfo->nHeight);
+            ion_flush_cache((void*)pPicture->pData1,pVideoInfo->nWidth*pVideoInfo->nHeight/2);
+            memcpy(out, (void*)pPicture->pData0, pVideoInfo->nWidth*pVideoInfo->nHeight);
+            memcpy((char*)out + pVideoInfo->nWidth*pVideoInfo->nHeight, (void*)pPicture->pData1, pVideoInfo->nWidth*pVideoInfo->nHeight/2);
+
+            ReturnPicture(*mVideoDecoder, pPicture);
+        }
+    }
+}
+
+int Libve_init2(VideoDecoder** mVideoDecoder, VideoStreamInfo* pVideoInfo, VConfig* pVconfig)
+{
+    if(*mVideoDecoder != NULL)
+    {
+        LOGE("FUNC: %s fail, LINE: %d, mVideoDecoder is not NULL, please check it!",__FUNCTION__, __LINE__);
+        return -1;
+    }
+
+    *mVideoDecoder = CreateVideoDecoder();
+
+    //* initialize the decoder.
+    if(InitializeVideoDecoder(*mVideoDecoder, pVideoInfo, pVconfig) != 0)
+    {
+        LOGE("initialize video decoder fail.");
+        DestroyVideoDecoder(*mVideoDecoder);
+        *mVideoDecoder = NULL;
+        return -1;
+    }
+
+    return 0;
+}
+
+int Libve_exit2(VideoDecoder** mVideoDecoder)
+{
+    if(*mVideoDecoder == NULL)
+    {
+        LOGE("FUNC: %s, LINE: %d, mVideoDecoder == NULL",__FUNCTION__, __LINE__);
+        return -1;
+    }
+
+    DestroyVideoDecoder(*mVideoDecoder);
+    *mVideoDecoder = NULL;
+
+    return 0;
+}
+
diff --git a/hardware/camera/Libve_Decoder2.h b/hardware/camera/Libve_Decoder2.h
new file mode 100755
index 0000000..845bb10
--- /dev/null
+++ b/hardware/camera/Libve_Decoder2.h
@@ -0,0 +1,29 @@
+#ifndef __LIBVE_DECORDER2_H__
+#define __LIBVE_DECORDER2_H__
+
+#include <sys/mman.h>
+#include <sys/ioctl.h>
+#include <fcntl.h>
+
+#include <pthread.h>
+#include "vencoder.h"  //* video encode library in "LIBRARY/CODEC/VIDEO/ENCODER"
+//#include "memoryAdapter.h"
+#include "vdecoder.h"
+
+#define DBG_ENABLE 0
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+void Libve_dec2(VideoDecoder** mVideoDecoder, const void *in, void *out, VideoStreamInfo* pVideoInfo, VideoStreamDataInfo* dataInfo, VConfig* pVconfig);
+int  Libve_init2(VideoDecoder** mVideoDecoder,  VideoStreamInfo* pVideoInfo, VConfig* pVconfig);
+int  Libve_exit2(VideoDecoder** mVideoDecoder);
+
+#ifdef __cplusplus
+}
+#endif
+
+
+#endif  /* __LIBVE_DECORDER2_H__ */
+
diff --git a/hardware/camera/PreviewWindow.cpp b/hardware/camera/PreviewWindow.cpp
index 595a7f6..bbd1faf 100755
--- a/hardware/camera/PreviewWindow.cpp
+++ b/hardware/camera/PreviewWindow.cpp
@@ -9,7 +9,7 @@
 #include <ui/Rect.h>
 #include <ui/GraphicBufferMapper.h>
 
-#include "V4L2CameraDevice2.h"
+#include "V4L2CameraDevice.h"
 #include "PreviewWindow.h"
 
 namespace android {
@@ -19,9 +19,9 @@ namespace android {
 								 GRALLOC_USAGE_SW_READ_RARELY | \
 								 GRALLOC_USAGE_SW_WRITE_NEVER
 */
-#define CAMHAL_GRALLOC_USAGE GRALLOC_USAGE_SW_READ_RARELY | \
-								GRALLOC_USAGE_SW_WRITE_NEVER
 
+#define CAMHAL_GRALLOC_USAGE GRALLOC_USAGE_SW_READ_RARELY | \
+                                     GRALLOC_USAGE_SW_WRITE_OFTEN
 
 static int calculateFrameSize(int width, int height, uint32_t pix_fmt)
 {
@@ -44,7 +44,6 @@ static int calculateFrameSize(int width, int height, uint32_t pix_fmt)
 	return frame_size;
 }
 
-
 DBG_TIME_AVG_BEGIN(TAG_CPY);
 DBG_TIME_AVG_BEGIN(TAG_DQBUF);
 DBG_TIME_AVG_BEGIN(TAG_LKBUF);
@@ -175,7 +174,7 @@ bool PreviewWindow::onNextFrameAvailable(const void* frame)
 		preview_height= pv4l2_buf->height;
 		memcpy((void*)&preview_crop, (void*)&pv4l2_buf->crop_rect, sizeof(RECT_t));
 	}
-    
+
     /* Make sure that preview window dimensions are OK with the camera device */
     if (adjustPreviewDimensions(pv4l2_buf) || mShouldAdjustDimensions) {
         LOGD("%s: Adjusting preview windows %p geometry to %dx%d",
@@ -190,9 +189,9 @@ bool PreviewWindow::onNextFrameAvailable(const void* frame)
 				format = HAL_PIXEL_FORMAT_YCrCb_420_SP;
 				break;
 			case V4L2_PIX_FMT_NV12:
-				    LOGV("preview format: V4L2_PIX_FMT_NV12");
-				    format = 0x101;			// NV12
-				    break;
+				LOGV("preview format: V4L2_PIX_FMT_NV12");
+				format = 0x101;			// NV12
+				break;
 			case V4L2_PIX_FMT_YVU420:
 			case V4L2_PIX_FMT_YUV420:	// to do
 				LOGV("preview format: HAL_PIXEL_FORMAT_YV12");
@@ -282,7 +281,7 @@ bool PreviewWindow::onNextFrameAvailable(const void* frame)
     }
 
 	DBG_TIME_AVG_AREA_OUT(TAG_MAPPER);
-
+		
 	mPreviewWindow->set_crop(mPreviewWindow, 
 							preview_crop.left,
 							preview_crop.top, 
@@ -291,9 +290,14 @@ bool PreviewWindow::onNextFrameAvailable(const void* frame)
 
 	DBG_TIME_AVG_AREA_IN(TAG_CPY);
 
-
-	//camera_phy_flush_cache((void*)preview_addr_vir, mPreviewFrameSize);
-
+        #ifdef USE_ION_MEM_ALLOCATOR
+	ion_flush_cache((void*)preview_addr_vir, mPreviewFrameSize);
+	//ion_flush_cache_all();
+	#elif USE_SUNXI_MEM_ALLOCATOR	
+	sunxi_flush_cache((void*)preview_addr_vir, mPreviewFrameSize);
+	// sunxi_flush_cache_all();
+	#endif
+	
 	if (preview_format == V4L2_PIX_FMT_NV21
 		|| preview_format == V4L2_PIX_FMT_NV12)
 	{
@@ -301,15 +305,14 @@ bool PreviewWindow::onNextFrameAvailable(const void* frame)
 		char * dst = (char *)img;
 
 		if (stride == ALIGN_16B(preview_width))
-        {
-            // y
-    		memcpy(dst, src, ALIGN_16B(preview_width) * preview_height);
-    		// uv
-    		src = (char *)preview_addr_vir + ALIGN_16B(preview_width) * preview_height;
-			dst = (char *)img + GPU_BUFFER_ALIGN(ALIGN_16B(preview_width)*preview_height);
-    		memcpy(dst, src, ALIGN_16B(preview_width) * preview_height >> 1);
-			//camera_phy_flush_cache((void*)dst, GPU_BUFFER_ALIGN(ALIGN_16B(preview_width)*preview_height) + \
-			//	                                ALIGN_16B(preview_width) * preview_height >> 1);
+		{
+			// y
+			memcpy(dst, src, ALIGN_16B(preview_width) * preview_height);
+			
+			// uv
+			src = (char *)preview_addr_vir + ALIGN_16B(preview_width) * preview_height;
+			dst = (char *)img + (ALIGN_16B(preview_width)*preview_height);
+			memcpy(dst, src, ALIGN_16B(preview_width) * preview_height >> 1);
 		}
 		else if (stride == ALIGN_32B(preview_width))
 		{
@@ -321,7 +324,7 @@ bool PreviewWindow::onNextFrameAvailable(const void* frame)
 				dst += ALIGN_32B(preview_width);
 			}
 			// uv
-			dst = (char *)img + GPU_BUFFER_ALIGN(ALIGN_32B(preview_width)*preview_height);
+			dst = (char *)img + (ALIGN_32B(preview_width)*preview_height);
 			for (int h = 0; h < preview_height/2; h++)
 			{
 				memcpy(dst, src, preview_width);
@@ -335,6 +338,7 @@ bool PreviewWindow::onNextFrameAvailable(const void* frame)
 		// YU12 to YV12
 		char * src = (char *)preview_addr_vir;
 		char * dst = (char *)img;
+		
 		if (stride == ALIGN_16B(preview_width))
 		{
 			// y
@@ -364,26 +368,26 @@ bool PreviewWindow::onNextFrameAvailable(const void* frame)
 		else if (stride == ALIGN_32B(preview_width))
 		{
 			// y
-		for (int h = 0; h < preview_height; h++)
-		{
-			memcpy(dst, src, preview_width);
-			src += ALIGN_16B(preview_width);
-			dst += ALIGN_32B(preview_width);
-		}
+			for (int h = 0; h < preview_height; h++)
+			{
+				memcpy(dst, src, preview_width);
+				src += ALIGN_16B(preview_width);
+				dst += ALIGN_32B(preview_width);
+			}
 
-		// v
+			// v
 			src = (char *)preview_addr_vir 
 					+ ALIGN_16B(preview_width)*preview_height 
 					+ ALIGN_16B(ALIGN_16B(preview_width)/2)*preview_height/2;
-		dst = (char *)img + ALIGN_32B(preview_width)*preview_height;
-		memcpy(dst, src, ALIGN_16B(preview_width/2)*preview_height >> 1);
-		
-		// u
-		src = (char *)preview_addr_vir + ALIGN_16B(preview_width)*preview_height;
+			dst = (char *)img + ALIGN_32B(preview_width)*preview_height;
+			memcpy(dst, src, ALIGN_16B(preview_width/2)*preview_height >> 1);
+			
+			// u
+			src = (char *)preview_addr_vir + ALIGN_16B(preview_width)*preview_height;
 			dst = (char *)img 
 					+ ALIGN_32B(preview_width)*preview_height
 					+ (ALIGN_16B(preview_width/2)*preview_height >> 1);
-		memcpy(dst, src, ALIGN_16B(preview_width/2)*preview_height >> 1);
+			memcpy(dst, src, ALIGN_16B(preview_width/2)*preview_height >> 1);
 		}
 	}
 	else if(preview_format == V4L2_PIX_FMT_YVU420)
@@ -395,15 +399,15 @@ bool PreviewWindow::onNextFrameAvailable(const void* frame)
 		if (stride == ALIGN_32B(preview_width))
 		{
 			// y
-		for (int h = 0; h < preview_height; h++)
-		{
-			memcpy(dst, src, preview_width);
-			src += ALIGN_16B(preview_width);
-			dst += ALIGN_32B(preview_width);
-		}
-		
-		// u & v
-		memcpy(dst, src, ALIGN_16B(preview_width/2)*preview_height);
+			for (int h = 0; h < preview_height; h++)
+			{
+				memcpy(dst, src, preview_width);
+				src += ALIGN_16B(preview_width);
+				dst += ALIGN_32B(preview_width);
+			}
+			
+			// u & v
+			memcpy(dst, src, ALIGN_16B(preview_width/2)*preview_height);
 		}
 		else if (stride == ALIGN_16B(preview_width))
 		{
diff --git a/hardware/camera/PreviewWindow.h b/hardware/camera/PreviewWindow.h
index 3065a55..64ec696 100755
--- a/hardware/camera/PreviewWindow.h
+++ b/hardware/camera/PreviewWindow.h
@@ -3,7 +3,7 @@
 #define __HAL_PREVIEW_WINDOW_H__
 
 #include <ui/Rect.h>
-#include "CameraPlatform.h"
+
 /*
  * Contains declaration of a class PreviewWindow that encapsulates functionality
  * of a preview window set via set_preview_window camera HAL API.
diff --git a/hardware/camera/SceneFactory/HDRSceneMode.cpp b/hardware/camera/SceneFactory/HDRSceneMode.cpp
deleted file mode 100755
index 6451f8e..0000000
--- a/hardware/camera/SceneFactory/HDRSceneMode.cpp
+++ /dev/null
@@ -1,252 +0,0 @@
-#include "HDRSceneMode.h"
-#define LOG_TAG "HDRSceneMode"
-namespace android {
-
-HDRSceneMode::HDRSceneMode()
-{
-	mWidth = 0;
-	mHeight = 0;
-	mSceneNotifyCb = NULL;
-	mUser = NULL;	
-	mSceneMode = SCENE_FACTORY_MODE_HDR;
-	mHDRState -1;
-	mHDRFinished = 0;
-	mGainBright = 0.0;
-	mGainDark = 0.0;
-	memset(&mHDRBuffer,0,sizeof(mHDRBuffer));
-	mHDRState = HDRSTEP0;
-}
-
-HDRSceneMode::~HDRSceneMode()
-{
-
-}
-
-int HDRSceneMode::RequestHDRBuffer()
-{
-	int ret = 0;
-	int framesize = mWidth * mHeight * 3 >>1;
-	// used for HDR image mode
-	if (mHDRBuffer.Image0Yuv == NULL)
-	    mHDRBuffer.Image0Yuv = (void *)malloc(framesize);
-	if (mHDRBuffer.Image1Yuv == NULL)
-	    mHDRBuffer.Image1Yuv = (void *)malloc(framesize);
-	if (mHDRBuffer.Image2Yuv == NULL)
-	    mHDRBuffer.Image2Yuv = (void *)malloc(framesize);
-	if (mHDRBuffer.Image3Yuv == NULL)
-	    mHDRBuffer.Image3Yuv = (void *)malloc(framesize);
-	if (mHDRBuffer.Image4Yuv == NULL)
-	    mHDRBuffer.Image4Yuv = (void *)malloc(framesize);
-
-
-	//malloc failed, release all buffers
-	if((mHDRBuffer.Image0Yuv == NULL) || \
-		 (mHDRBuffer.Image1Yuv == NULL) || \
-		 (mHDRBuffer.Image2Yuv == NULL) || \
-		 (mHDRBuffer.Image3Yuv == NULL) || \
-		 (mHDRBuffer.Image4Yuv == NULL)) {
-
-		ReleaseHDRBuffer();
-		ALOGE("Request HDR buffer failed!!!");
-		ret = -1;
-	}
-	return ret;
-
-}
-void HDRSceneMode::ReleaseHDRBuffer()
-{
-	//release all buffers
-	if (mHDRBuffer.Image0Yuv != NULL){
-		free(mHDRBuffer.Image0Yuv);
-		mHDRBuffer.Image0Yuv = NULL;
-	}
-	if (mHDRBuffer.Image1Yuv != NULL){
-		free(mHDRBuffer.Image1Yuv);
-		mHDRBuffer.Image1Yuv = NULL;
-	}
-	if (mHDRBuffer.Image2Yuv != NULL){
-		free(mHDRBuffer.Image2Yuv);
-		mHDRBuffer.Image2Yuv = NULL;
-	}
-	if (mHDRBuffer.Image3Yuv != NULL){
-		free(mHDRBuffer.Image3Yuv);
-		mHDRBuffer.Image3Yuv = NULL;
-	}
-	if (mHDRBuffer.Image4Yuv != NULL){
-		free(mHDRBuffer.Image4Yuv);
-		mHDRBuffer.Image4Yuv = NULL;
-	}
-}
-void HDRSceneMode::SetCallBack(SceneNotifyCb Scenenotifycb,void* user)
-{
-	mSceneNotifyCb = Scenenotifycb;
-	mUser = user;
-}
-
-int HDRSceneMode::InitSceneMode(int width,int height)
-{
-	int ret;
-	mWidth	=	width;
-	mHeight	=	height;
-	ALOGD("HDR InitSceneModeframe size: %d x %d",mWidth,mHeight);
-
-	ret = RequestHDRBuffer();
-	if(ret == -1){
-		ALOGE("Request HDR Buffer failed");
-		return -1;
-	}		
-	return 0;
-}
-
-int HDRSceneMode::StartScenePicture()
-{
-	int ret;
-	const double LOG_2 = log(2);
-	int value_dark, value_bright;
-	struct isp_stat_buf	AeBuf;
-	struct isp_stat_buf	HistBuf;
-	
-	//check callback handle
-	if(mSceneNotifyCb == NULL) return -1;
-	
-	//request isp buffer
-	HistBuf.buf = malloc(0x200);
-	AeBuf.buf = malloc(0xc00);
-	if(AeBuf.buf == NULL || HistBuf.buf == NULL){
-		if(AeBuf.buf != NULL) free(AeBuf.buf);
-		if(HistBuf.buf != NULL) free(HistBuf.buf);
-		return -1;
-	}
-	
-	//get AE State
-	memset(AeBuf.buf,0,0xc00);
-	mSceneNotifyCb(SCENE_NOTIFY_CMD_GET_AE_STATE,(void*)&AeBuf,&ret,mUser);
-	
-	//get Hist state
-	memset(HistBuf.buf,0,0x200);
-	mSceneNotifyCb(SCENE_NOTIFY_CMD_GET_HIST_STATE,(void*)&HistBuf,&ret,mUser);
-
-	//get exposuregain
-	GetExposureGain(mWidth, mHeight, (uint32_t *)AeBuf.buf, (uint32_t *)HistBuf.buf, &mGainDark, &mGainBright);
-	
-	//get dark and bright value
-	value_dark = - int(25.0*log(1.0/mGainDark)/LOG_2+0.5);
-	value_bright = int(25.0*log(mGainBright)/LOG_2+0.5);
-	
-	ALOGD("gain_dark = %lf, gain_bright = %lf", mGainDark, mGainBright);
-	ALOGD("value_dark = %d, value_bright = %d", value_dark, value_bright);
-	
-	mHDRSetting.hdr_en = 1;
-	mHDRSetting.total_frames = 2;
-	mHDRSetting.values[0] = value_dark;
-	mHDRSetting.values[1] = value_bright;
-	mHDRSetting.values[2] = 0;
-	mHDRSetting.values[3] = 0;
-	mHDRSetting.values[4] = 0;
-	free(AeBuf.buf);
-	free(HistBuf.buf);
-	
-	// set GAIN and EXP
-	mSceneNotifyCb(SCENE_NOTIFY_CMD_SET_HDR_SETTING,(void*)&mHDRSetting,&ret,mUser);
-	//ALOGD("setHDRMode retrun = %d\n",ret);
-	mSceneNotifyCb(SCENE_NOTIFY_CMD_SET_3A_LOCK,(void*)8,&ret,mUser);
-	//ALOGD("set3ALock retrun = %d\n",ret);
-	mHDRState = HDRSTEP1;
-	return ret;
-}
-
-int HDRSceneMode::StopScenePicture()
-{
-	mHDRState = HDRSTEP0;
-	return 0;
-}
-
-int HDRSceneMode::GetCurrentFrameData(void* vaddr)
-{
-	int ret;
-	int FrameCnt;
-	mSceneNotifyCb(SCENE_NOTIFY_CMD_GET_HDR_FRAME_COUNT,(void*)&FrameCnt,&ret,mUser);	
-	if(FrameCnt > 3) return SCENE_CAPTURE_FAIL;
-	if(FrameCnt == 1)
-	{
-		if(mHDRState == HDRSTEP1)
-		{
-			ALOGD("step 1");
-			//save dark picture
-			int framesize = mWidth * mHeight * 3 >> 1;
-			memcpy(mHDRBuffer.Image0Yuv, vaddr, framesize);
-			mHDRState = HDRSTEP2;
-		}
-	}
-	
-	if(FrameCnt == 2)
-	{
-		if(mHDRState == HDRSTEP2)
-		{
-			ALOGD("step 2");
-			//save light picture
-			int frame_size = mWidth * mHeight * 3 >> 1;
-			memcpy(mHDRBuffer.Image1Yuv,vaddr, frame_size);
-			mHDRFinished = 1;
-			mHDRState = HDRSTEP3;
-		}
-	}
-	
-	if((FrameCnt <= 2) && (mHDRState != HDRSTEP3)) //???
-		return SCENE_CAPTURE_UNKNOW;
-
-	if(FrameCnt > 2 && mHDRState == HDRSTEP3)
-	{
-		struct isp_hdr_setting_t hdr_setting;
-		hdr_setting.hdr_en = 0;
-		hdr_setting.total_frames = 5;
-		hdr_setting.values[0] = -50;
-		hdr_setting.values[1] = 0;
-		hdr_setting.values[2] = 0;
-		hdr_setting.values[3] = 0;
-		hdr_setting.values[4] = 0;
-		mSceneNotifyCb(SCENE_NOTIFY_CMD_SET_HDR_SETTING,(void*)&hdr_setting,&ret,mUser);
-		mSceneNotifyCb(SCENE_NOTIFY_CMD_SET_3A_LOCK,(void*)0,&ret,mUser);
-		return SCENE_CAPTURE_DONE;
-	}
-
-	return SCENE_CAPTURE_UNKNOW;
-}
-
-int HDRSceneMode::PostScenePicture(void* vaddr)
-{
-	if(mHDRState == HDRSTEP3){
-		captureHDR(mHDRBuffer.Image0Yuv,
-				   mHDRBuffer.Image1Yuv,
-				   mHDRBuffer.Image2Yuv,
-				   mHDRBuffer.Image3Yuv,
-				   &mHDRFinished,
-				   mWidth,
-				   mHeight,
-				   mGainBright,
-				   mGainDark);
-	}
-	if(mHDRFinished){
-		ALOGD("hdr done");
-		memcpy(vaddr,mHDRBuffer.Image3Yuv,mWidth*mHeight*3 >> 1);
-		return SCENE_COMPUTE_DONE;
-	}
-	ALOGD("hdr fail");
-	return SCENE_COMPUTE_FAIL;
-}
-int HDRSceneMode::GetScenePictureState()
-{
-	return 0;
-}
-int HDRSceneMode::GetCurrentSceneMode()
-{
-	return mSceneMode;
-}
-void HDRSceneMode::ReleaseSceneMode()
-{
-	ALOGD("Release HDR SenceMode");
-	ReleaseHDRBuffer();
-}
-
-
-};
\ No newline at end of file
diff --git a/hardware/camera/SceneFactory/HDRSceneMode.h b/hardware/camera/SceneFactory/HDRSceneMode.h
deleted file mode 100755
index df486ce..0000000
--- a/hardware/camera/SceneFactory/HDRSceneMode.h
+++ /dev/null
@@ -1,71 +0,0 @@
-#ifndef __HDR_SCENE_MODE__
-#define __HDR_SCENE_MODE__
-
-#include <stdlib.h>
-#include <cutils/log.h>
-#include <math.h>
-
-#include "CameraPlatform.h"
-#include "ISceneMode.h"
-#include "hdr.h"
-
-#ifdef __PLATFORM_A64__
-#include <sunxi_camera.h>
-#else
-#include <videodev2_34.h>
-#endif
-
-namespace android {
-
-enum HDRState{
-	HDRSTEP0 = 0,	//used for init step, do nothing
-	HDRSTEP1 = 1,
-	HDRSTEP2 = 2,
-	HDRSTEP3 = 3,
-	HDRSTEP4 = 4,
-};
-struct HDRBuffer{
-	void*	Image0Yuv;
-	void*	Image1Yuv;
-	void*	Image2Yuv;
-	void*	Image3Yuv;
-	void*	Image4Yuv;
-};
-
-class HDRSceneMode : public ISceneMode {
-
-public:
-	HDRSceneMode();
-	~HDRSceneMode();
-
-/************************************************************
-* Public API for baseclass ISceneMode virtual function
-* it must be declared here and realized here
-*************************************************************/
-public:
-	int		InitSceneMode(int width,int height);
-	void	SetCallBack(SceneNotifyCb Scenenotifycb,void* user);
-	int		StartScenePicture();
-	int		StopScenePicture();
-	int		GetCurrentFrameData(void* vaddr);
-	int		PostScenePicture(void* vaddr);	
-	void	ReleaseSceneMode();
-	int		GetScenePictureState();
-	int		GetCurrentSceneMode();
-
-protected:
-	enum	HDRState mHDRState;
-	int 	mHDRFinished;
-
-	struct HDRBuffer mHDRBuffer;
-	struct isp_hdr_setting_t mHDRSetting;
-	double 	mGainBright;
-	double 	mGainDark;
-
-private:
-	int  	RequestHDRBuffer();
-	void 	ReleaseHDRBuffer();
-};
-
-};
-#endif
diff --git a/hardware/camera/SceneFactory/ISceneMode.h b/hardware/camera/SceneFactory/ISceneMode.h
deleted file mode 100755
index c39dd9c..0000000
--- a/hardware/camera/SceneFactory/ISceneMode.h
+++ /dev/null
@@ -1,115 +0,0 @@
-#ifndef __I_SCENE_MODE__
-#define __I_SCENE_MODE__
-
-namespace android {
-
-// type of scene notify callback
-typedef int (*SceneNotifyCb)(int cmd, void* data, int* ret,void* user);
-
-enum scene_mode {
-	SCENE_FACTORY_MODE_NONE			= 0,
-	//SCENE_FACTORY_MODE_BACKLIGHT		= 1,
-	//SCENE_FACTORY_MODE_BEACH_SNOW		= 2,
-	//SCENE_FACTORY_MODE_CANDLE_LIGHT	= 3,
-	//SCENE_FACTORY_MODE_DAWN_DUSK		= 4,
-	//SCENE_FACTORY_MODE_FALL_COLORS	= 5,
-	//SCENE_FACTORY_MODE_FIREWORKS		= 6,
-	//SCENE_FACTORY_MODE_LANDSCAPE		= 7,
-	SCENE_FACTORY_MODE_NIGHT		= 8,	//now we support the mode (8)
-	//SCENE_FACTORY_MODE_PARTY_INDOOR	= 9,
-	//SCENE_FACTORY_MODE_PORTRAIT		= 10,
-	//SCENE_FACTORY_MODE_SPORTS		= 11,
-	//CENE_FACTORY_MODE_SUNSET		= 12,
-	//SCENE_FACTORY_MODE_TEXT		= 13,
-	SCENE_FACTORY_MODE_AUTO			= 20,	//now we support the mode
-	SCENE_FACTORY_MODE_HDR			= 21,	//now we support the mode (21)
-};
-enum scene_state {
-	SCENE_CAPTURE_UNKNOW = 100,
-	SCENE_CAPTURE_DONE = 101,
-	SCENE_CAPTURE_FAIL = 102,
-	SCENE_COMPUTE_DONE = 103,
-	SCENE_COMPUTE_FAIL = 104,
-};
-enum SenceNotifyCMD{
-	SCENE_NOTIFY_CMD_GET_AE_STATE,
-	SCENE_NOTIFY_CMD_GET_HIST_STATE,
-	SCENE_NOTIFY_CMD_SET_3A_LOCK,
-	SCENE_NOTIFY_CMD_SET_HDR_SETTING,
-	SCENE_NOTIFY_CMD_GET_HDR_FRAME_COUNT,
-	//SCENE_NOTIFY_CMD_,
-	//SCENE_NOTIFY_CMD_,
-	//SCENE_NOTIFY_CMD_,
-};
-
-/*
-** SceneMode public interface.
-** All scene mode must extern it,and realize the virtual interfaces
-** The user(client) just care and use the public virtual interfaces
-*/
-class ISceneMode {
-public:
-	ISceneMode():	\
-		mSceneMode(SCENE_FACTORY_MODE_AUTO),	\
-		mWidth(0),mHeight(0),	\
-		mSceneNotifyCb(NULL),
-		mUser(NULL){};	//do nothing
-	virtual ~ISceneMode(){};
-
-public:
-	/* Do some software init,must be called after the SceneMode 
-	** constured, eg: alloc buffer.... Can't do some operation  
-	** about hardware here, eg: get AE state,set 3A lock ...
-	** width: capture frame width.
-	** height: capture frame height.
-	*/
-	virtual int	InitSceneMode(int width,int height) = 0;
-	
-	/*TODO: It seems to need a hardhare init interface????(or not)~~*/
-	
-	/* Set notify callback,user(client) must realize the callback function and set it,
-	** SceneMode can get some capture information through this callback.
-	** scenenotifycb: callback function handle.
-	** user:          the user(client) this point.
-	*/
-	virtual void	SetCallBack(SceneNotifyCb scenenotifycb,void* user) = 0;
-	
-	/* Start take sence picture,it must be called once when take sence picture
-	** shutter down, do some hardare or software setting,witch is differnt every time.
-	*/
-	virtual int	StartScenePicture() = 0;
-	
-	/* It must be called when take the scene picture end. */
-	virtual int	StopScenePicture() = 0;
-	
-	/* Get current frame source data, it must be called per frame in capture thread,
-	** SceneMode must distinguish the frame status weather the frame data needed or not.
-	** vaddr: capture frame data virtual addr
-	** return:when SenceMode get enough frame return SCENE_CAPTURE_DONE(101)
-	*/
-	virtual int	GetCurrentFrameData(void* vaddr) = 0;
-	
-	/* Start to compute the scene picture, 
-	** picture computed completly,copy the target scene picturn into vaddr,return SCENE_COMPUTE_DONE.
-	** picture computed uncompletly, do nothing about the vaddr,return SCENE_COMPUTE_FAIL.
-	*/
-	virtual int	PostScenePicture(void* vaddr) = 0;
-	
-	/*Release*/
-	virtual void	ReleaseSceneMode() = 0;
-	
-	/*Return current SceneMode state*/
-	virtual int	GetScenePictureState() = 0;
-	/*return current SceneMode mode*/
-	virtual int	GetCurrentSceneMode() = 0;
-
-protected:
-	int mSceneMode;
-	int mWidth;
-	int mHeight;
-	SceneNotifyCb mSceneNotifyCb;
-	void* mUser;
-};
-
-};
-#endif
\ No newline at end of file
diff --git a/hardware/camera/SceneFactory/NightSceneMode.cpp b/hardware/camera/SceneFactory/NightSceneMode.cpp
deleted file mode 100755
index f16e9ea..0000000
--- a/hardware/camera/SceneFactory/NightSceneMode.cpp
+++ /dev/null
@@ -1,193 +0,0 @@
-#include "NightSceneMode.h"
-#define LOG_TAG "NightSceneMode"
-namespace android {
-
-NightSceneMode::NightSceneMode()
-{
-	mWidth = 0;
-	mHeight = 0;
-	mSceneNotifyCb = NULL;
-	mUser = NULL;
-	mNightFinished = 0;
-	mGainBright = 0.0;
-	mGainDark = 0.0;
-	mSceneMode = SCENE_FACTORY_MODE_NIGHT;
-	memset(&mNightBuffer,0,sizeof(mNightBuffer));
-	mNightState = NightSTEP0;
-}
-
-NightSceneMode::~NightSceneMode()
-{
-
-}
-
-int NightSceneMode::RequestNightBuffer()
-{
-	int ret = 0;
-	int framesize = mWidth * mHeight * 3 >>1;
-	// used for Night Scene mode image
-	if (mNightBuffer.Image0Yuv == NULL)
-	    mNightBuffer.Image0Yuv = (void *)malloc(framesize);
-	if (mNightBuffer.Image1Yuv == NULL)
-	    mNightBuffer.Image1Yuv = (void *)malloc(framesize);
-	if (mNightBuffer.Image2Yuv == NULL)
-	    mNightBuffer.Image2Yuv = (void *)malloc(framesize);
-	if (mNightBuffer.Image3Yuv == NULL)
-	    mNightBuffer.Image3Yuv = (void *)malloc(framesize);
-	if (mNightBuffer.Image4Yuv == NULL)
-	    mNightBuffer.Image4Yuv = (void *)malloc(framesize);
-
-	ALOGD("Request Night Buffer Successes!");
-	//malloc failed, release all buffers
-	if ((mNightBuffer.Image0Yuv == NULL) ||  \
-		 (mNightBuffer.Image1Yuv == NULL) || \
-		 (mNightBuffer.Image2Yuv == NULL) || \
-		 (mNightBuffer.Image3Yuv == NULL) || \
-		 (mNightBuffer.Image4Yuv == NULL)) {
-
-		ReleaseNightBuffer();
-		ALOGE("Request Night buffer failed!!!");
-		ret = -1;
-	}
-	return ret;
-}
-void NightSceneMode::ReleaseNightBuffer()
-{
-	//release all buffers
-	if (mNightBuffer.Image0Yuv != NULL){
-		free(mNightBuffer.Image0Yuv);
-		mNightBuffer.Image0Yuv = NULL;
-	}
-	if (mNightBuffer.Image1Yuv != NULL){
-		free(mNightBuffer.Image1Yuv);
-		mNightBuffer.Image1Yuv = NULL;
-	}
-	if (mNightBuffer.Image2Yuv != NULL){
-		free(mNightBuffer.Image2Yuv);
-		mNightBuffer.Image2Yuv = NULL;
-	}
-	if (mNightBuffer.Image3Yuv != NULL){
-		free(mNightBuffer.Image3Yuv);
-		mNightBuffer.Image3Yuv = NULL;
-	}
-	if (mNightBuffer.Image4Yuv != NULL){
-		free(mNightBuffer.Image4Yuv);
-		mNightBuffer.Image4Yuv = NULL;
-	}
-}
-void NightSceneMode::SetCallBack(SceneNotifyCb scenenotifycb,void* user)
-{
-	mSceneNotifyCb = scenenotifycb;
-	mUser = user;
-}
-
-int NightSceneMode::InitSceneMode(int width,int height)
-{
-	int ret;
-	mWidth	=	width;
-	mHeight	=	height;
-	ALOGD("Night InitSceneModeframe size: %d x %d",mWidth,mHeight);
-
-	ret = RequestNightBuffer();
-	if(ret == -1){
-		ALOGE("Request Night Buffer failed");
-		return -1;
-	}		
-	return 0;
-}
-
-int NightSceneMode::StartScenePicture()
-{
-	mNightState = NightSTEP1;
-	return 0;
-}
-
-int NightSceneMode::StopScenePicture()
-{
-	mNightState = NightSTEP0;
-	return 0;
-}
-
-int NightSceneMode::GetCurrentFrameData(void* vaddr)
-{
-	int ret;
-	if(mNightState == NightSTEP1)
-	{
-		ALOGD("step 1");
-		//save 1st picture
-		int framesize = mWidth * mHeight * 3 >> 1;
-		memcpy(mNightBuffer.Image0Yuv, vaddr, framesize);
-		mNightState = NightSTEP2;
-	}	
-	else if(mNightState == NightSTEP2)
-	{
-		ALOGD("step 2");
-		//save 2nd picture
-		int frame_size = mWidth * mHeight * 3 >> 1;
-		memcpy(mNightBuffer.Image1Yuv, vaddr, frame_size);
-		mNightState = NightSTEP3;
-	}
-	else if(mNightState == NightSTEP3)
-	{
-		ALOGD("step 3");
-		//save 3rd picture
-		int frame_size = mWidth * mHeight * 3 >> 1;
-		memcpy(mNightBuffer.Image2Yuv, vaddr, frame_size);
-		mNightState = NightSTEP4;
-	}
-	else if(mNightState == NightSTEP4)
-	{
-		ALOGD("step 4");
-		//save 4th picture
-		int frame_size = mWidth * mHeight * 3 >> 1;
-		memcpy(mNightBuffer.Image3Yuv, vaddr, frame_size);
-		mNightFinished = 1;
-		mNightState = NightSTEP5;
-	}
-	
-	if(mNightState <= 4) //???
-		return SCENE_CAPTURE_UNKNOW;
-
-	if(mNightState == NightSTEP5)
-	{		
-		mSceneNotifyCb(SCENE_NOTIFY_CMD_SET_3A_LOCK,(void*)0,&ret,mUser);
-		return SCENE_CAPTURE_DONE;
-	}
-	return SCENE_CAPTURE_UNKNOW;
-}
-
-int NightSceneMode::PostScenePicture(void* vaddr)
-{
-	captureDenoise(mNightBuffer.Image0Yuv,
-			   	   mNightBuffer.Image1Yuv,
-			   	   mNightBuffer.Image2Yuv,
-			   	   mNightBuffer.Image3Yuv,
-			   	   mNightBuffer.Image4Yuv,
-			 	   &mNightFinished,
-			   	   mWidth,
-			   	   mHeight);
-	if(mNightFinished){
-		ALOGD("Night Denoise done");
-		memcpy(vaddr,mNightBuffer.Image4Yuv,mWidth*mHeight*3 >> 1);
-		return SCENE_COMPUTE_DONE;
-	}
-	ALOGD("Night Denoise fail");
-	return SCENE_COMPUTE_FAIL;
-}
-
-int NightSceneMode::GetScenePictureState()
-{
-	return 0;
-}
-
-int NightSceneMode::GetCurrentSceneMode()
-{
-	return mSceneMode;
-}
-
-void NightSceneMode::ReleaseSceneMode()
-{
-	ReleaseNightBuffer();
-}
-
-};
\ No newline at end of file
diff --git a/hardware/camera/SceneFactory/NightSceneMode.h b/hardware/camera/SceneFactory/NightSceneMode.h
deleted file mode 100755
index a90cbec..0000000
--- a/hardware/camera/SceneFactory/NightSceneMode.h
+++ /dev/null
@@ -1,72 +0,0 @@
-#ifndef __NIGHT_SCENE_MODE__
-#define __NIGHT_SCENE_MODE__
-
-#include <stdlib.h>
-#include <cutils/log.h>
-#include <math.h>
-
-#include "CameraPlatform.h"
-#include "ISceneMode.h"
-#include "hdr.h"
-
-#ifdef __PLATFORM_A64__
-#include <sunxi_camera.h>
-#else
-#include <videodev2_34.h>
-#endif
-
-namespace android {
-
-enum NightState{
-	NightSTEP0 = 0,	//used for init step, do nothing
-	NightSTEP1 = 1,
-	NightSTEP2 = 2,
-	NightSTEP3 = 3,
-	NightSTEP4 = 4,
-	NightSTEP5 = 5,
-};
-struct NightBuffer{
-	void*	Image0Yuv;
-	void*	Image1Yuv;
-	void*	Image2Yuv;
-	void*	Image3Yuv;
-	void*	Image4Yuv;
-};
-
-class NightSceneMode : public ISceneMode {
-
-public:
-	NightSceneMode();
-	~NightSceneMode();
-
-/************************************************************
-* Public API for baseclass ISceneMode virtual function
-* it must be declared here and realized here
-*************************************************************/
-public:
-	int		InitSceneMode(int width,int height);
-	void	SetCallBack(SceneNotifyCb scenenotifycb,void* user);
-	int		StartScenePicture();
-	int		StopScenePicture();
-	int		GetCurrentFrameData(void* vaddr);
-	int		PostScenePicture(void* vaddr);	
-	void	ReleaseSceneMode();
-	int		GetScenePictureState();
-	int		GetCurrentSceneMode();
-
-protected:
-	enum 	NightState mNightState;
-	int 	mNightFinished;
-
-	struct 	NightBuffer mNightBuffer;
-	//struct isp_hdr_setting_t mNightSetting;
-	double 	mGainBright;
-	double 	mGainDark;
-
-private:
-	int  	RequestNightBuffer();
-	void 	ReleaseNightBuffer();
-};
-
-};
-#endif
diff --git a/hardware/camera/SceneFactory/SceneModeFactory.cpp b/hardware/camera/SceneFactory/SceneModeFactory.cpp
deleted file mode 100755
index 74675d2..0000000
--- a/hardware/camera/SceneFactory/SceneModeFactory.cpp
+++ /dev/null
@@ -1,84 +0,0 @@
-#include "SceneModeFactory.h"
-
-#define LOG_TAG "SceneModeFactory"
-
-namespace android {
-
-ISceneMode* SceneModeFactory::CreateSceneMode(int SceneMode)
-{
-	ISceneMode* mode = NULL;
-	mSceneMode = SceneMode;
-	switch(mSceneMode)
-	{
-		case SCENE_FACTORY_MODE_HDR:
-			mode = HDRSceneModeGetInstance();
-			if(mode == NULL)
-				ALOGE("Create HDR Scene Mode failed!");
-			break;
-		case SCENE_FACTORY_MODE_NIGHT:
-			mode = NightSceneModeGetInstance();
-			if(mode == NULL)
-				ALOGE("Create Night Scene Mode failed!");
-			break;
-		default:
-			break;
-	}
-	return mode;
-}
-
-void SceneModeFactory::DestorySceneMode(ISceneMode* mode)
-{	
-	//destory all mode
-	ALOGD("DestorySceneMode %d",mSceneMode);
-	if(mode == NULL){
-		mSceneMode = SCENE_FACTORY_MODE_AUTO;
-		if(mHDRSceneMode != NULL){
-			mHDRSceneMode->ReleaseSceneMode();
-			delete(mHDRSceneMode);
-			mHDRSceneMode = NULL;
-		}
-		//Night mode
-		if(mNightSceneMode != NULL){
-			mNightSceneMode->ReleaseSceneMode();
-			delete(mNightSceneMode);
-			mNightSceneMode = NULL;
-		}
-		return;
-	}
-	//just destory the HDR mode
-	switch(mode->GetCurrentSceneMode())
-	{
-		case SCENE_FACTORY_MODE_HDR:
-			if(mHDRSceneMode != NULL){
-				delete(mHDRSceneMode);
-				mHDRSceneMode = NULL;
-			}
-			break;
-		case SCENE_FACTORY_MODE_NIGHT:
-			if(mNightSceneMode != NULL){
-				delete(mNightSceneMode);
-				mNightSceneMode = NULL;
-			}
-			break;
-		default:
-			break;
-	}
-	mSceneMode = SCENE_FACTORY_MODE_AUTO;
-	return;
-}
-
-HDRSceneMode* SceneModeFactory::HDRSceneModeGetInstance()
-{
-	if(mHDRSceneMode == NULL)
-		mHDRSceneMode = new HDRSceneMode();
-	return 	mHDRSceneMode;
-}
-
-NightSceneMode* SceneModeFactory::NightSceneModeGetInstance()
-{
-	if(mNightSceneMode == NULL)
-		mNightSceneMode = new NightSceneMode();
-	return 	mNightSceneMode;
-}
-
-};
\ No newline at end of file
diff --git a/hardware/camera/SceneFactory/SceneModeFactory.h b/hardware/camera/SceneFactory/SceneModeFactory.h
deleted file mode 100755
index 7e9254a..0000000
--- a/hardware/camera/SceneFactory/SceneModeFactory.h
+++ /dev/null
@@ -1,33 +0,0 @@
-#ifndef __SCENE_MODE_FACTORY_H__
-#define __SCENE_MODE_FACTORY_H__
-#include <cutils/log.h>
-#include "ISceneMode.h"
-#include "HDRSceneMode.h"
-#include "NightSceneMode.h"
-
-namespace android {
-
-/* ScenceMode factory,all the SenceMode created and destory in here*/
-class SceneModeFactory {
-public:
-	SceneModeFactory():	\
-		mSceneMode(SCENE_FACTORY_MODE_AUTO),mHDRSceneMode(NULL),mNightSceneMode(NULL){};
-	~SceneModeFactory(){};
-
-private:
-	int mSceneMode;
-	HDRSceneMode* mHDRSceneMode;	//now we support HDR mode
-	NightSceneMode* mNightSceneMode; // now we support Night mode
-
-private:
-	HDRSceneMode* HDRSceneModeGetInstance();
-	NightSceneMode* NightSceneModeGetInstance();
-public:
-	ISceneMode* CreateSceneMode(int mode);
-	void DestorySceneMode(ISceneMode* mode);
-};
-
-
-};
-
-#endif
\ No newline at end of file
diff --git a/hardware/camera/SceneFactory/hdr.h b/hardware/camera/SceneFactory/hdr.h
deleted file mode 100755
index 36a8bba..0000000
--- a/hardware/camera/SceneFactory/hdr.h
+++ /dev/null
@@ -1,81 +0,0 @@
-#ifndef __HDR_H___
-#define __HDR_H___
-
-#define  MAX(a,b)              (((a) > (b)) ? (a) : (b))
-#define  MIN(a,b)              (((a) < (b)) ? (a) : (b))
-
-#define Radius(u,v)            ((Au=Abs((u))) > (Av=Abs((v))) ? \
-                                (Aw=Av/Au, Au*sqrt_new(1.0+Aw*Aw)) : \
-                                (Av ? (Aw=Au/Av, Av*sqrt_new(1.+Aw*Aw)) : 0.0f) )
-
-#define Sign(u,v)               ( (v)>=0.0 ? Abs(u) : -Abs(u) )
-
-#define Max(u,v)                ( (u)>(v)?  (u) : (v) )
-
-#define Abs(x)                  ( (x)>0.0f?  (x) : (-(x)) )
-
-#define Sqrt(a, b)              (MAX(a,b) + MIN(a,b)/2)
-
-#define  CLIP(a,i,s)            (((a) > (s)) ? (s) : MAX(a,i))
-
-struct HarrisPoint
-{
-	int row;
-	int col;
-	float row_sub;
-	float col_sub;
-};
-
-struct NormPoint
-{
-	double x;
-	double y;
-	double w;
-};
-
-struct PixelPoint
-{
-	int x;
-	int y;
-};
-
-struct LineSegment
-{
-	PixelPoint corner[2];
-};
-
-struct Quadrilateral
-{
-	PixelPoint corner[4];
-};
-
-struct Octagon
-{
-	int numgon;
-	PixelPoint corner[8];
-};
-
-struct Rectangle
-{
-	int xmin;
-	int xmax;
-	int ymin;
-	int ymax;
-};
-
-
-extern "C" void ImgRGB2NV21_neon(unsigned char *pu8RgbBuffer, unsigned char *pu8SrcYUV, int *l32Width_stride, int l32Height);
-
-extern "C" void ImgNV212RGB_neon(unsigned char *pu8RgbBuffer, int pu8SrcYUV, int l32Width, int l32Height);
-
-extern void homology_display(double *matH);
-
-extern void GetExposureGain(const int width, const int height, unsigned int *AeStat, unsigned int *HistStat,
-						double *gain_dark_ptr, double *gain_bright_ptr);
-
-extern void captureHDR(void * DarkYuv, void * LightYuv, void * TransYuv, void * HDRYuv, int * HDRMode_ptr,
-				const int width, const int height, const double gain_bright, const double gain_dark);
-
-extern void captureDenoise(void * Image0Yuv, void * Image1Yuv, void * Image2Yuv, void * Image3Yuv, void * Image4Yuv, int * DenosieMode_ptr, const int width, const int height);
-
-#endif     // __HDR_H___
\ No newline at end of file
diff --git a/hardware/camera/V4L2CameraDevice.cpp b/hardware/camera/V4L2CameraDevice.cpp
new file mode 100755
index 0000000..2c6b103
--- /dev/null
+++ b/hardware/camera/V4L2CameraDevice.cpp
@@ -0,0 +1,1806 @@
+
+#include "CameraDebug.h"
+#if DBG_V4L2_CAMERA
+#define LOG_NDEBUG 0
+#endif
+#define LOG_TAG "V4L2CameraDevice"
+#include <cutils/log.h>
+
+#include <sys/mman.h> 
+#include <videodev2.h>
+#include <linux/videodev.h> 
+
+#ifdef USE_MP_CONVERT
+#include <g2d_driver.h>
+#endif
+
+#include "V4L2CameraDevice.h"
+#include "CallbackNotifier.h"
+#include "PreviewWindow.h"
+#include "CameraHardware.h"
+
+#define CHECK_NO_ERROR(a)						\
+	if (a != NO_ERROR) {						\
+		if (mCameraFd != NULL) {				\
+			close(mCameraFd);					\
+			mCameraFd = NULL;					\
+		}										\
+		return EINVAL;							\
+	}
+	
+namespace android {
+	
+static void calculateCrop(Rect * rect, int new_zoom, int max_zoom, int width, int height)
+{
+	if (max_zoom == 0)
+	{
+		rect->left		= 0;
+		rect->top		= 0;
+		rect->right 	= width -1;
+		rect->bottom	= height -1;
+	}
+	else
+	{
+		int new_ratio = (new_zoom * 2 * 100 / max_zoom + 100);
+		rect->left		= (width - (width * 100) / new_ratio)/2;
+		rect->top		= (height - (height * 100) / new_ratio)/2;
+		rect->right 	= rect->left + (width * 100) / new_ratio -1;
+		rect->bottom	= rect->top  + (height * 100) / new_ratio - 1;
+	}
+	
+	// LOGD("crop: [%d, %d, %d, %d]", rect->left, rect->top, rect->right, rect->bottom);
+}
+
+static void YUYVToNV12(const void* yuyv, void *nv12, int width, int height)
+{
+	uint8_t* Y	= (uint8_t*)nv12;
+	uint8_t* UV = (uint8_t*)Y + width * height;
+	
+	for(int i = 0; i < height; i += 2)
+	{
+		for (int j = 0; j < width; j++)
+		{
+			*(uint8_t*)((uint8_t*)Y + i * width + j) = *(uint8_t*)((uint8_t*)yuyv + i * width * 2 + j * 2);
+			*(uint8_t*)((uint8_t*)Y + (i + 1) * width + j) = *(uint8_t*)((uint8_t*)yuyv + (i + 1) * width * 2 + j * 2);
+			*(uint8_t*)((uint8_t*)UV + ((i * width) >> 1) + j) = *(uint8_t*)((uint8_t*)yuyv + i * width * 2 + j * 2 + 1);
+		}
+	}
+}
+
+static void YUYVToNV21(const void* yuyv, void *nv21, int width, int height)
+{
+	uint8_t* Y	= (uint8_t*)nv21;
+	uint8_t* VU = (uint8_t*)Y + width * height;
+	
+	for(int i = 0; i < height; i += 2)
+	{
+		for (int j = 0; j < width; j++)
+		{
+			*(uint8_t*)((uint8_t*)Y + i * width + j) = *(uint8_t*)((uint8_t*)yuyv + i * width * 2 + j * 2);
+			*(uint8_t*)((uint8_t*)Y + (i + 1) * width + j) = *(uint8_t*)((uint8_t*)yuyv + (i + 1) * width * 2 + j * 2);
+
+			if (j % 2)
+			{
+				if (j < width - 1)
+				{
+					*(uint8_t*)((uint8_t*)VU + ((i * width) >> 1) + j) = *(uint8_t*)((uint8_t*)yuyv + i * width * 2 + (j + 1) * 2 + 1);
+				}
+			}
+			else
+			{
+				if (j > 1)
+				{
+					*(uint8_t*)((uint8_t*)VU + ((i * width) >> 1) + j) = *(uint8_t*)((uint8_t*)yuyv + i * width * 2 + (j - 1) * 2 + 1); 		
+				}
+			}
+		}
+	}
+}
+
+#ifdef USE_MP_CONVERT
+void V4L2CameraDevice::YUYVToYUV420C(const void* yuyv, void *yuv420, int width, int height)
+{
+	g2d_blt		blit_para;
+	int 		err;
+	
+	blit_para.src_image.addr[0]      = (int)yuyv;
+	blit_para.src_image.addr[1]      = (int)yuyv + width * height;
+	blit_para.src_image.w            = width;	      /* src buffer width in pixel units */
+	blit_para.src_image.h            = height;	      /* src buffer height in pixel units */
+	blit_para.src_image.format       = G2D_FMT_IYUV422;
+	blit_para.src_image.pixel_seq    = G2D_SEQ_NORMAL;          /* not use now */
+	blit_para.src_rect.x             = 0;						/* src rect->x in pixel */
+	blit_para.src_rect.y             = 0;						/* src rect->y in pixel */
+	blit_para.src_rect.w             = width;			/* src rect->w in pixel */
+	blit_para.src_rect.h             = height;			/* src rect->h in pixel */
+
+	blit_para.dst_image.addr[0]      = (int)yuv420;
+	blit_para.dst_image.addr[1]      = (int)yuv420 + width * height;
+	blit_para.dst_image.w            = width;	      /* dst buffer width in pixel units */			
+	blit_para.dst_image.h            = height;	      /* dst buffer height in pixel units */
+	blit_para.dst_image.format       = G2D_FMT_PYUV420UVC;
+	blit_para.dst_image.pixel_seq    = (mVideoFormat == V4L2_PIX_FMT_NV12) ? G2D_SEQ_NORMAL : G2D_SEQ_VUVU;          /* not use now */
+	blit_para.dst_x                  = 0;					/* dst rect->x in pixel */
+	blit_para.dst_y                  = 0;					/* dst rect->y in pixel */
+	blit_para.color                  = 0xff;          		/* fix me*/
+	blit_para.alpha                  = 0xff;                /* globe alpha */ 
+
+	blit_para.flag = G2D_BLT_NONE; // G2D_BLT_FLIP_HORIZONTAL;
+
+	err = ioctl(mG2DHandle, G2D_CMD_BITBLT, (unsigned long)&blit_para);				
+	if(err < 0) 	
+	{			
+		LOGE("ioctl, G2D_CMD_BITBLT failed");
+		return;
+	}
+}
+
+void V4L2CameraDevice::NV21ToYV12(const void* nv21, void *yv12, int width, int height)
+{
+	g2d_blt		blit_para;
+	int 		err;
+	int			u, v;
+	if (mVideoFormat == V4L2_PIX_FMT_NV21)
+	{
+		u = 1;
+		v = 2;
+	}
+	else
+	{
+		u = 2;
+		v = 1;
+	}
+	
+	blit_para.src_image.addr[0]      = (int)nv21;
+	blit_para.src_image.addr[1]      = (int)nv21 + width * height;
+	blit_para.src_image.w            = width;	      /* src buffer width in pixel units */
+	blit_para.src_image.h            = height;	      /* src buffer height in pixel units */
+	blit_para.src_image.format       = G2D_FMT_PYUV420UVC;
+	blit_para.src_image.pixel_seq    = G2D_SEQ_NORMAL;//G2D_SEQ_VUVU;          /*  */
+	blit_para.src_rect.x             = 0;						/* src rect->x in pixel */
+	blit_para.src_rect.y             = 0;						/* src rect->y in pixel */
+	blit_para.src_rect.w             = width;			/* src rect->w in pixel */
+	blit_para.src_rect.h             = height;			/* src rect->h in pixel */
+
+	blit_para.dst_image.addr[0]      = (int)yv12;							// y
+	blit_para.dst_image.addr[u]      = (int)yv12 + width * height;			// v
+	blit_para.dst_image.addr[v]      = (int)yv12 + width * height * 5 / 4;	// u
+	blit_para.dst_image.w            = width;	      /* dst buffer width in pixel units */			
+	blit_para.dst_image.h            = height;	      /* dst buffer height in pixel units */
+	blit_para.dst_image.format       = G2D_FMT_PYUV420;
+	blit_para.dst_image.pixel_seq    = G2D_SEQ_NORMAL;          /* not use now */
+	blit_para.dst_x                  = 0;					/* dst rect->x in pixel */
+	blit_para.dst_y                  = 0;					/* dst rect->y in pixel */
+	blit_para.color                  = 0xff;          		/* fix me*/
+	blit_para.alpha                  = 0xff;                /* globe alpha */ 
+	
+	blit_para.flag = G2D_BLT_NONE;
+	
+	err = ioctl(mG2DHandle , G2D_CMD_BITBLT, (unsigned long)&blit_para);				
+	if(err < 0)
+	{
+		LOGE("NV21ToYV12 ioctl, G2D_CMD_BITBLT failed");
+		return;
+	}
+}
+#endif
+
+DBG_TIME_AVG_BEGIN(TAG_CONTINUOUS_PICTURE);
+
+V4L2CameraDevice::V4L2CameraDevice(CameraHardware* camera_hal,
+								   PreviewWindow * preview_window, 
+    							   CallbackNotifier * cb)
+    : mCameraHardware(camera_hal),
+      mPreviewWindow(preview_window),
+      mCallbackNotifier(cb),
+      mCameraDeviceState(STATE_CONSTRUCTED),
+      mCaptureThreadState(CAPTURE_STATE_NULL),
+      mCameraFd(0),
+      mIsUsbCamera(false),
+      mTakePictureState(TAKE_PICTURE_NULL),
+      mIsPicCopy(false),
+      mFrameWidth(0),
+      mFrameHeight(0),
+      mThumbWidth(0),
+      mThumbHeight(0),
+      mCurFrameTimestamp(0),
+      mBufferCnt(NB_BUFFER),
+      mUseHwEncoder(false),
+	  mNewZoom(0),
+	  mLastZoom(-1),
+	  mMaxZoom(0xffffffff),
+	  mCaptureFormat(V4L2_PIX_FMT_NV21),
+	  mVideoFormat(V4L2_PIX_FMT_NV21)
+#ifdef USE_MP_CONVERT
+	  ,mG2DHandle(0)
+#endif
+	  ,mCurrentV4l2buf(NULL)
+	  ,mCanBeDisconnected(false)
+	  ,mContinuousPictureStarted(false)
+	  ,mContinuousPictureCnt(0)
+	  ,mContinuousPictureMax(0)
+	  ,mContinuousPictureStartTime(0)
+	  ,mContinuousPictureLast(0)
+	  ,mContinuousPictureAfter(0)
+	  ,mFaceDectectLast(0)
+	  ,mFaceDectectAfter(0)
+	  ,mPreviewLast(0)
+	  ,mPreviewAfter(0)
+	  ,mFrameRate(30)
+	  ,mVideoHint(false)
+{
+	LOGV("V4L2CameraDevice construct");
+
+	memset(&mHalCameraInfo, 0, sizeof(mHalCameraInfo));
+	memset(&mRectCrop, 0, sizeof(Rect));
+	memset(&mMapMem, 0, sizeof(v4l2_mem_map_t));
+	memset(&mVideoBuffer, 0, sizeof(bufferManagerQ_t));
+
+	// init preview buffer queue
+	OSAL_QueueCreate(&mQueueBufferPreview, NB_BUFFER);
+	OSAL_QueueCreate(&mQueueBufferPicture, 2);
+	
+	// init capture thread
+	mCaptureThread = new DoCaptureThread(this);
+	pthread_mutex_init(&mCaptureMutex, NULL);
+	pthread_cond_init(&mCaptureCond, NULL);
+	mCaptureThreadState = CAPTURE_STATE_PAUSED;
+	mCaptureThread->startThread();
+
+	// init preview thread
+	mPreviewThread = new DoPreviewThread(this);
+	pthread_mutex_init(&mPreviewMutex, NULL);
+	pthread_cond_init(&mPreviewCond, NULL);
+	mPreviewThread->startThread();
+
+	// init picture thread
+	mPictureThread = new DoPictureThread(this);
+	pthread_mutex_init(&mPictureMutex, NULL);
+	pthread_cond_init(&mPictureCond, NULL);
+	mPictureThread->startThread();
+	
+	pthread_mutex_init(&mConnectMutex, NULL);
+	pthread_cond_init(&mConnectCond, NULL);
+	
+	// init continuous picture thread
+	mContinuousPictureThread = new DoContinuousPictureThread(this);
+	pthread_mutex_init(&mContinuousPictureMutex, NULL);
+	pthread_cond_init(&mContinuousPictureCond, NULL);
+	mContinuousPictureThread->startThread();
+}
+
+V4L2CameraDevice::~V4L2CameraDevice()
+{
+	LOGV("V4L2CameraDevice disconstruct");
+
+	if (mCaptureThread != NULL)
+	{
+		mCaptureThread->stopThread();
+		pthread_cond_signal(&mCaptureCond);
+		mCaptureThread.clear();
+		mCaptureThread = 0;
+	}
+
+	if (mPreviewThread != NULL)
+	{
+		mPreviewThread->stopThread();
+		pthread_cond_signal(&mPreviewCond);
+		mPreviewThread.clear();
+		mPreviewThread = 0;
+	}
+
+	if (mPictureThread != NULL)
+	{
+		mPictureThread->stopThread();
+		pthread_cond_signal(&mPictureCond);
+		mPictureThread.clear();
+		mPictureThread = 0;
+	}
+
+	if (mContinuousPictureThread != NULL)
+	{
+		mContinuousPictureThread->stopThread();
+		pthread_cond_signal(&mContinuousPictureCond);
+		mContinuousPictureThread.clear();
+		mContinuousPictureThread = 0;
+	}
+
+	pthread_mutex_destroy(&mCaptureMutex);
+	pthread_cond_destroy(&mCaptureCond);
+
+	pthread_mutex_destroy(&mPreviewMutex);
+	pthread_cond_destroy(&mPreviewCond);
+	
+	pthread_mutex_destroy(&mPictureMutex);
+	pthread_cond_destroy(&mPictureCond);
+	
+	pthread_mutex_destroy(&mConnectMutex);
+	pthread_cond_destroy(&mConnectCond);
+	
+	pthread_mutex_destroy(&mContinuousPictureMutex);
+	pthread_cond_destroy(&mContinuousPictureCond);
+	
+	OSAL_QueueTerminate(&mQueueBufferPreview);
+	OSAL_QueueTerminate(&mQueueBufferPicture);
+}
+
+/****************************************************************************
+ * V4L2CameraDevice interface implementation.
+ ***************************************************************************/
+
+status_t V4L2CameraDevice::connectDevice(HALCameraInfo * halInfo)
+{
+	F_LOG;
+
+    Mutex::Autolock locker(&mObjectLock);
+	
+	if (isConnected()) 
+	{
+		LOGW("%s: camera device is already connected.", __FUNCTION__);
+		return NO_ERROR;
+	}
+
+	// open v4l2 camera device
+	int ret = openCameraDev(halInfo);
+	if (ret != OK)
+	{
+		return ret;
+	}
+
+	memcpy((void*)&mHalCameraInfo, (void*)halInfo, sizeof(HALCameraInfo));
+
+#ifdef USE_MP_CONVERT
+	if (mIsUsbCamera)
+	{
+		// open MP driver
+		mG2DHandle = open("/dev/g2d", O_RDWR, 0);
+		if (mG2DHandle < 0)
+		{
+			LOGE("open /dev/g2d failed");
+			return -1;
+		}
+		LOGV("open /dev/g2d OK");
+	}
+#endif 
+
+#ifdef USE_ION_MEM_ALLOCATOR
+	ret = ion_alloc_open();
+	if (ret < 0)
+	{
+		LOGE("ion_alloc_open failed");
+		return -EINVAL;
+	}
+	LOGV("ion_alloc_open ok");
+
+	// used for normal picture mode
+	mPicBuffer.addrVirY = (int)ion_alloc_alloc(MAX_PICTURE_SIZE);
+	mPicBuffer.addrPhyY = ion_alloc_vir2phy((void*)mPicBuffer.addrVirY);
+#else USE_SUNXI_MEM_ALLOCATOR
+	ret = sunxi_alloc_open();
+	if (ret < 0)
+	{
+		LOGE("sunxi_alloc_open failed");
+		return -EINVAL;
+	}
+	LOGV("sunxi_alloc_open ok");
+
+	// used for normal picture mode
+	mPicBuffer.addrVirY = (int)sunxi_alloc_alloc(MAX_PICTURE_SIZE);
+	mPicBuffer.addrPhyY = sunxi_alloc_vir2phy((void *)mPicBuffer.addrVirY);
+#endif
+	
+	/* There is a device to connect to. */
+	mCameraDeviceState = STATE_CONNECTED;
+
+    return NO_ERROR;
+}
+
+status_t V4L2CameraDevice::disconnectDevice()
+{
+	F_LOG;
+	
+	Mutex::Autolock locker(&mObjectLock);
+	
+	if (!isConnected()) 
+	{
+		LOGW("%s: camera device is already disconnected.", __FUNCTION__);
+		return NO_ERROR;
+	}
+	
+	if (isStarted()) 
+	{
+		LOGE("%s: Cannot disconnect from the started device.", __FUNCTION__);
+		return -EINVAL;
+	}
+	
+	// close v4l2 camera device
+	closeCameraDev();
+	
+#ifdef USE_MP_CONVERT
+	if(mG2DHandle != NULL)
+	{
+		close(mG2DHandle);
+		mG2DHandle = NULL;
+	}
+#endif
+
+#ifdef USE_ION_MEM_ALLOCATOR
+    if (mPicBuffer.addrVirY != NULL)
+	{
+		ion_alloc_free((void*)mPicBuffer.addrVirY);
+		mPicBuffer.addrPhyY = 0;
+	}
+	int ret = ion_alloc_close();
+	if (ret < 0)
+	{
+		LOGE("ion_alloc_close failed\n");
+	}
+	LOGD("ion_alloc_close ok");
+#else USE_SUNXI_MEM_ALLOCATOR
+	if (mPicBuffer.addrVirY != NULL)
+	{
+		sunxi_alloc_free((void*)mPicBuffer.addrVirY);
+		mPicBuffer.addrPhyY = 0;
+	}
+    int ret = sunxi_alloc_close();
+	if (ret < 0)
+	{
+		LOGE("sunxi_alloc_close failed\n");
+	}
+	LOGD("sunxi_alloc_close ok");
+#endif
+
+    /* There is no device to disconnect from. */
+    mCameraDeviceState = STATE_CONSTRUCTED;
+
+    return NO_ERROR;
+}
+
+status_t V4L2CameraDevice::startDevice(int width,
+                                       int height,
+                                       uint32_t pix_fmt,
+                                       bool video_hint)
+{
+	LOGD("%s, wxh: %dx%d, fmt: %d", __FUNCTION__, width, height, pix_fmt);
+	
+	Mutex::Autolock locker(&mObjectLock);
+	
+	if (!isConnected()) 
+	{
+		LOGE("%s: camera device is not connected.", __FUNCTION__);
+		return EINVAL;
+	}
+	
+	if (isStarted()) 
+	{
+		LOGE("%s: camera device is already started.", __FUNCTION__);
+		return EINVAL;
+	}
+
+	// VE encoder need this format
+	mVideoFormat = pix_fmt;
+	mCurrentV4l2buf = NULL;
+
+	mVideoHint = video_hint;
+	mCanBeDisconnected = false;
+
+	// set capture mode and fps
+	// CHECK_NO_ERROR(v4l2setCaptureParams());	// do not check this error
+	v4l2setCaptureParams();
+	
+	// set v4l2 device parameters, it maybe change the value of mFrameWidth and mFrameHeight.
+	CHECK_NO_ERROR(v4l2SetVideoParams(width, height, pix_fmt));
+	
+	// v4l2 request buffers
+	int buf_cnt = (mTakePictureState == TAKE_PICTURE_NORMAL) ? 1 : NB_BUFFER;
+	CHECK_NO_ERROR(v4l2ReqBufs(&buf_cnt));
+	mBufferCnt = buf_cnt;
+
+	// v4l2 query buffers
+	CHECK_NO_ERROR(v4l2QueryBuf());
+	
+	// stream on the v4l2 device
+	CHECK_NO_ERROR(v4l2StartStreaming());
+
+	mCameraDeviceState = STATE_STARTED;
+
+	mContinuousPictureAfter = 1000000 / 10;
+	mFaceDectectAfter = 1000000 / 15;
+	mPreviewAfter = 1000000 / 24;
+	
+    return NO_ERROR;
+}
+
+status_t V4L2CameraDevice::stopDevice()
+{
+	LOGD("V4L2CameraDevice::stopDevice");
+	
+	pthread_mutex_lock(&mConnectMutex);
+	if (!mCanBeDisconnected)
+	{
+		LOGW("wait until capture thread pause or exit");
+		pthread_cond_wait(&mConnectCond, &mConnectMutex);
+	}
+	pthread_mutex_unlock(&mConnectMutex);
+	
+	Mutex::Autolock locker(&mObjectLock);
+	
+	if (!isStarted()) 
+	{
+		LOGW("%s: camera device is not started.", __FUNCTION__);
+		return NO_ERROR;
+	}
+
+	// v4l2 device stop stream
+	v4l2StopStreaming();
+	
+	// v4l2 device unmap buffers
+    v4l2UnmapBuf();
+	
+	for(int i = 0; i < NB_BUFFER; i++)
+	{
+		memset(&mV4l2buf[i], 0, sizeof(V4L2BUF_t));
+	}
+	
+	mCameraDeviceState = STATE_CONNECTED;
+
+	mLastZoom = -1;
+	
+	mCurrentV4l2buf = NULL;
+	
+    return NO_ERROR;
+}
+
+status_t V4L2CameraDevice::startDeliveringFrames()
+{
+	F_LOG;
+	
+	pthread_mutex_lock(&mCaptureMutex);
+
+	if (mCaptureThreadState == CAPTURE_STATE_NULL)
+	{
+		LOGE("error state of capture thread, %s", __FUNCTION__);
+		pthread_mutex_unlock(&mCaptureMutex);
+		return EINVAL;
+	}
+
+	if (mCaptureThreadState == CAPTURE_STATE_STARTED)
+	{
+		LOGW("capture thread has already started");
+		pthread_mutex_unlock(&mCaptureMutex);
+		return NO_ERROR;
+	}
+
+	// singal to start capture thread
+	mCaptureThreadState = CAPTURE_STATE_STARTED;
+	pthread_cond_signal(&mCaptureCond);
+	pthread_mutex_unlock(&mCaptureMutex);
+
+	return NO_ERROR;
+}
+
+status_t V4L2CameraDevice::stopDeliveringFrames()
+{
+	F_LOG;
+	
+	pthread_mutex_lock(&mCaptureMutex);
+	if (mCaptureThreadState == CAPTURE_STATE_NULL)
+	{
+		LOGE("error state of capture thread, %s", __FUNCTION__);
+		pthread_mutex_unlock(&mCaptureMutex);
+		return EINVAL;
+	}
+
+	if (mCaptureThreadState == CAPTURE_STATE_PAUSED)
+	{
+		LOGW("capture thread has already paused");
+		pthread_mutex_unlock(&mCaptureMutex);
+		return NO_ERROR;
+	}
+
+	mCaptureThreadState = CAPTURE_STATE_PAUSED;
+	pthread_mutex_unlock(&mCaptureMutex);
+
+	return NO_ERROR;
+}
+
+
+/****************************************************************************
+ * Worker thread management.
+ ***************************************************************************/
+
+int V4L2CameraDevice::v4l2WaitCameraReady()
+{
+	fd_set fds;		
+	struct timeval tv;
+	int r;
+
+	FD_ZERO(&fds);
+	FD_SET(mCameraFd, &fds);		
+	
+	/* Timeout */
+	tv.tv_sec  = 2;
+	tv.tv_usec = 0;
+	
+	r = select(mCameraFd + 1, &fds, NULL, NULL, &tv);
+	if (r == -1) 
+	{
+		LOGE("select err, %s", strerror(errno));
+		return -1;
+	} 
+	else if (r == 0) 
+	{
+		LOGE("select timeout");
+		return -1;
+	}
+
+	return 0;
+}
+
+void V4L2CameraDevice::singalDisconnect()
+{
+	pthread_mutex_lock(&mConnectMutex);
+	mCanBeDisconnected = true;
+	pthread_cond_signal(&mConnectCond);
+	pthread_mutex_unlock(&mConnectMutex);
+}
+
+bool V4L2CameraDevice::captureThread()
+{
+	pthread_mutex_lock(&mCaptureMutex);
+	// stop capture
+	if (mCaptureThreadState == CAPTURE_STATE_PAUSED)
+	{
+		singalDisconnect();
+		// wait for signal of starting to capture a frame
+		LOGV("capture thread paused");
+		pthread_cond_wait(&mCaptureCond, &mCaptureMutex);
+	}
+
+	// thread exit
+	if (mCaptureThreadState == CAPTURE_STATE_EXIT)
+	{
+		singalDisconnect();
+		LOGV("capture thread exit");
+		pthread_mutex_unlock(&mCaptureMutex);
+		return false;
+	}
+	pthread_mutex_unlock(&mCaptureMutex);
+
+	int ret = v4l2WaitCameraReady();
+
+	pthread_mutex_lock(&mCaptureMutex);
+	// stop capture or thread exit
+	if (mCaptureThreadState == CAPTURE_STATE_PAUSED
+		|| mCaptureThreadState == CAPTURE_STATE_EXIT)
+	{
+		singalDisconnect();
+		LOGW("should stop capture now");
+		pthread_mutex_unlock(&mCaptureMutex);
+		return __LINE__;
+	}
+
+	if (ret != 0)
+	{
+		LOGW("wait v4l2 buffer time out");
+		pthread_mutex_unlock(&mCaptureMutex);
+		return __LINE__;
+	}
+
+	// get one video frame
+	struct v4l2_buffer buf;
+	memset(&buf, 0, sizeof(v4l2_buffer));
+	ret = getPreviewFrame(&buf);
+	if (ret != OK)
+	{	
+		int preview_num = OSAL_GetElemNum(&mQueueBufferPreview);
+		int picture_num = OSAL_GetElemNum(&mQueueBufferPicture);
+		LOGD("preview_num: %d, picture_num: %d", preview_num, picture_num);
+
+		if (preview_num >= 2)
+		{
+			V4L2BUF_t * pbuf = (V4L2BUF_t *)OSAL_Dequeue(&mQueueBufferPreview);
+			if (pbuf != NULL)
+			{
+				releasePreviewFrame(pbuf->index);
+			}
+		}
+		
+		pthread_mutex_unlock(&mCaptureMutex);
+		usleep(10000);
+		return ret;
+	}
+	
+	// deal with this frame
+	mCurFrameTimestamp = (int64_t)((int64_t)buf.timestamp.tv_usec + (((int64_t)buf.timestamp.tv_sec) * 1000000));
+
+	if (mLastZoom != mNewZoom)
+	{
+		// the main frame crop
+		calculateCrop(&mRectCrop, mNewZoom, mMaxZoom, mFrameWidth, mFrameHeight);
+		mCameraHardware->setNewCrop(&mRectCrop);
+		
+		// the sub-frame crop
+		if (mHalCameraInfo.fast_picture_mode)
+		{
+			calculateCrop(&mThumbRectCrop, mNewZoom, mMaxZoom, mThumbWidth, mThumbHeight);
+		}
+		
+		mLastZoom = mNewZoom;
+
+		LOGV("CROP: [%d, %d, %d, %d]", mRectCrop.left, mRectCrop.top, mRectCrop.right, mRectCrop.bottom);
+		LOGV("thumb CROP: [%d, %d, %d, %d]", mThumbRectCrop.left, mThumbRectCrop.top, mThumbRectCrop.right, mThumbRectCrop.bottom);
+	}
+
+	if (mVideoFormat != V4L2_PIX_FMT_YUYV
+		&& mCaptureFormat == V4L2_PIX_FMT_YUYV)
+	{
+#ifdef USE_MP_CONVERT
+		YUYVToYUV420C((void*)buf.m.offset, 
+					  (void*)(mVideoBuffer.buf_phy_addr[buf.index] | 0x40000000),
+					  mFrameWidth, 
+					  mFrameHeight);
+#else
+		YUYVToNV21(mMapMem.mem[buf.index], 
+					   (void*)mVideoBuffer.buf_vir_addr[buf.index], 
+					   mFrameWidth, 
+					   mFrameHeight);
+#endif
+	}
+
+	// V4L2BUF_t for preview and HW encoder
+	V4L2BUF_t v4l2_buf;
+	if (mVideoFormat != V4L2_PIX_FMT_YUYV
+		&& mCaptureFormat == V4L2_PIX_FMT_YUYV)
+	{
+		v4l2_buf.addrPhyY		= mVideoBuffer.buf_phy_addr[buf.index]; 
+		v4l2_buf.addrVirY		= mVideoBuffer.buf_vir_addr[buf.index]; 
+	}
+	else
+	{
+		v4l2_buf.addrPhyY		= buf.m.offset & 0x0fffffff;
+		v4l2_buf.addrVirY		= (unsigned int)mMapMem.mem[buf.index];
+	}
+	v4l2_buf.index				= buf.index;
+	v4l2_buf.timeStamp			= mCurFrameTimestamp;
+	v4l2_buf.width				= mFrameWidth;
+	v4l2_buf.height				= mFrameHeight;
+	v4l2_buf.crop_rect.left		= mRectCrop.left;
+	v4l2_buf.crop_rect.top		= mRectCrop.top;
+	v4l2_buf.crop_rect.width	= mRectCrop.right - mRectCrop.left + 1;
+	v4l2_buf.crop_rect.height	= mRectCrop.bottom - mRectCrop.top + 1;
+	v4l2_buf.format				= mVideoFormat;
+
+	if (mHalCameraInfo.fast_picture_mode)
+	{
+		v4l2_buf.isThumbAvailable		= 1;
+		v4l2_buf.thumbUsedForPreview	= 1;
+		v4l2_buf.thumbUsedForPhoto		= 0;
+		v4l2_buf.thumbUsedForVideo		= 0;
+		v4l2_buf.thumbAddrPhyY			= v4l2_buf.addrPhyY + ALIGN_4K(ALIGN_32B(mFrameWidth) * mFrameHeight * 3 / 2);	// to do
+		v4l2_buf.thumbAddrVirY			= v4l2_buf.addrVirY + ALIGN_4K(ALIGN_32B(mFrameWidth) * mFrameHeight * 3 / 2);	// to do
+		v4l2_buf.thumbWidth				= mThumbWidth;
+		v4l2_buf.thumbHeight			= mThumbHeight;
+		v4l2_buf.thumb_crop_rect.left	= mThumbRectCrop.left;
+		v4l2_buf.thumb_crop_rect.top	= mThumbRectCrop.top;
+		v4l2_buf.thumb_crop_rect.width	= mThumbRectCrop.right - mThumbRectCrop.left;
+		v4l2_buf.thumb_crop_rect.height	= mThumbRectCrop.bottom - mThumbRectCrop.top;
+		v4l2_buf.thumbFormat			= mVideoFormat;
+	}
+	else
+	{
+		v4l2_buf.isThumbAvailable		= 0;
+	}
+	
+	v4l2_buf.refCnt = 1;
+	memcpy(&mV4l2buf[v4l2_buf.index], &v4l2_buf, sizeof(V4L2BUF_t));
+	if (!mVideoHint)
+	{
+		// face detection only use when picture mode
+		mCurrentV4l2buf = &mV4l2buf[v4l2_buf.index];
+	}
+
+	if (mTakePictureState == TAKE_PICTURE_NORMAL)
+	{
+		//copy picture buffer
+		unsigned int phy_addr = mPicBuffer.addrPhyY;
+		unsigned int vir_addr = mPicBuffer.addrVirY;
+		int frame_size = mFrameWidth * mFrameHeight * 3 >> 1;
+
+		if (frame_size > MAX_PICTURE_SIZE)
+		{
+			LOGE("picture buffer size(%d) is smaller than the frame buffer size(%d)", MAX_PICTURE_SIZE, frame_size);
+			pthread_mutex_unlock(&mCaptureMutex);
+			return false;
+		}
+		
+		memcpy((void*)&mPicBuffer, &v4l2_buf, sizeof(V4L2BUF_t));
+		mPicBuffer.addrPhyY = phy_addr;
+		mPicBuffer.addrVirY = vir_addr;
+        
+    #ifdef USE_ION_MEM_ALLOCATOR
+		ion_flush_cache((void*)v4l2_buf.addrVirY, frame_size);
+		memcpy((void*)mPicBuffer.addrVirY, (void*)v4l2_buf.addrVirY, frame_size);
+		ion_flush_cache((void*)mPicBuffer.addrVirY, frame_size);
+#else USE_SUNXI_MEM_ALLOCATOR
+		sunxi_flush_cache((void*)v4l2_buf.addrVirY, frame_size);
+		memcpy((void*)mPicBuffer.addrVirY, (void*)v4l2_buf.addrVirY, frame_size);
+		sunxi_flush_cache((void*)mPicBuffer.addrVirY, frame_size);
+    #endif
+
+		// enqueue picture buffer
+		ret = OSAL_Queue(&mQueueBufferPicture, &mPicBuffer);
+		if (ret != 0)
+		{
+			LOGW("picture queue full");
+			pthread_cond_signal(&mPictureCond);
+			goto DEC_REF;
+		}
+		
+		mIsPicCopy = true;
+		mCaptureThreadState = CAPTURE_STATE_PAUSED;
+		mTakePictureState = TAKE_PICTURE_NULL;
+		pthread_cond_signal(&mPictureCond);
+		
+		goto DEC_REF;
+	}
+	else
+	{
+		ret = OSAL_Queue(&mQueueBufferPreview, &mV4l2buf[v4l2_buf.index]);
+		if (ret != 0)
+		{
+			LOGW("preview queue full");
+			goto DEC_REF;
+		}
+
+		// add reference count
+		mV4l2buf[v4l2_buf.index].refCnt++;
+		// signal a new frame for preview
+		pthread_cond_signal(&mPreviewCond);
+
+		if (mTakePictureState == TAKE_PICTURE_FAST
+			|| mTakePictureState == TAKE_PICTURE_RECORD)
+		{
+			// enqueue picture buffer
+			ret = OSAL_Queue(&mQueueBufferPicture, &mV4l2buf[v4l2_buf.index]);
+			if (ret != 0)
+			{
+				LOGW("picture queue full");
+				pthread_cond_signal(&mPictureCond);
+				goto DEC_REF;
+			}
+			
+			// add reference count
+			mV4l2buf[v4l2_buf.index].refCnt++;
+			mTakePictureState = TAKE_PICTURE_NULL;
+			mIsPicCopy = false;
+			pthread_cond_signal(&mPictureCond);
+		}
+		
+		if ((mTakePictureState == TAKE_PICTURE_CONTINUOUS
+			|| mTakePictureState == TAKE_PICTURE_CONTINUOUS_FAST)
+			&& isContinuousPictureTime())
+		{
+			// enqueue picture buffer
+			ret = OSAL_Queue(&mQueueBufferPicture, &mV4l2buf[v4l2_buf.index]);
+			if (ret != 0)
+			{
+				// LOGV("continuous picture queue full");
+				pthread_cond_signal(&mContinuousPictureCond);
+				goto DEC_REF;
+			}
+
+			// add reference count
+			mV4l2buf[v4l2_buf.index].refCnt++;
+			mIsPicCopy = false;
+			pthread_cond_signal(&mContinuousPictureCond);
+		}
+	}
+
+DEC_REF:
+	releasePreviewFrame(v4l2_buf.index);
+	
+	pthread_mutex_unlock(&mCaptureMutex);
+    return true;
+}
+
+bool V4L2CameraDevice::previewThread()
+{
+	V4L2BUF_t * pbuf = (V4L2BUF_t *)OSAL_Dequeue(&mQueueBufferPreview);
+	if (pbuf == NULL)
+	{
+		// LOGV("picture queue no buffer, sleep...");
+		pthread_mutex_lock(&mPreviewMutex);
+		pthread_cond_wait(&mPreviewCond, &mPreviewMutex);
+		pthread_mutex_unlock(&mPreviewMutex);
+		return true;
+	}
+
+	Mutex::Autolock locker(&mObjectLock);
+	if (mMapMem.mem[pbuf->index] == NULL
+		|| pbuf->addrPhyY == 0)
+	{
+		LOGV("preview buffer have been released...");
+		return true;
+	}
+
+	// callback
+	mCallbackNotifier->onNextFrameAvailable((void*)pbuf, mUseHwEncoder);
+
+	// preview
+	if (isPreviewTime())
+	{
+		mPreviewWindow->onNextFrameAvailable((void*)pbuf);
+	}
+
+	// LOGD("preview id : %d", pbuf->index);
+
+	releasePreviewFrame(pbuf->index);
+
+	return true;
+}
+
+// singal picture
+bool V4L2CameraDevice::pictureThread()
+{
+	V4L2BUF_t * pbuf = (V4L2BUF_t *)OSAL_Dequeue(&mQueueBufferPicture);
+	if (pbuf == NULL)
+	{
+		LOGV("picture queue no buffer, sleep...");
+		pthread_mutex_lock(&mPictureMutex);
+		pthread_cond_wait(&mPictureCond, &mPictureMutex);
+		pthread_mutex_unlock(&mPictureMutex);
+		return true;
+	}
+
+	DBG_TIME_BEGIN("taking picture", 0);
+
+	// notify picture cb
+	mCameraHardware->notifyPictureMsg((void*)pbuf);
+
+	DBG_TIME_DIFF("notifyPictureMsg");
+
+	mCallbackNotifier->takePicture((void*)pbuf);
+	
+	char str[128];
+	sprintf(str, "hw picture size: %dx%d", pbuf->width, pbuf->height);
+	DBG_TIME_DIFF(str);
+	
+	if (!mIsPicCopy)
+	{
+		releasePreviewFrame(pbuf->index);
+	}
+
+	DBG_TIME_END("Take picture", 0);
+
+	return true;
+}
+
+// continuous picture
+bool V4L2CameraDevice::continuousPictureThread()
+{
+	V4L2BUF_t * pbuf = (V4L2BUF_t *)OSAL_Dequeue(&mQueueBufferPicture);
+	if (pbuf == NULL)
+	{
+		LOGV("continuousPictureThread queue no buffer, sleep...");
+		pthread_mutex_lock(&mContinuousPictureMutex);
+		pthread_cond_wait(&mContinuousPictureCond, &mContinuousPictureMutex);
+		pthread_mutex_unlock(&mContinuousPictureMutex);
+		return true;
+	}
+	
+	Mutex::Autolock locker(&mObjectLock);
+	if (mMapMem.mem[pbuf->index] == NULL
+		|| pbuf->addrPhyY == 0)
+	{
+		LOGV("picture buffer have been released...");
+		return true;
+	}
+	
+	DBG_TIME_AVG_AREA_IN(TAG_CONTINUOUS_PICTURE);
+
+	// reach the max number of pictures
+	if (mContinuousPictureCnt >= mContinuousPictureMax)
+	{
+		mTakePictureState = TAKE_PICTURE_NULL;
+		stopContinuousPicture();
+		releasePreviewFrame(pbuf->index);
+		return true;
+	}
+
+	// apk stop continuous pictures
+	if (!mContinuousPictureStarted)
+	{
+		mTakePictureState = TAKE_PICTURE_NULL;
+		releasePreviewFrame(pbuf->index);
+		return true;
+	}
+
+	bool ret = mCallbackNotifier->takePicture((void*)pbuf, true);
+	if (ret)
+	{
+		mContinuousPictureCnt++;
+	
+		DBG_TIME_AVG_AREA_OUT(TAG_CONTINUOUS_PICTURE);
+	}
+	else
+	{
+		// LOGW("do not encoder jpeg");
+	}
+	
+	releasePreviewFrame(pbuf->index);
+
+	return true;
+}
+
+void V4L2CameraDevice::startContinuousPicture()
+{
+	F_LOG;
+
+	mContinuousPictureCnt = 0;
+	mContinuousPictureStarted = true;
+	mContinuousPictureStartTime = systemTime(SYSTEM_TIME_MONOTONIC);
+
+	DBG_TIME_AVG_INIT(TAG_CONTINUOUS_PICTURE);
+}
+
+void V4L2CameraDevice::stopContinuousPicture()
+{
+	F_LOG;
+
+	if (!mContinuousPictureStarted)
+	{
+		LOGD("Continuous picture has already stopped");
+		return;
+	}
+	
+	mContinuousPictureStarted = false;
+
+	nsecs_t time = (systemTime(SYSTEM_TIME_MONOTONIC) - mContinuousPictureStartTime)/1000000;
+	LOGD("Continuous picture cnt: %d, use time %lld(ms)", mContinuousPictureCnt, time);
+	if (time != 0)
+	{
+		LOGD("Continuous picture %f(fps)", (float)mContinuousPictureCnt/(float)time * 1000);
+	}
+
+	DBG_TIME_AVG_END(TAG_CONTINUOUS_PICTURE, "picture enc");
+}
+
+void V4L2CameraDevice::setContinuousPictureCnt(int cnt)
+{
+	F_LOG;
+	mContinuousPictureMax = cnt;
+}
+
+bool V4L2CameraDevice::isContinuousPictureTime()
+{
+	if (mTakePictureState == TAKE_PICTURE_CONTINUOUS_FAST)
+	{
+		return true;
+	}
+	
+    timeval cur_time;
+    gettimeofday(&cur_time, NULL);
+    const uint64_t cur_mks = cur_time.tv_sec * 1000000LL + cur_time.tv_usec;
+    if ((cur_mks - mContinuousPictureLast) >= mContinuousPictureAfter) {
+        mContinuousPictureLast = cur_mks;
+        return true;
+    }
+    return false;
+}
+
+bool V4L2CameraDevice::isPreviewTime()
+{
+	if (mVideoHint != true)
+	{
+		return true;
+	}
+	
+    timeval cur_time;
+    gettimeofday(&cur_time, NULL);
+    const uint64_t cur_mks = cur_time.tv_sec * 1000000LL + cur_time.tv_usec;
+    if ((cur_mks - mPreviewLast) >= mPreviewAfter) {
+        mPreviewLast = cur_mks;
+        return true;
+    }
+    return false;
+}
+
+void V4L2CameraDevice::waitFaceDectectTime()
+{
+    timeval cur_time;
+    gettimeofday(&cur_time, NULL);
+    const uint64_t cur_mks = cur_time.tv_sec * 1000000LL + cur_time.tv_usec;
+	
+    if ((cur_mks - mFaceDectectLast) >= mFaceDectectAfter)
+	{
+		mFaceDectectLast = cur_mks;
+	}	
+	else
+	{
+		usleep(mFaceDectectAfter - (cur_mks - mFaceDectectLast));
+	    gettimeofday(&cur_time, NULL);
+		mFaceDectectLast = cur_time.tv_sec * 1000000LL + cur_time.tv_usec;
+	}
+}
+
+int V4L2CameraDevice::getCurrentFaceFrame(void * frame)
+{
+	if (frame == NULL)
+	{
+		LOGE("getCurrentFrame: error in null pointer");
+		return -1;
+	}
+
+	pthread_mutex_lock(&mCaptureMutex);
+	// stop capture
+	if (mCaptureThreadState != CAPTURE_STATE_STARTED)
+	{
+		LOGW("capture thread dose not started");
+		pthread_mutex_unlock(&mCaptureMutex);
+		return -1;
+	}
+	pthread_mutex_unlock(&mCaptureMutex);
+	
+	waitFaceDectectTime();
+
+    Mutex::Autolock locker(&mObjectLock);
+	
+	if (mCurrentV4l2buf == NULL
+		|| mCurrentV4l2buf->addrVirY == 0)
+	{
+		LOGW("frame buffer not ready");
+		return -1;
+	}
+
+	if ((mCurrentV4l2buf->isThumbAvailable == 1)
+		&& (mCurrentV4l2buf->thumbUsedForPreview == 1))
+	{
+		memcpy(frame, 
+				(void*)mCurrentV4l2buf->addrVirY + ALIGN_4K(ALIGN_32B(mCurrentV4l2buf->width) * mCurrentV4l2buf->height * 3 / 2), 
+				ALIGN_32B(mCurrentV4l2buf->thumbWidth) * mCurrentV4l2buf->thumbHeight);
+	}
+	else
+	{
+		memcpy(frame, (void*)mCurrentV4l2buf->addrVirY, mCurrentV4l2buf->width * mCurrentV4l2buf->height);
+	}
+
+	return 0;
+}
+
+// -----------------------------------------------------------------------------
+// extended interfaces here <***** star *****>
+// -----------------------------------------------------------------------------
+int V4L2CameraDevice::openCameraDev(HALCameraInfo * halInfo)
+{
+	F_LOG;
+	
+	int ret = -1;
+	struct v4l2_input inp;
+	struct v4l2_capability cap; 
+
+	if (halInfo == NULL)
+	{
+		LOGE("error HAL camera info");
+		return -1;
+	}
+	
+	// open V4L2 device
+	mCameraFd = open(halInfo->device_name, O_RDWR | O_NONBLOCK, 0);
+	if (mCameraFd == -1) 
+	{ 
+        LOGE("ERROR opening %s: %s", halInfo->device_name, strerror(errno)); 
+		return -1; 
+	}
+
+	// check v4l2 device capabilities
+	ret = ioctl (mCameraFd, VIDIOC_QUERYCAP, &cap); 
+    if (ret < 0) 
+	{ 
+        LOGE("Error opening device: unable to query device."); 
+        goto END_ERROR;
+    } 
+
+    if ((cap.capabilities & V4L2_CAP_VIDEO_CAPTURE) == 0) 
+	{ 
+        LOGE("Error opening device: video capture not supported."); 
+        goto END_ERROR;
+    } 
+  
+    if ((cap.capabilities & V4L2_CAP_STREAMING) == 0) 
+	{ 
+        LOGE("Capture device does not support streaming i/o"); 
+        goto END_ERROR;
+    } 
+
+	if (!strcmp((char *)cap.driver, "uvcvideo"))
+	{
+		mIsUsbCamera = true;
+	}
+
+	if (!mIsUsbCamera)
+	{
+		// uvc do not need to set input
+		inp.index = halInfo->device_id;
+		if (-1 == ioctl (mCameraFd, VIDIOC_S_INPUT, &inp))
+		{
+			LOGE("VIDIOC_S_INPUT error!");
+			goto END_ERROR;
+		}
+	}
+	
+	// try to support this format: NV21, YUYV
+	// we do not support mjpeg camera now
+	if (tryFmt(V4L2_PIX_FMT_NV21) == OK)
+	{
+		mCaptureFormat = V4L2_PIX_FMT_NV21;
+		LOGV("capture format: V4L2_PIX_FMT_NV21");
+	}
+	else if(tryFmt(V4L2_PIX_FMT_YUYV) == OK)
+	{
+		mCaptureFormat = V4L2_PIX_FMT_YUYV;		// maybe usb camera
+		LOGV("capture format: V4L2_PIX_FMT_YUYV");
+	}
+	else
+	{
+		LOGE("driver should surpport NV21/NV12 or YUYV format, but it not!");
+		goto END_ERROR;
+	}
+
+	return OK;
+
+END_ERROR:
+
+	if (mCameraFd != NULL)
+	{
+		close(mCameraFd);
+		mCameraFd = NULL;
+	}
+	
+	return -1;
+}
+
+void V4L2CameraDevice::closeCameraDev()
+{
+	F_LOG;
+	
+	if (mCameraFd != NULL)
+	{
+		close(mCameraFd);
+		mCameraFd = NULL;
+	}
+}
+
+int V4L2CameraDevice::v4l2SetVideoParams(int width, int height, uint32_t pix_fmt)
+{
+	int ret = UNKNOWN_ERROR;
+	struct v4l2_format format;
+
+	LOGV("%s, line: %d, w: %d, h: %d, pfmt: %d", 
+		__FUNCTION__, __LINE__, width, height, pix_fmt);
+	
+	memset(&format, 0, sizeof(format));
+    format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE; 
+    format.fmt.pix.width  = width;
+    format.fmt.pix.height = height;
+    if (mCaptureFormat == V4L2_PIX_FMT_YUYV)
+	{
+    	format.fmt.pix.pixelformat = V4L2_PIX_FMT_YUYV; 
+	}
+	else
+	{
+		format.fmt.pix.pixelformat = pix_fmt; 
+	}
+	format.fmt.pix.field = V4L2_FIELD_NONE;
+	
+	ret = ioctl(mCameraFd, VIDIOC_S_FMT, &format); 
+	if (ret < 0) 
+	{ 
+		LOGE("VIDIOC_S_FMT Failed: %s", strerror(errno)); 
+		return ret; 
+	} 
+
+	mFrameWidth = format.fmt.pix.width;
+	mFrameHeight = format.fmt.pix.height;
+	LOGV("camera params: w: %d, h: %d, pfmt: %d, pfield: %d", 
+		mFrameWidth, mFrameHeight, pix_fmt, V4L2_FIELD_NONE);
+
+	return OK;
+}
+
+int V4L2CameraDevice::v4l2ReqBufs(int * buf_cnt)
+{
+	F_LOG;
+	int ret = UNKNOWN_ERROR;
+	struct v4l2_requestbuffers rb;
+
+	LOGV("TO VIDIOC_REQBUFS count: %d", *buf_cnt);
+	
+	memset(&rb, 0, sizeof(rb));
+    rb.type   = V4L2_BUF_TYPE_VIDEO_CAPTURE; 
+    rb.memory = V4L2_MEMORY_MMAP; 
+    rb.count  = *buf_cnt; 
+	
+	ret = ioctl(mCameraFd, VIDIOC_REQBUFS, &rb); 
+    if (ret < 0) 
+	{ 
+        LOGE("Init: VIDIOC_REQBUFS failed: %s", strerror(errno)); 
+		return ret;
+    } 
+
+	*buf_cnt = rb.count;
+	LOGV("VIDIOC_REQBUFS count: %d", *buf_cnt);
+
+	return OK;
+}
+
+int V4L2CameraDevice::v4l2QueryBuf()
+{
+	F_LOG;
+	int ret = UNKNOWN_ERROR;
+	struct v4l2_buffer buf;
+	
+	for (int i = 0; i < mBufferCnt; i++) 
+	{  
+        memset (&buf, 0, sizeof (struct v4l2_buffer)); 
+		buf.type   = V4L2_BUF_TYPE_VIDEO_CAPTURE; 
+		buf.memory = V4L2_MEMORY_MMAP; 
+		buf.index  = i; 
+		
+		ret = ioctl (mCameraFd, VIDIOC_QUERYBUF, &buf); 
+        if (ret < 0) 
+		{ 
+            LOGE("Unable to query buffer (%s)", strerror(errno)); 
+            return ret; 
+        } 
+
+ 
+        mMapMem.mem[i] = mmap (0, buf.length, 
+                            PROT_READ | PROT_WRITE, 
+                            MAP_SHARED, 
+                            mCameraFd, 
+                            buf.m.offset); 
+		mMapMem.length = buf.length;
+		LOGV("index: %d, mem: %x, len: %x, offset: %x", i, (int)mMapMem.mem[i], buf.length, buf.m.offset);
+ 
+        if (mMapMem.mem[i] == MAP_FAILED) 
+		{ 
+			LOGE("Unable to map buffer (%s)", strerror(errno)); 
+            return -1; 
+        } 
+
+		// start with all buffers in queue
+        ret = ioctl(mCameraFd, VIDIOC_QBUF, &buf); 
+        if (ret < 0) 
+		{ 
+            LOGE("VIDIOC_QBUF Failed"); 
+            return ret; 
+        } 
+
+		if (mIsUsbCamera)		// star to do
+		{
+			int buffer_len = mFrameWidth * mFrameHeight * 3 / 2;
+        #ifdef USE_ION_MEM_ALLOCATOR
+			mVideoBuffer.buf_vir_addr[i] = (int)ion_alloc_alloc(buffer_len);
+			mVideoBuffer.buf_phy_addr[i] = ion_alloc_vir2phy((void*)mVideoBuffer.buf_vir_addr[i]);
+#else USE_SUNXI_MEM_ALLOCATOR
+			mVideoBuffer.buf_vir_addr[i] = (int)sunxi_alloc_alloc(buffer_len);
+			mVideoBuffer.buf_phy_addr[i] = sunxi_alloc_vir2phy((void*)mVideoBuffer.buf_vir_addr[i]);
+        #endif
+			LOGV("video buffer: index: %d, vir: %x, phy: %x, len: %x", 
+					i, mVideoBuffer.buf_vir_addr[i], mVideoBuffer.buf_phy_addr[i], buffer_len);
+			
+			memset((void*)mVideoBuffer.buf_vir_addr[i], 0x10, mFrameWidth * mFrameHeight);
+			memset((void*)mVideoBuffer.buf_vir_addr[i] + mFrameWidth * mFrameHeight, 
+					0x80, mFrameWidth * mFrameHeight / 2);
+		}
+	} 
+
+	return OK;
+}
+
+int V4L2CameraDevice::v4l2StartStreaming()
+{
+	F_LOG;
+	int ret = UNKNOWN_ERROR; 
+	enum v4l2_buf_type type = V4L2_BUF_TYPE_VIDEO_CAPTURE; 
+	
+  	ret = ioctl (mCameraFd, VIDIOC_STREAMON, &type); 
+	if (ret < 0) 
+	{ 
+		LOGE("StartStreaming: Unable to start capture: %s", strerror(errno)); 
+		return ret; 
+	} 
+
+	return OK;
+}
+
+int V4L2CameraDevice::v4l2StopStreaming()
+{
+	F_LOG;
+	int ret = UNKNOWN_ERROR; 
+	enum v4l2_buf_type type = V4L2_BUF_TYPE_VIDEO_CAPTURE; 
+	
+	ret = ioctl (mCameraFd, VIDIOC_STREAMOFF, &type); 
+	if (ret < 0) 
+	{ 
+		LOGE("StopStreaming: Unable to stop capture: %s", strerror(errno)); 
+		return ret; 
+	} 
+	LOGV("V4L2Camera::v4l2StopStreaming OK");
+
+	return OK;
+}
+
+int V4L2CameraDevice::v4l2UnmapBuf()
+{
+	F_LOG;
+	int ret = UNKNOWN_ERROR;
+	
+	for (int i = 0; i < mBufferCnt; i++) 
+	{
+		ret = munmap(mMapMem.mem[i], mMapMem.length);
+        if (ret < 0) 
+		{
+            LOGE("v4l2CloseBuf Unmap failed"); 
+			return ret;
+		}
+
+		mMapMem.mem[i] = NULL;
+
+		if (mVideoBuffer.buf_vir_addr[i] != 0)
+		{
+        #ifdef USE_ION_MEM_ALLOCATOR
+			ion_alloc_free((void*)mVideoBuffer.buf_vir_addr[i]);
+			mVideoBuffer.buf_phy_addr[i] = 0;
+        #else USE_SUNXI_MEM_ALLOCATOR
+            sunxi_alloc_free((void*)mVideoBuffer.buf_vir_addr[i]);
+			mVideoBuffer.buf_phy_addr[i] = 0;
+        #endif
+		}
+	}
+	mVideoBuffer.buf_unused = NB_BUFFER;
+	mVideoBuffer.read_id = 0;
+	mVideoBuffer.read_id = 0;
+	
+	return OK;
+}
+
+void V4L2CameraDevice::releasePreviewFrame(int index)
+{
+	int ret = UNKNOWN_ERROR;
+	struct v4l2_buffer buf;
+
+    Mutex::Autolock locker(&mReleaseBufferLock);
+
+	// decrease buffer reference count first, if the reference count is no more than 0, release it.
+	if (mV4l2buf[index].refCnt > 0
+		&& --mV4l2buf[index].refCnt == 0)
+	{
+		memset(&buf, 0, sizeof(v4l2_buffer));
+		buf.type   = V4L2_BUF_TYPE_VIDEO_CAPTURE; 
+	    buf.memory = V4L2_MEMORY_MMAP; 
+		buf.index = index;
+		
+		// LOGD("r ID: %d", buf.index);
+	    ret = ioctl(mCameraFd, VIDIOC_QBUF, &buf); 
+	    if (ret != 0) 
+		{
+	        LOGE("releasePreviewFrame: VIDIOC_QBUF Failed: index = %d, ret = %d, %s", 
+				buf.index, ret, strerror(errno)); 
+	    }
+	}
+}
+
+int V4L2CameraDevice::getPreviewFrame(v4l2_buffer *buf)
+{
+	int ret = UNKNOWN_ERROR;
+	
+	buf->type   = V4L2_BUF_TYPE_VIDEO_CAPTURE; 
+    buf->memory = V4L2_MEMORY_MMAP; 
+ 
+    ret = ioctl(mCameraFd, VIDIOC_DQBUF, buf); 
+    if (ret < 0) 
+	{ 
+        LOGW("GetPreviewFrame: VIDIOC_DQBUF Failed, %s", strerror(errno)); 
+        return __LINE__; 			// can not return false
+    }
+
+	return OK;
+}
+
+int V4L2CameraDevice::tryFmt(int format)
+{	
+	struct v4l2_fmtdesc fmtdesc;
+	fmtdesc.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	for(int i = 0; i < 12; i++)
+	{
+		fmtdesc.index = i;
+		if (-1 == ioctl (mCameraFd, VIDIOC_ENUM_FMT, &fmtdesc))
+		{
+			break;
+		}
+		LOGV("format index = %d, name = %s, v4l2 pixel format = %x\n",
+			i, fmtdesc.description, fmtdesc.pixelformat);
+
+		if (fmtdesc.pixelformat == format)
+		{
+			return OK;
+		}
+	}
+
+	return -1;
+}
+
+int V4L2CameraDevice::tryFmtSize(int * width, int * height)
+{
+	F_LOG;
+	int ret = -1;
+	struct v4l2_format fmt;
+
+	LOGV("V4L2Camera::TryFmtSize: w: %d, h: %d", *width, *height);
+
+
+	memset(&fmt, 0, sizeof(fmt));
+    fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE; 
+    fmt.fmt.pix.width  = *width; 
+    fmt.fmt.pix.height = *height; 
+    if (mCaptureFormat == V4L2_PIX_FMT_YUYV)
+	{
+		fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_YUYV;
+	}
+	else
+	{
+    	fmt.fmt.pix.pixelformat = mVideoFormat; 
+	}
+	fmt.fmt.pix.field = V4L2_FIELD_NONE;
+
+	ret = ioctl(mCameraFd, VIDIOC_TRY_FMT, &fmt); 
+	if (ret < 0) 
+	{ 
+		LOGE("VIDIOC_TRY_FMT Failed: %s", strerror(errno)); 
+		return ret; 
+	} 
+
+	// driver surpport this size
+	*width = fmt.fmt.pix.width; 
+    *height = fmt.fmt.pix.height; 
+
+	return 0;
+}
+
+int V4L2CameraDevice::setFrameRate(int rate)
+{
+	mFrameRate = rate;
+	return OK;
+}
+
+int V4L2CameraDevice::getFrameRate()
+{
+	F_LOG;
+	int ret = -1;
+
+	struct v4l2_streamparm parms;
+	parms.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+
+	ret = ioctl (mCameraFd, VIDIOC_G_PARM, &parms);
+	if (ret < 0) 
+	{
+		LOGE("VIDIOC_G_PARM getFrameRate error, %s", strerror(errno));
+		return ret;
+	}
+
+	int numerator = parms.parm.capture.timeperframe.numerator;
+	int denominator = parms.parm.capture.timeperframe.denominator;
+	
+	LOGV("frame rate: numerator = %d, denominator = %d", numerator, denominator);
+
+	if (numerator != 0
+		&& denominator != 0)
+	{
+		return denominator / numerator;
+	}
+	else
+	{
+		LOGW("unsupported frame rate: %d/%d", denominator, numerator);
+		return 30;
+	}
+}
+
+int V4L2CameraDevice::setImageEffect(int effect)
+{
+	F_LOG;
+	int ret = -1;
+	struct v4l2_control ctrl;
+
+	ctrl.id = V4L2_CID_COLORFX;
+	ctrl.value = effect;
+	ret = ioctl(mCameraFd, VIDIOC_S_CTRL, &ctrl);
+	if (ret < 0)
+		LOGV("setImageEffect failed!");
+	else 
+		LOGV("setImageEffect ok");
+
+	return ret;
+}
+
+int V4L2CameraDevice::setWhiteBalance(int wb)
+{
+	struct v4l2_control ctrl;
+	int ret = -1;
+
+	ctrl.id = V4L2_CID_DO_WHITE_BALANCE;
+	ctrl.value = wb;
+	ret = ioctl(mCameraFd, VIDIOC_S_CTRL, &ctrl);
+	if (ret < 0)
+		LOGV("setWhiteBalance failed, %s", strerror(errno));
+	else 
+		LOGV("setWhiteBalance ok");
+
+	return ret;
+}
+
+int V4L2CameraDevice::setExposure(int exp)
+{
+	F_LOG;
+	int ret = -1;
+	struct v4l2_control ctrl;
+
+	ctrl.id = V4L2_CID_EXPOSURE;
+	ctrl.value = exp;
+	ret = ioctl(mCameraFd, VIDIOC_S_CTRL, &ctrl);
+	if (ret < 0)
+		LOGV("setExposure failed, %s", strerror(errno));
+	else 
+		LOGV("setExposure ok");
+
+	return ret;
+}
+
+// flash mode
+int V4L2CameraDevice::setFlashMode(int mode)
+{
+	F_LOG;
+	int ret = -1;
+	struct v4l2_control ctrl;
+
+	ctrl.id = V4L2_CID_CAMERA_FLASH_MODE;
+	ctrl.value = mode;
+	ret = ioctl(mCameraFd, VIDIOC_S_CTRL, &ctrl);
+	if (ret < 0)
+		LOGV("setFlashMode failed, %s", strerror(errno));
+	else 
+		LOGV("setFlashMode ok");
+
+	return ret;
+}
+
+int V4L2CameraDevice::enumSize(char * pSize, int len)
+{
+	struct v4l2_frmsizeenum size_enum;
+	size_enum.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	size_enum.pixel_format = mCaptureFormat;
+
+	if (pSize == NULL)
+	{
+		LOGE("error input params");
+		return -1;
+	}
+
+	char str[16];
+	memset(str, 0, 16);
+	memset(pSize, 0, len);
+	
+	for(int i = 0; i < 20; i++)
+	{
+		size_enum.index = i;
+		if (-1 == ioctl (mCameraFd, VIDIOC_ENUM_FRAMESIZES, &size_enum))
+		{
+			break;
+		}
+		// LOGV("format index = %d, size_enum: %dx%d", i, size_enum.discrete.width, size_enum.discrete.height);
+		sprintf(str, "%dx%d", size_enum.discrete.width, size_enum.discrete.height);
+		if (i != 0)
+		{
+			strcat(pSize, ",");
+		}
+		strcat(pSize, str);
+	}
+
+	return OK;
+}
+
+// af mode
+int V4L2CameraDevice::setAutoFocusMode(int af_mode)
+{
+	F_LOG;
+	int ret = -1;
+	struct v4l2_control ctrl;
+
+	ctrl.id = V4L2_CID_CAMERA_AF_MODE;
+	ctrl.value = af_mode;
+	ret = ioctl(mCameraFd, VIDIOC_S_CTRL, &ctrl);
+	if (ret < 0)
+		LOGV("setAutoFocusMode failed, %s", strerror(errno));
+	else 
+		LOGV("setAutoFocusMode ok");
+
+	return ret;
+}
+
+// af ctrl
+int V4L2CameraDevice::setAutoFocusCtrl(int af_ctrl, void *areas)
+{
+	F_LOG;
+	int ret = -1;
+	struct v4l2_control ctrl;
+
+	ctrl.id = V4L2_CID_CAMERA_AF_CTRL;
+	ctrl.value = af_ctrl;
+	ctrl.user_pt = (unsigned int)areas;
+	ret = ioctl(mCameraFd, VIDIOC_S_CTRL, &ctrl);
+	if (ret < 0)
+		LOGE("setAutoFocusCtrl failed, %s", strerror(errno));
+	else 
+		LOGV("setAutoFocusCtrl ok");
+
+	return ret;
+}
+
+int V4L2CameraDevice::getAutoFocusStatus(int af_ctrl)
+{
+	F_LOG;
+	int ret = -1;
+	struct v4l2_control ctrl;
+
+	if (mCameraFd == NULL)
+	{
+		return 0xFF000000;
+	}
+
+	ctrl.id = V4L2_CID_CAMERA_AF_CTRL;
+	ctrl.value = af_ctrl;
+	ret = ioctl(mCameraFd, VIDIOC_G_CTRL, &ctrl);
+	if (ret >= 0)
+		LOGV("getAutoFocusCtrl ok");
+
+	return ret;
+}
+
+int V4L2CameraDevice::v4l2setCaptureParams()
+{
+	F_LOG;
+	int ret = -1;
+	
+	struct v4l2_streamparm params;
+	params.parm.capture.timeperframe.numerator = 1;
+	params.parm.capture.timeperframe.denominator = mFrameRate;
+	params.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	if (mTakePictureState == TAKE_PICTURE_NORMAL)
+	{
+		params.parm.capture.capturemode = V4L2_MODE_IMAGE;
+	}
+	else
+	{
+		if(mVideoHint == true)
+		{
+			params.parm.capture.capturemode = V4L2_MODE_VIDEO;
+		}
+		else
+		{
+			params.parm.capture.capturemode = V4L2_MODE_PREVIEW;
+		}
+	}
+
+	LOGV("VIDIOC_S_PARM mFrameRate: %d, capture mode: %d", mFrameRate, params.parm.capture.capturemode);
+
+	ret = ioctl(mCameraFd, VIDIOC_S_PARM, &params);
+	if (ret < 0)
+		LOGE("v4l2setCaptureParams failed, %s", strerror(errno));
+	else 
+		LOGV("v4l2setCaptureParams ok");
+
+	return ret;
+}
+
+}; /* namespace android */
diff --git a/hardware/camera/V4L2CameraDevice.h b/hardware/camera/V4L2CameraDevice.h
new file mode 100755
index 0000000..9a71551
--- /dev/null
+++ b/hardware/camera/V4L2CameraDevice.h
@@ -0,0 +1,489 @@
+
+#ifndef __HAL_V4L2_CAMERA_DEVICE_H__
+#define __HAL_V4L2_CAMERA_DEVICE_H__
+
+/*
+ * Contains declaration of a class V4L2CameraDevice.
+ */
+
+#include <ui/Rect.h>
+#include <fcntl.h> 
+#include <utils/Thread.h>
+#include <hardware/camera.h>
+//#include <videodev2.h>
+
+#include <type_camera.h>
+
+#include "OSAL_Queue.h"
+
+#ifdef __PLATFORM_H64__
+#include <sunxi_camera.h>
+#else
+#include <videodev2_34.h>
+#endif
+
+#define NB_BUFFER 7
+
+#define MAX_PICTURE_SIZE (2592*1936*3>>1)
+
+namespace android {
+
+class CameraHardware;
+class CallbackNotifier;
+class PreviewWindow;
+
+/*
+ * 
+ */
+typedef struct HALCameraInfo{
+	char	device_name[16];		// device node name, such as "/dev/video0"
+	int 	device_id;				// device id for camera share with the same CSI
+	int 	facing; 				// facing front or back
+	int 	orientation;			// 
+	bool	fast_picture_mode;		// 
+	bool	is_uvc;					// usb camera
+}HALCameraInfo;
+
+enum TAKE_PICTURE_STATE {
+	TAKE_PICTURE_NULL,			// do not take picture
+	TAKE_PICTURE_NORMAL,		// stream off -> stream on -> take picture -> stream off -> stream on
+	TAKE_PICTURE_FAST,			// normal mode but do not need to stream off/on
+	TAKE_PICTURE_RECORD, 		// take picture in recording
+	TAKE_PICTURE_CONTINUOUS,
+	TAKE_PICTURE_CONTINUOUS_FAST
+};
+
+/* 
+ * V4L2CameraDevice
+ */
+class V4L2CameraDevice {
+public:
+    /* Constructs V4L2CameraDevice instance. */
+    V4L2CameraDevice(CameraHardware* camera_hal, 
+    				 PreviewWindow * preview_window, 
+    				 CallbackNotifier * cb);
+
+    /* Destructs V4L2CameraDevice instance. */
+    ~V4L2CameraDevice();
+
+    /***************************************************************************
+     * V4L2Camera device abstract interface implementation.
+     * See declarations of these methods in V4L2Camera class for
+     * information on each of these methods.
+     **************************************************************************/
+
+public:
+    /* Connects to the camera device.
+     * Since there is no real device to connect to, this method does nothing,
+     * but changes the state.
+     */
+    status_t connectDevice(HALCameraInfo * halInfo);
+
+    /* Disconnects from the camera device.
+     * Since there is no real device to disconnect from, this method does
+     * nothing, but changes the state.
+     */
+    status_t disconnectDevice();
+
+    /* Starts the camera device. */
+    status_t startDevice(int width, int height, uint32_t pix_fmt, bool video_hint);
+
+    /* Stops the camera device. */
+    status_t stopDevice();
+
+    /* Gets current preview fame into provided buffer. */
+    status_t getPreviewFrame(void* buffer);
+
+	/* Starts delivering frames captured from the camera device.
+     * This method will start the worker thread that would be pulling frames from
+     * the camera device, and will deliver the pulled frames back to the emulated
+     * camera via onNextFrameAvailable callback. This method must be called on a
+     * connected instance of this class with a started camera device. If it is
+     * called on a disconnected instance, or camera device has not been started,
+     * this method must return a failure.
+     * Param:
+     *  one_burst - Controls how many frames should be delivered. If this
+     *      parameter is 'true', only one captured frame will be delivered to the
+     *      V4L2Camera. If this parameter is 'false', frames will keep
+     *      coming until stopDeliveringFrames method is called. Typically, this
+     *      parameter is set to 'true' only in order to obtain a single frame
+     *      that will be used as a "picture" in takePicture method of the
+     *      V4L2Camera.
+     * Return:
+     *  NO_ERROR on success, or an appropriate error status.
+     */
+    status_t startDeliveringFrames();
+	
+	/* Stops delivering frames captured from the camera device.
+     * This method will stop the worker thread started by startDeliveringFrames.
+     * Return:
+     *  NO_ERROR on success, or an appropriate error status.
+     */
+	status_t stopDeliveringFrames();
+
+    /***************************************************************************
+     * Worker thread management overrides.
+     * See declarations of these methods in V4L2Camera class for
+     * information on each of these methods.
+     **************************************************************************/
+
+protected:
+
+	// -------------------------------------------------------------------------
+	// extended interfaces here <***** star *****>
+	// -------------------------------------------------------------------------
+
+	class DoCaptureThread : public Thread {
+        V4L2CameraDevice*	mV4l2CameraDevice;
+		bool				mRequestExit;
+    public:
+        DoCaptureThread(V4L2CameraDevice* dev) :
+			Thread(false),
+			mV4l2CameraDevice(dev),
+			mRequestExit(false) {
+		}
+        void startThread() {
+			run("CameraCaptureThread", PRIORITY_URGENT_DISPLAY);
+        }
+		void stopThread() {
+			mRequestExit = true;
+        }
+        virtual bool threadLoop() {
+			if (mRequestExit) {
+				return false;
+			}
+			return mV4l2CameraDevice->captureThread();
+        }
+    };
+	
+	class DoPreviewThread : public Thread {
+        V4L2CameraDevice*	mV4l2CameraDevice;
+		bool				mRequestExit;
+    public:
+        DoPreviewThread(V4L2CameraDevice* dev) :
+			Thread(false),
+			mV4l2CameraDevice(dev),
+			mRequestExit(false) {
+		}
+        void startThread() {
+			run("CameraPreviewThread", PRIORITY_URGENT_DISPLAY);
+        }
+		void stopThread() {
+			mRequestExit = true;
+        }
+        virtual bool threadLoop() {
+			if (mRequestExit) {
+				return false;
+			}
+			return mV4l2CameraDevice->previewThread();
+        }
+    };
+
+	class DoPictureThread : public Thread {
+        V4L2CameraDevice*	mV4l2CameraDevice;
+		bool				mRequestExit;
+    public:
+        DoPictureThread(V4L2CameraDevice* dev) :
+			Thread(false),
+			mV4l2CameraDevice(dev),
+			mRequestExit(false) {
+		}
+		void startThread() {
+			run("CameraPictrueThread", PRIORITY_AUDIO);
+		}
+		void stopThread() {
+			mRequestExit = true;
+        }
+        virtual bool threadLoop() {
+			if (mRequestExit) {
+				return false;
+			}
+			return mV4l2CameraDevice->pictureThread();
+		}
+    };
+
+	class DoContinuousPictureThread : public Thread {
+        V4L2CameraDevice*	mV4l2CameraDevice;
+		bool				mRequestExit;
+    public:
+        DoContinuousPictureThread(V4L2CameraDevice* dev) :
+			Thread(false),
+			mV4l2CameraDevice(dev),
+			mRequestExit(false) {
+		}
+		void startThread() {
+			run("CameraContinuousPictrueThread", PRIORITY_AUDIO);
+		}
+		void stopThread() {
+			mRequestExit = true;
+        }
+        virtual bool threadLoop() {
+			if (mRequestExit) {
+				return false;
+			}
+			return mV4l2CameraDevice->continuousPictureThread();
+		}
+    };
+
+public:
+
+	bool captureThread();
+	bool previewThread();
+	bool pictureThread();
+	bool continuousPictureThread();
+
+	int tryFmt(int format);							// check if driver support this format
+	int tryFmtSize(int * width, int * height);		// check if driver support this size
+	int setFrameRate(int rate);						// set frame rate from camera.cfg
+	int getFrameRate();								// get v4l2 device current frame rate
+
+	int setImageEffect(int effect);
+	int setWhiteBalance(int wb);
+	int setExposure(int exp);
+	int setFlashMode(int mode);
+	
+	int enumSize(char * pSize, int len);
+	int setAutoFocusMode(int af);
+	int setAutoFocusCtrl(int af_ctrl, void * areas);
+	int getAutoFocusStatus(int af_ctrl);
+	
+	void releasePreviewFrame(int index);			// Q buffer for encoder
+
+	int getCurrentFaceFrame(void * frame);
+
+	inline void setCrop(int new_zoom, int max_zoom)
+	{
+		mNewZoom = new_zoom;
+		mMaxZoom = max_zoom;
+	}
+
+	inline int getCaptureFormat()
+	{
+		return mCaptureFormat;
+	}
+
+	inline void setHwEncoder(bool hw)
+	{
+		mUseHwEncoder = hw;
+	}
+
+	inline void setTakePictureState(TAKE_PICTURE_STATE state)
+	{
+		pthread_mutex_lock(&mCaptureMutex);
+		LOGV("setTakePictureState %d", state);
+		mTakePictureState = state;
+		pthread_mutex_unlock(&mCaptureMutex);
+	}
+	
+	void startContinuousPicture();
+	void stopContinuousPicture();
+	void setContinuousPictureCnt(int cnt);
+	
+	/*
+	 * State checkers.
+	 */
+	inline bool isConnected() const {
+        /* Instance is connected when its status is either"connected", or
+         * "started". */
+        return mCameraDeviceState == STATE_CONNECTED || mCameraDeviceState == STATE_STARTED;
+    }
+    inline bool isStarted() const {
+        return mCameraDeviceState == STATE_STARTED;
+    }
+	
+private:
+	int openCameraDev(HALCameraInfo * halInfo);
+	void closeCameraDev();
+	int v4l2SetVideoParams(int width, int height, uint32_t pix_fmt);
+	int v4l2setCaptureParams();
+	int v4l2ReqBufs(int * buf_cnt);
+	int v4l2QueryBuf();
+	int v4l2StartStreaming(); 
+	int v4l2StopStreaming(); 
+	int v4l2UnmapBuf();
+
+	int v4l2WaitCameraReady();
+	int getPreviewFrame(v4l2_buffer *buf);
+	
+	void dealWithVideoFrameSW(V4L2BUF_t * pBuf);
+	void dealWithVideoFrameHW(V4L2BUF_t * pBuf);
+	void dealWithVideoFrameTest(V4L2BUF_t * pBuf);
+	
+	/* Checks if it's the time to push new frame to continuous picture.
+	 * Note that this method must be called while object is locked. */
+	bool isContinuousPictureTime();
+	
+	bool isPreviewTime();
+	
+	void waitFaceDectectTime();
+	
+	void singalDisconnect();
+public:
+#ifdef USE_MP_CONVERT
+	// use for YUYV to YUV420C
+	void YUYVToYUV420C(const void* yuyv, void *yuv420, int width, int height);
+	void NV21ToYV12(const void* nv21, void *yv12, int width, int height);
+
+#endif
+
+private:
+	// -------------------------------------------------------------------------
+	// private data
+	// -------------------------------------------------------------------------
+
+	/* Locks this instance for parameters, state, etc. change. */
+	Mutex                       	mObjectLock;
+	Mutex                       	mReleaseBufferLock;
+
+	// instance of CameraHardware
+	CameraHardware *             	mCameraHardware;
+
+	// instance of PreviewWindow
+	PreviewWindow *					mPreviewWindow;
+
+	// instance of CallbackNotifier
+	CallbackNotifier *				mCallbackNotifier;
+
+	HALCameraInfo					mHalCameraInfo;
+	
+	/* Defines possible states of the V4L2Camera device object.
+     */
+    enum CameraDeviceState {
+        /* Object has been constructed. */
+        STATE_CONSTRUCTED,
+        /* Object has been connected to the physical device. */
+        STATE_CONNECTED,
+        /* Camera device has been started. */
+        STATE_STARTED,
+    };
+
+    /* Object state. */
+    CameraDeviceState   			mCameraDeviceState;
+
+	/* Defines possible states of the V4L2CameraDevice capture thread.
+     */
+    enum CaptureThreadState {
+    	/* Do not capture frame. */
+        CAPTURE_STATE_NULL,
+        /* Do not capture frame. */
+        CAPTURE_STATE_PAUSED,
+        /* Start capture frame. */
+        CAPTURE_STATE_STARTED,
+        /* exit thread*/
+		CAPTURE_STATE_EXIT,
+    };
+
+	/* capture thread state. */
+	CaptureThreadState				mCaptureThreadState;
+	
+	// v4l2 device handle
+	int								mCameraFd; 
+
+	// be usb camera or not
+	bool							mIsUsbCamera;
+
+	int								mFrameRate;
+
+	TAKE_PICTURE_STATE				mTakePictureState;
+	V4L2BUF_t						mPicBuffer;
+	bool							mIsPicCopy;
+
+    /* Frame width */
+    int                         	mFrameWidth;
+
+    /* Frame height */
+    int                         	mFrameHeight;
+
+	/* thumb Frame width */
+    int                         	mThumbWidth;
+
+    /* thumb Frame height */
+    int                         	mThumbHeight;
+
+	/* Timestamp of the current frame. */
+	nsecs_t 						mCurFrameTimestamp;
+
+	typedef struct v4l2_mem_map_t{
+		void *	mem[NB_BUFFER]; 
+		int 	length;
+	}v4l2_mem_map_t;
+	v4l2_mem_map_t					mMapMem;
+
+	// actually buffer counts
+	int								mBufferCnt;
+
+	bool							mUseHwEncoder;
+	
+	Rect							mRectCrop;
+	Rect							mThumbRectCrop;
+	int								mNewZoom;
+	int								mLastZoom;
+	int								mMaxZoom;
+
+	int								mCaptureFormat;		// the driver capture format
+	int								mVideoFormat;		// the user request format, it should convert video buffer format 
+														// if mVideoFormat is different from mCaptureFormat. 
+	
+	typedef struct bufferManagerQ_t
+	{
+		int			buf_vir_addr[NB_BUFFER];
+		int			buf_phy_addr[NB_BUFFER];
+		int			write_id;
+		int			read_id;
+		int			buf_unused;
+	}bufferManagerQ_t;
+	bufferManagerQ_t				mVideoBuffer;		// for usb camera
+
+#ifdef USE_MP_CONVERT
+	int 							mG2DHandle;
+#endif
+
+	OSAL_QUEUE						mQueueBufferPreview;
+	OSAL_QUEUE						mQueueBufferPicture;
+	V4L2BUF_t						mV4l2buf[NB_BUFFER];
+
+	sp<DoCaptureThread>				mCaptureThread;
+	pthread_mutex_t 				mCaptureMutex;
+	pthread_cond_t					mCaptureCond;
+
+	sp<DoPreviewThread>				mPreviewThread;
+	pthread_mutex_t 				mPreviewMutex;
+	pthread_cond_t					mPreviewCond;
+	
+	sp<DoPictureThread>				mPictureThread;
+	pthread_mutex_t 				mPictureMutex;
+	pthread_cond_t					mPictureCond;
+
+	pthread_mutex_t 				mConnectMutex;
+	pthread_cond_t					mConnectCond;
+	bool							mCanBeDisconnected;
+
+	sp<DoContinuousPictureThread>	mContinuousPictureThread;
+	pthread_mutex_t 				mContinuousPictureMutex;
+	pthread_cond_t					mContinuousPictureCond;
+	bool							mContinuousPictureStarted;
+	int								mContinuousPictureCnt;
+	int								mContinuousPictureMax;
+	nsecs_t 						mContinuousPictureStartTime;
+
+	/* Timestamp (abs. microseconds) when last frame has been pushed to the
+     * preview window. */
+    uint64_t                        mContinuousPictureLast;
+
+    /* Preview frequency in microseconds. */
+    uint32_t                        mContinuousPictureAfter;
+	
+    uint64_t                        mFaceDectectLast;
+    uint32_t                        mFaceDectectAfter;
+
+    uint64_t                        mPreviewLast;
+    uint32_t                        mPreviewAfter;
+
+	V4L2BUF_t *						mCurrentV4l2buf;
+
+	bool							mVideoHint;
+};
+
+}; /* namespace android */
+
+#endif  /* __HAL_V4L2_CAMERA_DEVICE_H__ */
diff --git a/hardware/camera/V4L2CameraDevice2.cpp b/hardware/camera/V4L2CameraDevice2.cpp
index 72e82c3..1697453 100755
--- a/hardware/camera/V4L2CameraDevice2.cpp
+++ b/hardware/camera/V4L2CameraDevice2.cpp
@@ -7,6 +7,8 @@
 #include <cutils/log.h>
 
 #include <sys/mman.h> 
+//#include <videodev2.h>
+//#include <linux/videodev.h> 
 #include <sys/time.h>
 
 #ifdef USE_MP_CONVERT
@@ -17,10 +19,9 @@
 #include "CallbackNotifier.h"
 #include "PreviewWindow.h"
 #include "CameraHardware2.h"
+#include "HALCameraFactory.h"
 
-#include "math.h"
-
-#ifdef __PLATFORM_A64__
+#ifdef __PLATFORM_H64__
 #include <sunxi_camera.h>
 #else
 #include <videodev2_34.h>
@@ -30,61 +31,18 @@
 	if (a != NO_ERROR) {						\
 		if (mCameraFd != NULL) {				\
 			close(mCameraFd);					\
-			LOGE("error close device");			\
 			mCameraFd = NULL;					\
 		}										\
 		return EINVAL;							\
 	}
 	
 extern void PreviewCnr(unsigned int snr_level, unsigned int gain, int width, int height, char *src, char *dst);
-extern void ColorDenoise(unsigned char *dst_plane, unsigned char *src_plane, int width, int height, int threshold);
-extern	int Sharpen(unsigned char * image, int min_val, int level, int width, int height);
+
 namespace android {
 	
 // defined in HALCameraFactory.cpp
 extern void getCallingProcessName(char *name);
-static int SceneNotifyCallback(int cmd, void* data, int* ret,void* user)
-{
-
-	V4L2CameraDevice* dev = (V4L2CameraDevice*)user;
-	switch(cmd)
-	{
-		case SCENE_NOTIFY_CMD_GET_AE_STATE:
-			LOGV("SCENE_NOTIFY_CMD_GET_AE_STATE");
-			*ret = dev->getAeStat((struct isp_stat_buf *)data);
-			break;
-			
-		case SCENE_NOTIFY_CMD_GET_HIST_STATE:
-			LOGV("SCENE_NOTIFY_CMD_GET_HIST_STATE");
-			*ret = dev->getHistStat((struct isp_stat_buf * )data);
-			break;
-			
-		case SCENE_NOTIFY_CMD_SET_3A_LOCK:
-			LOGV("SCENE_NOTIFY_CMD_SET_3A_LOCK: %ld",(long)data);
-			*ret = dev->set3ALock((long)data);
-			break;
-			
-		case SCENE_NOTIFY_CMD_SET_HDR_SETTING:
-			LOGV("SENE_NOTIFY_CMD_SET_HDR_SETTING");
-			*ret = dev->setHDRMode(data);
-			break;
-			
-		case SCENE_NOTIFY_CMD_GET_HDR_FRAME_COUNT:
-			//*ret = dev->getHDRFrameCnt((int*)data);
-			int cnt;
-			cnt = dev->getHDRFrameCnt();
-			*(int *)data = cnt;
-			*ret = 0;
-			LOGD("SCENE_NOTIFY_CMD_GET_HDR_FRAME_COUNT: %ld",cnt);
-			break;
-
-		default:
-			break;
-
-	}
 
-	return 0;
-} 
 
 static void calculateCrop(Rect * rect, int new_zoom, int max_zoom, int width, int height)
 {
@@ -107,6 +65,7 @@ static void calculateCrop(Rect * rect, int new_zoom, int max_zoom, int width, in
 	// LOGD("crop: [%d, %d, %d, %d]", rect->left, rect->top, rect->right, rect->bottom);
 }
 
+
 static void YUYVToNV12(const void* yuyv, void *nv12, int width, int height)
 {
 	uint8_t* Y	= (uint8_t*)nv12;
@@ -154,6 +113,9 @@ static void YUYVToNV21(const void* yuyv, void *nv21, int width, int height)
 }
 
 #ifdef USE_MP_CONVERT
+
+
+
 void V4L2CameraDevice::YUYVToYUV420C(const void* yuyv, void *yuv420, int width, int height)
 {
 	g2d_blt		blit_para;
@@ -242,30 +204,56 @@ void V4L2CameraDevice::NV21ToYV12(const void* nv21, void *yv12, int width, int h
 #endif
 
 DBG_TIME_AVG_BEGIN(TAG_CONTINUOUS_PICTURE);
+static int saveframe(char *str,void *p,int length,int is_oneframe)
+{
+	FILE *fd;
+
+	if(is_oneframe){
+		fd = fopen(str,"wb");
+	}
+	else{
+		fd = fopen(str,"a");
+	}
+
+	if(!fd){
+		LOGE("Open file error");
+		return -1;
+	}
+	if(fwrite(p,1,length,fd)){
+	   LOGD("Write file successfully");
+	   fclose(fd);
+	   return 0;
+	}
+	else {
+	   LOGE("Write file fail");
+	   fclose(fd);
+	   return -1;
+	}
+}
 
 void  V4L2CameraDevice::showformat(int format,char *str)
 {
 	switch(format){
 	case V4L2_PIX_FMT_YUYV:
-		LOGV("The %s foramt is V4L2_PIX_FMT_YUYV",str);
+		LOGD("The %s foramt is V4L2_PIX_FMT_YUYV",str);
 		break;
 	case V4L2_PIX_FMT_MJPEG:
-		LOGV("The %s foramt is V4L2_PIX_FMT_MJPEG",str);
+		LOGD("The %s foramt is V4L2_PIX_FMT_MJPEG",str);
 		break;
 	case V4L2_PIX_FMT_YVU420:
-		LOGV("The %s foramt is V4L2_PIX_FMT_YVU420",str);
+		LOGD("The %s foramt is V4L2_PIX_FMT_YVU420",str);
 		break;
 	case V4L2_PIX_FMT_NV12:
-		LOGV("The %s foramt is V4L2_PIX_FMT_NV12",str);
+		LOGD("The %s foramt is V4L2_PIX_FMT_NV12",str);
 		break;
 	case V4L2_PIX_FMT_NV21:
-		LOGV("The %s foramt is V4L2_PIX_FMT_NV21",str);
+		LOGD("The %s foramt is V4L2_PIX_FMT_NV21",str);
 		break;
 	case V4L2_PIX_FMT_H264:
-		LOGV("The %s foramt is V4L2_PIX_FMT_H264",str);
+		LOGD("The %s foramt is V4L2_PIX_FMT_H264",str);
 		break;
 	default:
-		LOGV("The %s format can't be showed",str);
+		LOGD("The %s format can't be showed",str);
 	}
 }
 V4L2CameraDevice::V4L2CameraDevice(CameraHardware* camera_hal,
@@ -276,7 +264,6 @@ V4L2CameraDevice::V4L2CameraDevice(CameraHardware* camera_hal,
       mCallbackNotifier(cb),
       mCameraDeviceState(STATE_CONSTRUCTED),
       mCaptureThreadState(CAPTURE_STATE_NULL),
-      mPreviewThreadState(PREVIEW_STATE_NULL),
       mCameraFd(0),
       mIsUsbCamera(false),
       mTakePictureState(TAKE_PICTURE_NULL),
@@ -292,9 +279,7 @@ V4L2CameraDevice::V4L2CameraDevice(CameraHardware* camera_hal,
 	  mLastZoom(-1),
 	  mMaxZoom(0xffffffff),
 	  mCaptureFormat(V4L2_PIX_FMT_NV21),
-	  mVideoFormat(V4L2_PIX_FMT_NV21),
-	  mFrameRate(30),
-	  mStartSmartTimeout(false)
+	  mVideoFormat(V4L2_PIX_FMT_NV21)
 #ifdef USE_MP_CONVERT
 	  ,mG2DHandle(0)
 #endif
@@ -319,25 +304,24 @@ V4L2CameraDevice::V4L2CameraDevice(CameraHardware* camera_hal,
 	  ,mIsThumbUsedForVideo(false)
 	  ,mVideoWidth(640)
 	  ,mVideoHeight(480)
-	  ,mSceneMode(NULL)
-	  ,mFlashMode(V4L2_FLASH_LED_MODE_NONE)
-	  ,mZoomRatio(100)
-	  ,mExposureBias(0)
+	  ,mFrameRate(30)
+	  ,mDecoder(NULL)
+	  ,mCameraList(NULL)
 {
 	LOGV("V4L2CameraDevice construct");
 
-	memset(&mMapMem,0,sizeof(mMapMem));
-	memset(&mVideoBuffer,0,sizeof(mVideoBuffer));
-
 	memset(&mHalCameraInfo, 0, sizeof(mHalCameraInfo));
 	memset(&mRectCrop, 0, sizeof(Rect));
-	memset(&mTakePictureFlag,0,sizeof(mTakePictureFlag));
-	memset(&mPicBuffer,0,sizeof(mPicBuffer));
+	memset(&mMapMem, 0, sizeof(v4l2_mem_map_t));
+	memset(&mVideoBuffer, 0, sizeof(bufferManagerQ_t));
+	memset(&mVideoConf, 0, sizeof(VConfig));
+	memset(&mVideoInfo, 0, sizeof(VideoStreamInfo));
+	memset(&mDataInfo, 0, sizeof(VideoStreamDataInfo));
+
 	// init preview buffer queue
 	OSAL_QueueCreate(&mQueueBufferPreview, NB_BUFFER);
-	OSAL_QueueCreate(&mQueueBufferPicture, 2);
+	OSAL_QueueCreate(&mQueueBufferPicture, 4);
 	
-
 	// init capture thread
 	mCaptureThread = new DoCaptureThread(this);
 	pthread_mutex_init(&mCaptureMutex, NULL);
@@ -351,9 +335,6 @@ V4L2CameraDevice::V4L2CameraDevice(CameraHardware* camera_hal,
 	pthread_cond_init(&mPreviewCond, NULL);
 	mPreviewThread->startThread();
 
-	pthread_mutex_init(&mPreviewSyncMutex, NULL);
-	pthread_cond_init(&mPreviewSyncCond, NULL);
-	mPreviewThreadState = PREVIEW_STATE_STARTED;
 	// init picture thread
 	mPictureThread = new DoPictureThread(this);
 	pthread_mutex_init(&mPictureMutex, NULL);
@@ -362,11 +343,14 @@ V4L2CameraDevice::V4L2CameraDevice(CameraHardware* camera_hal,
 	
 	pthread_mutex_init(&mConnectMutex, NULL);
 	pthread_cond_init(&mConnectCond, NULL);
+	
 	// init continuous picture thread
 	mContinuousPictureThread = new DoContinuousPictureThread(this);
 	pthread_mutex_init(&mContinuousPictureMutex, NULL);
 	pthread_cond_init(&mContinuousPictureCond, NULL);
 	mContinuousPictureThread->startThread();
+
+	// init smart picture thread
 	mSmartPictureThread = new DoSmartPictureThread(this);
 	pthread_mutex_init(&mSmartPictureMutex, NULL);
 	pthread_cond_init(&mSmartPictureCond, NULL);
@@ -416,6 +400,7 @@ V4L2CameraDevice::~V4L2CameraDevice()
 		mSmartPictureThread.clear();
 		mSmartPictureThread = 0;
 	}
+
 	pthread_mutex_destroy(&mCaptureMutex);
 	pthread_cond_destroy(&mCaptureCond);
 
@@ -430,6 +415,7 @@ V4L2CameraDevice::~V4L2CameraDevice()
 	
 	pthread_mutex_destroy(&mContinuousPictureMutex);
 	pthread_cond_destroy(&mContinuousPictureCond);
+
 	pthread_mutex_destroy(&mSmartPictureMutex);
 	pthread_cond_destroy(&mSmartPictureCond);
 	
@@ -455,28 +441,12 @@ status_t V4L2CameraDevice::connectDevice(HALCameraInfo * halInfo)
 
 	// open v4l2 camera device
 	int ret = openCameraDev(halInfo);
-		if (ret != OK)
-		{
-			return ret;
-		}
-	switch((v4l2_sensor_type)getSensorType()){
-		case V4L2_SENSOR_TYPE_YUV:
-			LOGV("the sensor is YUV sensor");
-			mSensor_Type = V4L2_SENSOR_TYPE_YUV;
-			break;
-		case V4L2_SENSOR_TYPE_RAW:
-			LOGV("the sensor is RAW sensor");
-			mSensor_Type = V4L2_SENSOR_TYPE_RAW;
-			break;
-		default:
-			LOGE("get the sensor type failed");
-			goto END_ERROR;
+	if (ret != OK)
+	{
+		return ret;
 	}
-	halInfo->fast_picture_mode = (int)mSensor_Type;	//set the CameraHardware Class fast_picture_mode member
+
 	memcpy((void*)&mHalCameraInfo, (void*)halInfo, sizeof(HALCameraInfo));
-	struct isp_exif_attribute exif_attri;
-	getExifInfo(&exif_attri);
-	mCameraHardware->setExifInfo(exif_attri);
 
 #ifdef USE_MP_CONVERT
 	if (mIsUsbCamera)
@@ -492,7 +462,8 @@ status_t V4L2CameraDevice::connectDevice(HALCameraInfo * halInfo)
 	}
 #endif 
 
-	ret = camera_phy_alloc_open();
+#ifdef USE_ION_MEM_ALLOCATOR
+	ret = ion_alloc_open();
 	if (ret < 0)
 	{
 		LOGE("ion_alloc_open failed");
@@ -500,16 +471,36 @@ status_t V4L2CameraDevice::connectDevice(HALCameraInfo * halInfo)
 	}
 	LOGV("ion_alloc_open ok");
 
+	// used for normal picture mode
+	mPicBuffer.addrVirY = (int)ion_alloc_alloc(MAX_PICTURE_SIZE);
+	mPicBuffer.addrPhyY = ion_alloc_vir2phy((void*)mPicBuffer.addrVirY);
+#else USE_SUNXI_MEM_ALLOCATOR
+	ret = sunxi_alloc_open();
+	if (ret < 0)
+	{
+		LOGE("sunxi_alloc_open failed");
+		goto END_ERROR;
+	}
+	LOGV("sunxi_alloc_open ok");
+
+	// used for normal picture mode
+	mPicBuffer.addrVirY = (int)sunxi_alloc_alloc(MAX_PICTURE_SIZE);
+	mPicBuffer.addrPhyY = sunxi_alloc_vir2phy((void*)mPicBuffer.addrVirY);
+#endif
+
 	/* There is a device to connect to. */
 	mCameraDeviceState = STATE_CONNECTED;
 
     return NO_ERROR;
+	
 END_ERROR:
+
 	if (mCameraFd != NULL)
 	{
 		close(mCameraFd);
 		mCameraFd = NULL;
 	}
+	
 #ifdef USE_MP_CONVERT
 	if(mG2DHandle != NULL)
 	{
@@ -517,6 +508,7 @@ END_ERROR:
 		mG2DHandle = NULL;
 	}
 #endif
+
 	return UNKNOWN_ERROR;
 }
 
@@ -549,7 +541,14 @@ status_t V4L2CameraDevice::disconnectDevice()
 	}
 #endif
 
-	int ret = camera_phy_alloc_close();
+#ifdef USE_ION_MEM_ALLOCATOR
+	if (mPicBuffer.addrVirY != NULL)
+	{
+		ion_alloc_free((void*)mPicBuffer.addrVirY);
+		mPicBuffer.addrPhyY = 0;
+	}
+
+	int ret = ion_alloc_close();
 	if (ret < 0)
 	{
 		LOGE("sunxi_alloc_close failed\n");
@@ -558,7 +557,23 @@ status_t V4L2CameraDevice::disconnectDevice()
 	{
 		LOGV("sunxi_alloc_close ok");
 	}
+#else USE_SUNXI_MEM_ALLOCATOR
+	if (mPicBuffer.addrVirY != NULL)
+	{
+		sunxi_alloc_free((void*)mPicBuffer.addrVirY);
+		mPicBuffer.addrPhyY = 0;
+	}
 
+	int ret = sunxi_alloc_close();
+	if (ret < 0)
+	{
+		LOGE("sunxi_alloc_close failed\n");
+	}
+	else
+	{
+		LOGV("sunxi_alloc_close ok");
+	}
+#endif
 
     /* There is no device to disconnect from. */
     mCameraDeviceState = STATE_CONSTRUCTED;
@@ -618,7 +633,52 @@ status_t V4L2CameraDevice::startDevice(int width,
 	mContinuousPictureAfter = 1000000 / 10;
 	mFaceDectectAfter = 1000000 / 15;
 	mPreviewAfter = 1000000 / 24;
-	set3ALock(0);
+#ifdef CDX10
+	if((mCaptureFormat == V4L2_PIX_FMT_MJPEG)||(mCaptureFormat == V4L2_PIX_FMT_H264))
+	{
+		mStream_info.format 			= (mCaptureFormat == V4L2_PIX_FMT_MJPEG) ? CEDARV_STREAM_FORMAT_MJPEG : CEDARV_STREAM_FORMAT_H264 ;
+		mStream_info.sub_format 		= CEDARV_SUB_FORMAT_UNKNOW;
+		mStream_info.container_format	= CEDARV_CONTAINER_FORMAT_UNKNOW;
+		mStream_info.video_width	 = mFrameWidth;
+		mStream_info.video_height	 = mFrameHeight;
+		mStream_info.frame_rate 	 = mFrameRate*1000;
+		mStream_info.frame_duration  = 0;
+		//stream_info.aspect_ratio	 = 800/480*1000;
+		mStream_info.init_data_len	 = 0;
+		mStream_info.init_data		 = 0;
+		Libve_init(&mDecoder,&mStream_info,0,&mDecoderMutex);
+	}
+#endif
+
+#ifdef CDX20
+
+	if((mCaptureFormat == V4L2_PIX_FMT_MJPEG)||(mCaptureFormat == V4L2_PIX_FMT_H264))
+	{
+		LOGD("FUNC:%s, Line:%d init Dec!",__FUNCTION__,__LINE__);
+		//* all decoder support YV12 format.
+		mVideoConf.eOutputPixelFormat  = PIXEL_FORMAT_NV21;//PIXEL_FORMAT_YV12;PIXEL_FORMAT_YUV_MB32_420;//
+		//* never decode two picture when decoding a thumbnail picture.
+		mVideoConf.bDisable3D		  = 1;
+
+		mVideoConf.nVbvBufferSize	  = 0;
+
+		mVideoInfo.eCodecFormat =(mCaptureFormat == V4L2_PIX_FMT_MJPEG) ? VIDEO_CODEC_FORMAT_MJPEG : VIDEO_CODEC_FORMAT_H264;
+		mVideoInfo.nWidth = mFrameWidth;;
+		mVideoInfo.nHeight = mFrameHeight;
+		mVideoInfo.nFrameRate = mFrameRate;
+		mVideoInfo.nFrameDuration = 1000*1000/mFrameRate;
+		mVideoInfo.nAspectRatio = 1000;
+		mVideoInfo.bIs3DStream = 0;
+		mVideoInfo.nCodecSpecificDataLen = 0;
+		mVideoInfo.pCodecSpecificData = NULL;
+
+		Libve_init2(&mDecoder,&mVideoInfo,&mVideoConf);
+		if(mDecoder == NULL){
+			LOGE("FUNC:%s, Line:%d ",__FUNCTION__,__LINE__);
+		}
+	}
+
+#endif
     return NO_ERROR;
 }
 
@@ -658,7 +718,20 @@ status_t V4L2CameraDevice::stopDevice()
 	mLastZoom = -1;
 	
 	mCurrentV4l2buf = NULL;
-	
+#ifdef CDX10
+	if(mCaptureFormat == V4L2_PIX_FMT_MJPEG)
+	{
+		Libve_exit(&mDecoder,&mDecoderMutex);
+	}
+#endif
+
+#ifdef CDX20
+	if(mCaptureFormat == V4L2_PIX_FMT_MJPEG)
+	{
+		Libve_exit2(&mDecoder);
+	}
+#endif
+
     return NO_ERROR;
 }
 
@@ -686,11 +759,6 @@ status_t V4L2CameraDevice::startDeliveringFrames()
 	mCaptureThreadState = CAPTURE_STATE_STARTED;
 	pthread_cond_signal(&mCaptureCond);
 	pthread_mutex_unlock(&mCaptureMutex);
-	pthread_mutex_lock(&mPreviewSyncMutex);
-	mPreviewThreadState = PREVIEW_STATE_STARTED;
-	LOGV("set mPreviewThreadState to %d\n",mPreviewThreadState);
-	pthread_cond_signal(&mPreviewSyncCond);
-	pthread_mutex_unlock(&mPreviewSyncMutex);
 
 	return NO_ERROR;
 }
@@ -800,6 +868,7 @@ bool V4L2CameraDevice::captureThread()
 	{
 		LOGW("wait v4l2 buffer time out");
 		pthread_mutex_unlock(&mCaptureMutex);
+
 		LOGW("preview queue has %d items.", OSAL_GetElemNum(&mQueueBufferPreview));
 		return __LINE__;
 	}
@@ -815,32 +884,27 @@ bool V4L2CameraDevice::captureThread()
 		usleep(10000);
 		return ret;
 	}
-//modify for cts by clx
+
 	mCurAvailBufferCnt--;
-	if (mCurAvailBufferCnt <= 2)
-		{
+
+	if (mCurAvailBufferCnt <= 4)
+	{
 		mNeedHalfFrameRate = true;
 		mStatisicsIndex = 0;
 	}
 	else if (mNeedHalfFrameRate)
-			{
+	{
 		mStatisicsIndex++;
 		if (mStatisicsIndex >= STATISICS_CNT)
 		{
 			mNeedHalfFrameRate = false;
 		}
-		
 	}
 	
 	// deal with this frame
-#ifdef __CEDARX_FRAMEWORK_1__
-	mCurFrameTimestamp = (int64_t)((int64_t)buf.timestamp.tv_usec + (((int64_t)buf.timestamp.tv_sec) * 1000000));
-#elif defined __CEDARX_FRAMEWORK_2__
+	//mCurFrameTimestamp = (int64_t)((int64_t)buf.timestamp.tv_usec + (((int64_t)buf.timestamp.tv_sec) * 1000000));
+
 	mCurFrameTimestamp = (int64_t)systemTime();
-	
-#endif
-	//get picture flag
-	mTakePictureFlag.dwval = buf.reserved;
 
 	if (mLastZoom != mNewZoom)
 	{
@@ -864,10 +928,63 @@ bool V4L2CameraDevice::captureThread()
 		}
 		
 		mLastZoom = mNewZoom;
-		mZoomRatio = (mNewZoom * 2 * 100 / mMaxZoom + 100);
+
 		LOGV("CROP: [%d, %d, %d, %d]", mRectCrop.left, mRectCrop.top, mRectCrop.right, mRectCrop.bottom);
 		LOGV("thumb CROP: [%d, %d, %d, %d]", mThumbRectCrop.left, mThumbRectCrop.top, mThumbRectCrop.right, mThumbRectCrop.bottom);
 	}
+#ifdef CDX10
+	if((mCaptureFormat == V4L2_PIX_FMT_MJPEG) || (mCaptureFormat == V4L2_PIX_FMT_H264))
+	{
+		mData_info.lengh		=buf.bytesused;
+		mData_info.pts			=(u32)mCurFrameTimestamp;
+	#ifdef USE_ION_MEM_ALLOCATOR
+
+		ion_flush_cache((void*)mVideoBuffer.buf_vir_addr[buf.index], mFrameWidth*mFrameHeight*3/2);
+
+			Libve_dec( &mDecoder, \
+				 mMapMem.mem[buf.index], \
+			(void*)mVideoBuffer.buf_vir_addr[buf.index], \
+			(void*)&mStream_info, \
+			(void*)&mData_info, \
+			"NV21", \
+			/*only "NV21" (for A31 A31s A80 )or "NV12"(for A20)*/
+			&mDecoderMutex);
+		ion_flush_cache((void*)mVideoBuffer.buf_vir_addr[buf.index], mFrameWidth*mFrameHeight*3/2);
+
+	#else USE_SUNXI_MEM_ALLOCATOR
+
+		sunxi_flush_cache((void*)mVideoBuffer.buf_vir_addr[buf.index], mFrameWidth*mFrameHeight*3/2);
+
+			Libve_dec( &mDecoder, \
+				 mMapMem.mem[buf.index], \
+			(void*)mVideoBuffer.buf_vir_addr[buf.index], \
+			(void*)&mStream_info, \
+			(void*)&mData_info, \
+			"NV21", \
+			/*only "NV21" (for A31 A31s )or "NV12"(for A20)*/
+			&mDecoderMutex);
+		sunxi_flush_cache((void*)mVideoBuffer.buf_vir_addr[buf.index], mFrameWidth*mFrameHeight*3/2);
+	#endif
+	}
+#endif
+
+#ifdef CDX20
+	if((mCaptureFormat == V4L2_PIX_FMT_MJPEG) || (mCaptureFormat == V4L2_PIX_FMT_H264))
+	{
+		mDataInfo.nLength		=buf.bytesused;
+		mDataInfo.nPts			=(int64_t)mCurFrameTimestamp/1000;
+		ion_flush_cache((void*)mVideoBuffer.buf_vir_addr[buf.index], mFrameWidth*mFrameHeight*3/2);
+
+		Libve_dec2(&mDecoder,
+			mMapMem.mem[buf.index],
+			(void*)mVideoBuffer.buf_vir_addr[buf.index],
+			&mVideoInfo,
+			&mDataInfo,
+			&mVideoConf);
+
+		ion_flush_cache((void*)mVideoBuffer.buf_vir_addr[buf.index], mFrameWidth*mFrameHeight*3/2);
+	}
+#endif
 
 	if (mVideoFormat != V4L2_PIX_FMT_YUYV
 		&& mCaptureFormat == V4L2_PIX_FMT_YUYV)
@@ -878,10 +995,13 @@ bool V4L2CameraDevice::captureThread()
 					  mFrameWidth, 
 					  mFrameHeight);
 #else
-		YUYVToNV12(mMapMem.mem[buf.index], 
+		ion_flush_cache((void*)mVideoBuffer.buf_vir_addr[buf.index], mFrameWidth * mFrameHeight * 2);
+
+		YUYVToNV21(mMapMem.mem[buf.index], 
 					   (void*)mVideoBuffer.buf_vir_addr[buf.index], 
 					   mFrameWidth, 
 					   mFrameHeight);
+		ion_flush_cache((void*)mVideoBuffer.buf_vir_addr[buf.index], mFrameWidth * mFrameHeight * 2);
 #endif
 	}
 
@@ -890,34 +1010,53 @@ bool V4L2CameraDevice::captureThread()
 	if (mVideoFormat != V4L2_PIX_FMT_YUYV
 		&& mCaptureFormat == V4L2_PIX_FMT_YUYV)
 	{
-
-		v4l2_buf.addrPhyY		= mVideoBuffer.buf_phy_addr[buf.index];
+		v4l2_buf.addrPhyY		= mVideoBuffer.buf_phy_addr[buf.index] ;//- 0x20000000; //& 0x0fffffff;
+		v4l2_buf.addrVirY		= mVideoBuffer.buf_vir_addr[buf.index];
+		v4l2_buf.width			= mFrameWidth;
+		v4l2_buf.height			= mFrameHeight;
+	}
+#ifdef CDX10
+	else if(mVideoFormat != V4L2_PIX_FMT_YUYV
+		&&( (mCaptureFormat == V4L2_PIX_FMT_MJPEG) || (mCaptureFormat == V4L2_PIX_FMT_H264) ))
+	{
+		v4l2_buf.addrPhyY		= mVideoBuffer.buf_phy_addr[buf.index];//- 0x20000000; 
 		v4l2_buf.addrVirY		= mVideoBuffer.buf_vir_addr[buf.index]; 
+		v4l2_buf.width			= mStream_info.video_width;
+		v4l2_buf.height 		= mStream_info.video_height;
 	}
+#endif
+#ifdef CDX20
+	else if(mVideoFormat != V4L2_PIX_FMT_YUYV
+		&&( (mCaptureFormat == V4L2_PIX_FMT_MJPEG) || (mCaptureFormat == V4L2_PIX_FMT_H264) ))
+	{
+		v4l2_buf.addrPhyY		= mVideoBuffer.buf_phy_addr[buf.index];//- 0x20000000;
+		v4l2_buf.addrVirY		= mVideoBuffer.buf_vir_addr[buf.index];
+		v4l2_buf.width			= mFrameWidth;//mVideoInfo.nWidth;
+		v4l2_buf.height 		= mFrameHeight;//mVideoInfo.nHeight;
+	}
+#endif
+
 	else
 	{
+		v4l2_buf.addrPhyY		= buf.m.offset;// - 0x20000000;  //dram addr offset for ve 
 
-		v4l2_buf.addrPhyY		= buf.m.offset - BUFFER_PHY_OFFSET;
+#ifdef __SUN9I__
+		v4l2_buf.addrPhyY		= buf.m.offset;  //dram addr offset for ve
+#endif
 		v4l2_buf.addrVirY		= (unsigned long)mMapMem.mem[buf.index];
+		v4l2_buf.width			= mFrameWidth;
+		v4l2_buf.height			= mFrameHeight;
 	}
 	v4l2_buf.index				= buf.index;
 	v4l2_buf.timeStamp			= mCurFrameTimestamp;
-	v4l2_buf.width				= mFrameWidth;
-	v4l2_buf.height				= mFrameHeight;
+
 	v4l2_buf.crop_rect.left		= mRectCrop.left;
 	v4l2_buf.crop_rect.top		= mRectCrop.top;
 	v4l2_buf.crop_rect.width	= mRectCrop.right - mRectCrop.left + 1;
 	v4l2_buf.crop_rect.height	= mRectCrop.bottom - mRectCrop.top + 1;
 	v4l2_buf.format				= mVideoFormat;
-	
-#if DBG_BUFFER_SAVE
-	LOGD("Debug to save yuv data! Size:%dx%d",mFrameWidth,mFrameHeight);
-	unsigned int length = 0;
-	length = mFrameWidth*mFrameHeight*3/2;
-	saveframe("/data/camera/capture.bin",(void *)v4l2_buf.addrPhyY, length, 1);
-	saveSize(mFrameWidth,mFrameHeight);
-#endif
 
+	v4l2_buf.bytesused	        = buf.bytesused;
 	if (mHalCameraInfo.fast_picture_mode)
 	{
 		v4l2_buf.isThumbAvailable		= 1;
@@ -931,8 +1070,8 @@ bool V4L2CameraDevice::captureThread()
 		{
 			v4l2_buf.thumbUsedForVideo		= 0;
 		}
-		v4l2_buf.thumbAddrPhyY			= v4l2_buf.addrPhyY + ALIGN_4K(ALIGN_16B(mFrameWidth) * mFrameHeight * 3 / 2);	// to do
-		v4l2_buf.thumbAddrVirY			= v4l2_buf.addrVirY + ALIGN_4K(ALIGN_16B(mFrameWidth) * mFrameHeight * 3 / 2);	// to do
+		v4l2_buf.thumbAddrPhyY			= v4l2_buf.addrPhyY + ALIGN_4K(ALIGN_32B(mFrameWidth) * mFrameHeight * 3 / 2);	// to do
+		v4l2_buf.thumbAddrVirY			= v4l2_buf.addrVirY + ALIGN_4K(ALIGN_32B(mFrameWidth) * mFrameHeight * 3 / 2);	// to do
 		v4l2_buf.thumbWidth				= mThumbWidth;
 		v4l2_buf.thumbHeight			= mThumbHeight;
 		v4l2_buf.thumb_crop_rect.left	= mThumbRectCrop.left;
@@ -945,7 +1084,23 @@ bool V4L2CameraDevice::captureThread()
 	{
 		v4l2_buf.isThumbAvailable		= 0;
 	}
-	
+/*
+    int SnrValue = getSnrValue();
+    int SnrLevel = SnrValue >> 8;
+    int Gain = (SnrValue & 0xff);
+    
+    if (SnrLevel != 0 && Gain > 16)
+    {
+        Gain = Gain/16;
+	    char *cnr_uv = (char *)v4l2_buf.thumbAddrVirY + ALIGN_16B(v4l2_buf.thumbWidth) * v4l2_buf.thumbHeight;
+		PreviewCnr(SnrLevel, Gain, v4l2_buf.thumbWidth, v4l2_buf.thumbHeight,cnr_uv , cnr_uv);
+		if(mTakePictureState == TAKE_PICTURE_FAST)
+	    {
+			cnr_uv = (char *)v4l2_buf.addrVirY + ALIGN_16B(mFrameWidth) * mFrameHeight;
+			PreviewCnr(SnrLevel+1, Gain, mFrameWidth, mFrameHeight,cnr_uv , cnr_uv);
+        }
+    }
+*/
 	v4l2_buf.refCnt = 1;
 	memcpy(&mV4l2buf[v4l2_buf.index], &v4l2_buf, sizeof(V4L2BUF_t));
 	if ((!mVideoHint) && (mTakePictureState != TAKE_PICTURE_NORMAL))
@@ -957,6 +1112,8 @@ bool V4L2CameraDevice::captureThread()
 	if (mTakePictureState == TAKE_PICTURE_NORMAL)
 	{
 		//copy picture buffer
+		unsigned long phy_addr = mPicBuffer.addrPhyY;
+		unsigned long vir_addr = mPicBuffer.addrVirY;
 		int frame_size = mFrameWidth * mFrameHeight * 3 >> 1;
 
 		if (frame_size > MAX_PICTURE_SIZE)
@@ -965,19 +1122,20 @@ bool V4L2CameraDevice::captureThread()
 			pthread_mutex_unlock(&mCaptureMutex);
 			return false;
 		}
-		//copy picture buffer
-		memcpy((void*)&mPicBuffer, &v4l2_buf, sizeof(V4L2BUF_t));
-		mPicBuffer.addrVirY = (unsigned long)camera_phy_alloc_alloc(frame_size);
-		mPicBuffer.addrPhyY = camera_phy_alloc_vir2phy((void*)mPicBuffer.addrVirY);
 		
-		camera_phy_flush_cache((void*)v4l2_buf.addrVirY, frame_size);
+		memcpy((void*)&mPicBuffer, &v4l2_buf, sizeof(V4L2BUF_t));
+		mPicBuffer.addrPhyY = phy_addr;
+		mPicBuffer.addrVirY = vir_addr;
+
+		#ifdef USE_ION_MEM_ALLOCATOR
+		ion_flush_cache((void*)v4l2_buf.addrVirY, frame_size);
+		memcpy((void*)mPicBuffer.addrVirY, (void*)v4l2_buf.addrVirY, frame_size);
+		ion_flush_cache((void*)mPicBuffer.addrVirY, frame_size);
+		#else USE_SUNXI_MEM_ALLOCATOR
+		sunxi_flush_cache((void*)v4l2_buf.addrVirY, frame_size);
 		memcpy((void*)mPicBuffer.addrVirY, (void*)v4l2_buf.addrVirY, frame_size);
-		camera_phy_flush_cache((void*)mPicBuffer.addrVirY, frame_size);
-		//get Exif info for driver
-		struct isp_exif_attribute exif_attri;
-		getExifInfo(&exif_attri);
-		mCallbackNotifier->setExifInfo(exif_attri,mZoomRatio,mExposureBias);
-		mCameraHardware->setExifInfo(exif_attri);
+		sunxi_flush_cache((void*)mPicBuffer.addrVirY, frame_size);
+		#endif
 
 		// enqueue picture buffer
 		ret = OSAL_Queue(&mQueueBufferPicture, &mPicBuffer);
@@ -1009,105 +1167,16 @@ bool V4L2CameraDevice::captureThread()
 		// signal a new frame for preview
 		pthread_cond_signal(&mPreviewCond);
 
-		if (mTakePictureState == TAKE_PICTURE_SCENE_MODE)
-		{
-			int ret;
-			int frame_size = mFrameWidth * mFrameHeight * 3 >> 1;
-			if(mSceneMode == NULL)
-			{
-				pthread_mutex_unlock(&mCaptureMutex);
-				return false;
-			}
-			if(mSceneMode->GetCurrentSceneMode() != SCENE_FACTORY_MODE_HDR &&
-				mSceneMode->GetCurrentSceneMode() != SCENE_FACTORY_MODE_NIGHT)
-				goto DEC_REF;
-			#ifdef USE_ION_MEM_ALLOCATOR
-			ion_flush_cache((void*)v4l2_buf.addrVirY, frame_size);
-			#elif USE_SUNXI_MEM_ALLOCATOR
-			sunxi_flush_cache((void*)v4l2_buf.addrVirY, frame_size);
-			#endif
-			ret = mSceneMode->GetCurrentFrameData((void *)v4l2_buf.addrVirY);
-			//capture target frames finish
-			if(ret == SCENE_CAPTURE_DONE || ret == SCENE_CAPTURE_FAIL){
-				ret = OSAL_Queue(&mQueueBufferPicture, &mV4l2buf[v4l2_buf.index]);
-				if (ret != 0) {
-					LOGW("picture queue full"); //?? no test ??
-					pthread_cond_signal(&mPictureCond);
-					goto DEC_REF;
-				}
-				mV4l2buf[v4l2_buf.index].refCnt++;
-				mTakePictureState = TAKE_PICTURE_NULL;  //stop take picture
-				mIsPicCopy = false;				
-				pthread_cond_signal(&mPictureCond);
-			}
-		}
 		if (mTakePictureState == TAKE_PICTURE_FAST
 			|| mTakePictureState == TAKE_PICTURE_RECORD)
 		{
-			//LOGD("xxxxxxxxxxxxxxxxxxxx buf.reserved: %x", buf.reserved);
 			if (mHalCameraInfo.fast_picture_mode)
 			{
-				//LOGD("af_sharp: %d, hdr_cnt:%d, flash_ok: %d, capture_ok: %d.", mTakePictureFlag.bits.af_sharp, \
-				//get Exif info for driver
-				struct isp_exif_attribute exif_attri;
-				static int flash_fire = 0;
-				getExifInfo(&exif_attri);
-				if(mTakePictureState == TAKE_PICTURE_FAST){
-					//in order to get the right flash status ,it must check the status here.
-					//beause the flash and the flag is asynchronous,it means current flash 
-					//mode is on while flash_fire set at least one time.
-					if(exif_attri.flash_fire == 1)
-						flash_fire = 1;
-					//the current frame buffer is no the target frame,it can't be used for jpg encode
-					static int count = 0;
-					if (mFlashMode == V4L2_FLASH_LED_MODE_NONE  && \
-						mTakePictureFlag.bits.capture_ok == 0) {
-						
-						LOGV("mTakePictureFlag.bits.capture_ok:%d\n",mTakePictureFlag.bits.capture_ok);
-						if(count++ > 20) {
-							count = 0;
-							setTakePictureCtrl(V4L2_TAKE_PICTURE_NORM);
-						}
-						goto DEC_REF;
-					} else {
-						count = 0;
-					}
-					//when flash mode,the target frame buffer flag is 1
-					if (mFlashMode != V4L2_FLASH_LED_MODE_NONE && \
-						mTakePictureFlag.bits.flash_ok == 0 )
-						goto DEC_REF;
-
-					exif_attri.flash_fire = flash_fire;
-					flash_fire = 0;
-				}
-
-				mCallbackNotifier->setExifInfo(exif_attri,mZoomRatio,mExposureBias);
-				mCameraHardware->setExifInfo(exif_attri);
-
-				int SnrValue = getSnrValue();
-				int Gain = ((SnrValue >> V4L2_GAIN_SHIFT)&0xff);
-				int SharpLevel = (SnrValue >> V4L2_SHARP_LEVEL_SHIFT) &0xfff;
-				int SharpMin = (SnrValue >> V4L2_SHARP_MIN_SHIFT)&0x3f;
-				int NdfTh = ((SnrValue >> V4L2_NDF_SHIFT) &0x1f) ;
-				LOGD("Gain = %d, SharpLevel = %d, SharpMin = %d, NdfTh = %d!", Gain, SharpLevel, SharpMin, NdfTh);
-				if (NdfTh > 1)
+				if (buf.reserved == 0xFFFFFFFF)
 				{
-					unsigned char *p_addr =(unsigned char *)malloc((ALIGN_16B(mFrameWidth)*mFrameHeight)>>1);
-					ColorDenoise(p_addr, (unsigned char *)v4l2_buf.addrVirY+ALIGN_16B(mFrameWidth)*mFrameHeight, mFrameWidth, mFrameHeight >> 1, NdfTh + Gain / 24);//6);
-					memcpy((unsigned char *)v4l2_buf.addrVirY+ALIGN_16B(mFrameWidth)*mFrameHeight,p_addr,((ALIGN_16B(mFrameWidth)*mFrameHeight)>>1));
-					free(p_addr);
-				}
-				if (SharpLevel > 0)
-				{
-					Sharpen((unsigned char *)v4l2_buf.addrVirY, SharpMin,SharpLevel, mFrameWidth,mFrameHeight);
+					goto DEC_REF;
 				}
 			}
-			else{
-				struct isp_exif_attribute exif_attri;
-				getExifInfo(&exif_attri);
-				mCallbackNotifier->setExifInfo(exif_attri,mZoomRatio,mExposureBias);
-				mCameraHardware->setExifInfo(exif_attri);
-			}
 			
 			// enqueue picture buffer
 			ret = OSAL_Queue(&mQueueBufferPicture, &mV4l2buf[v4l2_buf.index]);
@@ -1124,39 +1193,29 @@ bool V4L2CameraDevice::captureThread()
 			mIsPicCopy = false;
 			pthread_cond_signal(&mPictureCond);
 		}
-		
+
 		if (mTakePictureState == TAKE_PICTURE_SMART)
 		{
-			//get Exif info for driver
-			if (mHalCameraInfo.fast_picture_mode)
-				if (mTakePictureFlag.bits.fast_capture_ok == 0)
-					goto DEC_REF;
-			struct isp_exif_attribute exif_attri;
-			getExifInfo(&exif_attri);
-			mCallbackNotifier->setExifInfo(exif_attri,mZoomRatio,mExposureBias);
-			mCameraHardware->setExifInfo(exif_attri);
-
 			// enqueue picture buffer
 			ret = OSAL_Queue(&mQueueBufferPicture, &mV4l2buf[v4l2_buf.index]);
 			if (ret != 0)
-				{
+			{
 				LOGW("picture queue full");
 				pthread_cond_signal(&mSmartPictureCond);
-					goto DEC_REF;
-				}
+				goto DEC_REF;
+			}
+			
 			// add reference count
 			mV4l2buf[v4l2_buf.index].refCnt++;
 			//mTakePictureState = TAKE_PICTURE_NULL;
 			mIsPicCopy = false;
 			pthread_cond_signal(&mSmartPictureCond);
 		}
-			
+		
 		if ((mTakePictureState == TAKE_PICTURE_CONTINUOUS
 			|| mTakePictureState == TAKE_PICTURE_CONTINUOUS_FAST)
 			&& isContinuousPictureTime())
 		{
-			if (mTakePictureFlag.bits.fast_capture_ok == 0)
-				goto DEC_REF;
 			// enqueue picture buffer
 			ret = OSAL_Queue(&mQueueBufferPicture, &mV4l2buf[v4l2_buf.index]);
 			if (ret != 0)
@@ -1166,11 +1225,6 @@ bool V4L2CameraDevice::captureThread()
 				goto DEC_REF;
 			}
 
-			//get Exif info for driver
-			struct isp_exif_attribute exif_attri;
-			getExifInfo(&exif_attri);
-			mCallbackNotifier->setExifInfo(exif_attri,mZoomRatio,mExposureBias);
-			mCameraHardware->setExifInfo(exif_attri);
 			// add reference count
 			mV4l2buf[v4l2_buf.index].refCnt++;
 			mIsPicCopy = false;
@@ -1180,6 +1234,7 @@ bool V4L2CameraDevice::captureThread()
 
 DEC_REF:
 	pthread_mutex_unlock(&mCaptureMutex);
+	
 	releasePreviewFrame(v4l2_buf.index);
 	
     return true;
@@ -1190,57 +1245,42 @@ bool V4L2CameraDevice::previewThread()
 	V4L2BUF_t * pbuf = (V4L2BUF_t *)OSAL_Dequeue(&mQueueBufferPreview);
 	if (pbuf == NULL)
 	{
-		LOGV("preview queue no buffer, sleep...");
+		// LOGV("picture queue no buffer, sleep...");
 		pthread_mutex_lock(&mPreviewMutex);
 		pthread_cond_wait(&mPreviewCond, &mPreviewMutex);
 		pthread_mutex_unlock(&mPreviewMutex);
 		return true;
 	}
-	//nsecs_t beforePrevew = (int64_t)systemTime();
-	pthread_mutex_lock(&mPreviewSyncMutex);
-	if(mPreviewThreadState == PREVIEW_STATE_PAUSED){
-		LOGV("preview thread paused");
-		pthread_cond_wait(&mPreviewSyncCond, &mPreviewSyncMutex);
-	}
 
 	Mutex::Autolock locker(&mObjectLock);
 	if (mMapMem.mem[pbuf->index] == NULL
 		|| pbuf->addrPhyY == 0)
 	{
 		LOGV("preview buffer have been released...");
-		pthread_mutex_unlock(&mPreviewSyncMutex);
 		return true;
 	}
-
+	//showformat(pbuf->format,"CallBack");
 	// callback
 	mCallbackNotifier->onNextFrameAvailable((void*)pbuf, mUseHwEncoder);
 
 	// preview
+	// if (isPreviewTime())
+#ifdef __SUN9I__
+	mPreviewWindow->onNextFrameAvailable((void*)pbuf);
+#else
 	if (!mNeedHalfFrameRate || mShouldPreview)
 	{
-	mPreviewWindow->onNextFrameAvailable((void*)pbuf);
+		mPreviewWindow->onNextFrameAvailable((void*)pbuf);
 	}
 	mShouldPreview = mShouldPreview ? false : true;
+#endif
 
-	//nsecs_t interval = (int64_t)systemTime() - beforePrevew;
-	//LOGE("preview id : %d, interval: %ld", pbuf->index, interval);
+	// LOGD("preview id : %d", pbuf->index);
 
 	releasePreviewFrame(pbuf->index);
-	pthread_mutex_unlock(&mPreviewSyncMutex);
 
 	return true;
 }
-void V4L2CameraDevice::stopPreviewThread()
-{
-	LOGV("stop preview thread!\n");
-	pthread_mutex_lock(&mPreviewSyncMutex);
-	if(mPreviewThreadState == PREVIEW_STATE_STARTED)
-	{
-		mPreviewThreadState = PREVIEW_STATE_PAUSED;
-		LOGV("set mPreviewThreadState to %d\n",mPreviewThreadState);
-	}
-	pthread_mutex_unlock(&mPreviewSyncMutex);
-}
 
 // singal picture
 bool V4L2CameraDevice::pictureThread()
@@ -1259,18 +1299,8 @@ bool V4L2CameraDevice::pictureThread()
 
 	// notify picture cb
 	mCameraHardware->notifyPictureMsg((void*)pbuf);
-	if(mSceneMode != NULL){
-		if(mSceneMode->GetCurrentSceneMode() == SCENE_FACTORY_MODE_HDR){
-			int ret;
-			ret = mSceneMode->PostScenePicture((void*) pbuf->addrVirY);		
-			stopSceneModePicture();		
-		}
-		else if(mSceneMode->GetCurrentSceneMode() == SCENE_FACTORY_MODE_NIGHT){
-			int ret;
-			ret = mSceneMode->PostScenePicture((void*) pbuf->addrVirY);
-			stopSceneModePicture();
-		}
-	}
+
+	DBG_TIME_DIFF("notifyPictureMsg");
 
 	mCallbackNotifier->takePicture((void*)pbuf);
 	
@@ -1282,16 +1312,12 @@ bool V4L2CameraDevice::pictureThread()
 	{
 		releasePreviewFrame(pbuf->index);
 	}
-    if (mPicBuffer.addrVirY != 0)
-	{
-		camera_phy_alloc_free((void*)mPicBuffer.addrVirY);
-		mPicBuffer.addrPhyY = 0;
-	}
 
 	DBG_TIME_END("Take picture", 0);
 
 	return true;
 }
+
 // blink picture
 bool V4L2CameraDevice::smartPictureThread()
 {
@@ -1316,8 +1342,8 @@ bool V4L2CameraDevice::smartPictureThread()
 		}
 		return true;
 	}
-
-    #if 0
+	
+    #if 1
 
 	ALOGD("!! mCameraHardware->mBlinkPictureResult %d state %d", mCameraHardware->mBlinkPictureResult, mCameraHardware->mBlinkDetectionState);
 
@@ -1332,6 +1358,8 @@ bool V4L2CameraDevice::smartPictureThread()
 
 		mCallbackNotifier->takePicture((void*)pbuf);
 
+		ALOGD("~~ smartPictureThread takePicture");
+
 		stopSmartPicture();
         mTakePictureState = TAKE_PICTURE_NULL;
 	}
@@ -1340,7 +1368,7 @@ bool V4L2CameraDevice::smartPictureThread()
 
 	#if 1
 
-	ALOGD("!!! mCameraHardware->mSmilePictureResult %d, state %d", mCameraHardware->mSmilePictureResult, mCameraHardware->mSmileDetectionState);
+	ALOGD("!! mCameraHardware->mSmilePictureResult %d, state %d", mCameraHardware->mSmilePictureResult, mCameraHardware->mSmileDetectionState);
 
 	if ((mCameraHardware->mSmilePictureResult == true) && (mCameraHardware->mSmileDetectionState == FACE_DETECTION_PREPARED))
 	{
@@ -1353,38 +1381,14 @@ bool V4L2CameraDevice::smartPictureThread()
 
 		mCallbackNotifier->takePicture((void*)pbuf);
 
+		ALOGD("~~ smartPictureThread takePicture");
+
 		stopSmartPicture();
         mTakePictureState = TAKE_PICTURE_NULL;
 	}
 	
 	#endif
 
-    #if 1
-
-	if (mStartSmartTimeout == false)
-	{
-		if ((systemTime() / 1000000 - mStartSmartTimeMs) > 5000)	// 5s timeout
-		{
-			mStartSmartTimeout = true;
-			
-			ALOGV("taking smile picture time out!!!");
-
-			DBG_TIME_BEGIN("taking smile picture time out!!!", 0);
-
-			// notify picture cb
-			mCameraHardware->notifyPictureMsg((void*)pbuf);
-
-			DBG_TIME_DIFF("notifyPictureMsg");
-
-			mCallbackNotifier->takePicture((void*)pbuf);
-
-			stopSmartPicture();
-	        mTakePictureState = TAKE_PICTURE_NULL;
-		}
-	}
-	
-	#endif
-
 	char str[128];
 	sprintf(str, "hw picture size: %dx%d", pbuf->width, pbuf->height);
 	DBG_TIME_DIFF(str);
@@ -1405,8 +1409,6 @@ void V4L2CameraDevice::startSmartPicture()
 	F_LOG;
 
 	mSmartPictureDone = false;
-	mStartSmartTimeout = false;
-	mStartSmartTimeMs = systemTime() / 1000000;
 
 	DBG_TIME_AVG_INIT(TAG_SMART_PICTURE);
 }
@@ -1420,66 +1422,12 @@ void V4L2CameraDevice::stopSmartPicture()
 		LOGD("Smart picture has already stopped");
 		return;
 	}
-	mStartSmartTimeout = true;
+	
 	mSmartPictureDone = true;
 
 	DBG_TIME_AVG_END(TAG_SMART_PICTURE, "picture enc");
 }
 
-status_t V4L2CameraDevice::openSceneMode(const char* scenemode)
-{
-	F_LOG;
-	int ret;
-	int mode = 0;
-	//HDR sence
-	if (!strcmp(scenemode, CameraParameters::SCENE_MODE_HDR)){
-		mode = SCENE_FACTORY_MODE_HDR;
-	}
-	if(!strcmp(scenemode, CameraParameters::SCENE_MODE_NIGHT)){
-		mode = SCENE_FACTORY_MODE_NIGHT;
-	}
-	
-	mSceneMode = mSceneModeFactory.CreateSceneMode(mode);
-	if(mSceneMode == NULL){
-		LOGE("SceneModeFactory CreateSceneMode failed");
-		mSceneModeFactory.DestorySceneMode(NULL);
-		return -1;
-	}
-	mSceneMode->SetCallBack(SceneNotifyCallback,(void*)this);
-
-	ret = mSceneMode->InitSceneMode(mFrameWidth,mFrameHeight);
-	if(ret == -1){
-		LOGE("SceneMode Init faided");
-		return -1;
-	}
-	return 0;	
-}
-
-void V4L2CameraDevice::closeSceneMode()
-{
-	F_LOG;
-	
-	if(mSceneMode != NULL){
-		mSceneMode->ReleaseSceneMode();
-		mSceneModeFactory.DestorySceneMode(mSceneMode);
-		mSceneMode = NULL;
-		//when close scene mode, it must restore the flash status
-		setFlashMode(mFlashMode);
-	}
-}
-
-
-void V4L2CameraDevice::startSceneModePicture(int scenemode)
-{
-	F_LOG
-	mSceneMode->StartScenePicture();
-}
-
-void V4L2CameraDevice::stopSceneModePicture()
-{
-	F_LOG
-	mSceneMode->StopScenePicture();
-}
 
 // continuous picture
 bool V4L2CameraDevice::continuousPictureThread()
@@ -1600,6 +1548,7 @@ bool V4L2CameraDevice::isPreviewTime()
 	{
 		return true;
 	}
+	
     timeval cur_time;
     gettimeofday(&cur_time, NULL);
     const uint64_t cur_mks = cur_time.tv_sec * 1000000LL + cur_time.tv_usec;
@@ -1609,6 +1558,7 @@ bool V4L2CameraDevice::isPreviewTime()
     }
     return false;
 }
+
 void V4L2CameraDevice::waitFaceDectectTime()
 {
     timeval cur_time;
@@ -1627,8 +1577,9 @@ void V4L2CameraDevice::waitFaceDectectTime()
 	}
 }
 
-int V4L2CameraDevice::getCurrentFaceFrame(void* frame, int* width, int* height)
+int V4L2CameraDevice::getCurrentFaceFrame(void * frame)
 {
+    int len = 0;
 	if (frame == NULL)
 	{
 		LOGE("getCurrentFrame: error in null pointer");
@@ -1645,9 +1596,7 @@ int V4L2CameraDevice::getCurrentFaceFrame(void* frame, int* width, int* height)
 	}
 	pthread_mutex_unlock(&mCaptureMutex);
 	
-#ifdef WATI_FACEDETECT
-	waitFaceDectectTime();
-#endif
+	//waitFaceDectectTime();
 
     Mutex::Autolock locker(&mObjectLock);
 	
@@ -1657,27 +1606,24 @@ int V4L2CameraDevice::getCurrentFaceFrame(void* frame, int* width, int* height)
 		LOGW("frame buffer not ready");
 		return -1;
 	}
-	//LOGV("getCurrentFaceFrame: %dx%d", mCurrentV4l2buf->width, mCurrentV4l2buf->height);
 
 	if ((mCurrentV4l2buf->isThumbAvailable == 1)
 		&& (mCurrentV4l2buf->thumbUsedForPreview == 1))
 	{
-		camera_phy_flush_cache((void*)mCurrentV4l2buf->addrVirY + (ALIGN_16B(mCurrentV4l2buf->width) * mCurrentV4l2buf->height * 3 / 2), ALIGN_16B(mCurrentV4l2buf->thumbWidth) * mCurrentV4l2buf->thumbHeight);
 		memcpy(frame, 
-				(void*)mCurrentV4l2buf->addrVirY + ALIGN_4K((ALIGN_16B(mCurrentV4l2buf->width) * mCurrentV4l2buf->height * 3 / 2)), 
+				(void*)mCurrentV4l2buf->addrVirY + ALIGN_4K(ALIGN_16B(mCurrentV4l2buf->width) * mCurrentV4l2buf->height * 3 / 2), 
 				ALIGN_16B(mCurrentV4l2buf->thumbWidth) * mCurrentV4l2buf->thumbHeight);
-		*width = mCurrentV4l2buf->thumbWidth;
-		*height = mCurrentV4l2buf->thumbHeight;
+
+		len = ALIGN_16B(mCurrentV4l2buf->thumbWidth) * mCurrentV4l2buf->thumbHeight;
 	}
 	else
 	{
-		camera_phy_flush_cache((void*)mCurrentV4l2buf->addrVirY, mCurrentV4l2buf->width * mCurrentV4l2buf->height);
 		memcpy(frame, (void*)mCurrentV4l2buf->addrVirY, mCurrentV4l2buf->width * mCurrentV4l2buf->height);
-		*width = mCurrentV4l2buf->width;
-		*height = mCurrentV4l2buf->height;
+		len =  mCurrentV4l2buf->width * mCurrentV4l2buf->height;
 	}
-	//LOGV("getCurrentFaceFrame: %dx%d", *width, *height);
-	return 0;
+
+	//return 0;
+	return len;
 }
 
 // -----------------------------------------------------------------------------
@@ -1686,10 +1632,11 @@ int V4L2CameraDevice::getCurrentFaceFrame(void* frame, int* width, int* height)
 int V4L2CameraDevice::openCameraDev(HALCameraInfo * halInfo)
 {
 	F_LOG;
-	
+
 	int ret = -1;
 	struct v4l2_input inp;
 	struct v4l2_capability cap; 
+	char dev_node[16];
 
 	if (halInfo == NULL)
 	{
@@ -1698,13 +1645,34 @@ int V4L2CameraDevice::openCameraDev(HALCameraInfo * halInfo)
 	}
 	
 	// open V4L2 device
-	mCameraFd = open(halInfo->device_name, O_RDWR | O_NONBLOCK, 0);
-	if (mCameraFd == -1) 
-	{ 
-        LOGE("ERROR opening %s: %s", halInfo->device_name, strerror(errno)); 
-		return -1; 
-	}
-
+    //-----------------------------------------------
+    //If "video0" not exist, use others instead
+    //Modified by Microphone
+    //2013-11-14
+    //-----------------------------------------------
+    if((access(halInfo->device_name, F_OK)) == 0)
+    {
+        strcpy(dev_node,halInfo->device_name);
+    }
+    else
+    {
+        for (int i = 0; i < MAX_NUM_OF_CAMERAS; i++)
+        {
+            sprintf(dev_node, "/dev/video%d", i);
+            ret = access(dev_node, F_OK);
+            if(ret == 0)
+            {
+                break;
+            }
+        }
+    }
+    mCameraFd = open(dev_node, O_RDWR | O_NONBLOCK, 0);
+    if (mCameraFd == -1)
+    {
+        LOGE("ERROR opening %s: %s", dev_node, strerror(errno));
+        return -1;
+    }
+    //-------------------------------------------------
 	// check v4l2 device capabilities
 	ret = ioctl (mCameraFd, VIDIOC_QUERYCAP, &cap); 
     if (ret < 0) 
@@ -1729,6 +1697,7 @@ int V4L2CameraDevice::openCameraDev(HALCameraInfo * halInfo)
 	{
 		mIsUsbCamera = true;
 	}
+	LOGD("The name of the Camera is '%s'",cap.card);
 
 	if (!mIsUsbCamera)
 	{
@@ -1745,16 +1714,43 @@ int V4L2CameraDevice::openCameraDev(HALCameraInfo * halInfo)
 	{
 		// try to support this format: NV21, YUYV
 		// we do not support mjpeg camera now
+
+		mCameraList = new CameraList();
+		bool isSupported = false;
+		char *res = strstr(mCameraList->mCameraDeviceList,(char const *)cap.card);
+		//if(mCameraList->mCameraDeviceList != NULL)LOGI("MJPEG Camera '%s',mCameraList->mCameraDeviceList lenght = %d",mCameraList->mCameraDeviceList,strlen((char const *)mCameraList->mCameraDeviceList));
+		//if(res != NULL)LOGI("MJPEG Camera '%s',sizeof = %d",res,strlen((char const *)res));
+		//LOGI("MJPEG Camera '%s',sizeof = %d",cap.card,strlen((char const *)cap.card));
+		if(res != NULL){
+		    if(!strncmp((char const *)cap.card,(char const *)res,strlen((char const *)cap.card))){
+			    isSupported = true;
+			    LOGI("MJPEG Camera '%s' is Supported",cap.card);
+		    }
+		}else{
+			LOGI("MJPEG Camera '%s' is not Supported",cap.card);
+		}
+		delete mCameraList;
+
 		if (tryFmt(V4L2_PIX_FMT_NV21) == OK)
 		{
 			mCaptureFormat = V4L2_PIX_FMT_NV21;
 			LOGV("capture format: V4L2_PIX_FMT_NV21");
 		}
+		else if(isSupported && (tryFmt(V4L2_PIX_FMT_MJPEG) == OK))
+		{
+			mCaptureFormat = V4L2_PIX_FMT_MJPEG;		// maybe usb camera
+			LOGV("capture format: V4L2_PIX_FMT_MJPEG");
+		}
 		else if(tryFmt(V4L2_PIX_FMT_YUYV) == OK)
 		{
 			mCaptureFormat = V4L2_PIX_FMT_YUYV;		// maybe usb camera
 			LOGV("capture format: V4L2_PIX_FMT_YUYV");
 		}
+		else if(tryFmt(V4L2_PIX_FMT_H264) == OK)
+		{
+			mCaptureFormat = V4L2_PIX_FMT_H264;
+			LOGV("capture format: V4L2_PIX_FMT_H264");
+		}
 		else
 		{
 			LOGE("driver should surpport NV21/NV12 or YUYV format, but it not!");
@@ -1786,7 +1782,7 @@ void V4L2CameraDevice::closeCameraDev()
 	}
 }
 
-#ifdef __PLATFORM_A64__
+#ifdef __PLATFORM_H64__
 int V4L2CameraDevice::v4l2SetVideoParams(int width, int height, uint32_t pix_fmt)
 {
 	int ret = UNKNOWN_ERROR;
@@ -1795,14 +1791,25 @@ int V4L2CameraDevice::v4l2SetVideoParams(int width, int height, uint32_t pix_fmt
 
 	LOGV("%s, line: %d, w: %d, h: %d, pfmt: %d", 
 		__FUNCTION__, __LINE__, width, height, pix_fmt);
-	
+	mCaptureFormat == V4L2_PIX_FMT_YUYV;
 	memset(&format, 0, sizeof(format));
     format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE; 
     format.fmt.pix.width  = width;
     format.fmt.pix.height = height;
-    if (mCaptureFormat == V4L2_PIX_FMT_YUYV)
+	if(mCaptureFormat == V4L2_PIX_FMT_MJPEG)
+	{
+		format.fmt.pix.pixelformat = V4L2_PIX_FMT_MJPEG;
+		LOGV("set capture format: V4L2_PIX_FMT_MJPEG");
+	}
+	else if (mCaptureFormat == V4L2_PIX_FMT_YUYV)
 	{
     	format.fmt.pix.pixelformat = V4L2_PIX_FMT_YUYV; 
+		LOGV("set capture format: V4L2_PIX_FMT_YUYV");
+	}
+	else if (mCaptureFormat == V4L2_PIX_FMT_H264)
+	{
+		format.fmt.pix.pixelformat = V4L2_PIX_FMT_H264;
+		LOGV("set capture format: V4L2_PIX_FMT_YUYV");
 	}
 	else
 	{
@@ -1886,9 +1893,20 @@ int V4L2CameraDevice::v4l2SetVideoParams(int width, int height, uint32_t pix_fmt
     format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE; 
     format.fmt.pix.width  = width;
     format.fmt.pix.height = height;
-    if (mCaptureFormat == V4L2_PIX_FMT_YUYV)
+	if(mCaptureFormat == V4L2_PIX_FMT_MJPEG)
+	{
+		format.fmt.pix.pixelformat = V4L2_PIX_FMT_MJPEG;
+		LOGV("set capture format: V4L2_PIX_FMT_MJPEG");
+	}
+	else if (mCaptureFormat == V4L2_PIX_FMT_YUYV)
 	{
     	format.fmt.pix.pixelformat = V4L2_PIX_FMT_YUYV; 
+		LOGV("set capture format: V4L2_PIX_FMT_YUYV");
+	}
+	else if (mCaptureFormat == V4L2_PIX_FMT_H264)
+	{
+		format.fmt.pix.pixelformat = V4L2_PIX_FMT_H264;
+		LOGV("set capture format: V4L2_PIX_FMT_YUYV");
 	}
 	else
 	{
@@ -1907,14 +1925,10 @@ int V4L2CameraDevice::v4l2SetVideoParams(int width, int height, uint32_t pix_fmt
 			LOGE("error thumb scale: %d, src_size: %dx%d", scale, width, height);
 			return UNKNOWN_ERROR;
 		}
-		int sub_width,sub_height;
-		sub_width = format.fmt.pix.width / scale;
-		sub_height = format.fmt.pix.height / scale;
-		mCameraHardware->getPriviewSize(&sub_width,&sub_height,format.fmt.pix.width,format.fmt.pix.height);
 		
 		format.fmt.pix.subchannel = &sub_fmt;
-		format.fmt.pix.subchannel->width = sub_width;
-		format.fmt.pix.subchannel->height = sub_height;
+		format.fmt.pix.subchannel->width = format.fmt.pix.width / scale;
+		format.fmt.pix.subchannel->height = format.fmt.pix.height / scale;
 		format.fmt.pix.subchannel->pixelformat = pix_fmt;
 		format.fmt.pix.subchannel->field = V4L2_FIELD_NONE;	
 		LOGV("to camera params: w: %d, h: %d, sub: %dx%d, pfmt: %d, pfield: %d", 
@@ -2019,16 +2033,15 @@ int V4L2CameraDevice::v4l2QueryBuf()
 
 		if (mIsUsbCamera)		// star to do
 		{
-			int buffer_len = mFrameWidth * mFrameHeight * 3 / 2;
-			
-#ifdef USE_ION_MEM_ALLOCATOR
+			int buffer_len = mFrameWidth * mFrameHeight * 2;
+		
+		    #ifdef USE_ION_MEM_ALLOCATOR
 			mVideoBuffer.buf_vir_addr[i] = (int)ion_alloc_alloc(buffer_len);
 			mVideoBuffer.buf_phy_addr[i] = ion_alloc_vir2phy((void*)mVideoBuffer.buf_vir_addr[i]);
-#elif USE_SUNXI_MEM_ALLOCATOR
+	            #else USE_SUNXI_MEM_ALLOCATOR
 			mVideoBuffer.buf_vir_addr[i] = (int)sunxi_alloc_alloc(buffer_len);
 			mVideoBuffer.buf_phy_addr[i] = sunxi_alloc_vir2phy((void*)mVideoBuffer.buf_vir_addr[i]);
-#endif/*USE_ION_MEM_ALLOCATOR*/
-
+		    #endif
 			LOGV("video buffer: index: %d, vir: %x, phy: %x, len: %x", 
 					i, mVideoBuffer.buf_vir_addr[i], mVideoBuffer.buf_phy_addr[i], buffer_len);
 			
@@ -2092,19 +2105,18 @@ int V4L2CameraDevice::v4l2UnmapBuf()
 
 		if (mVideoBuffer.buf_vir_addr[i] != 0)
 		{
-#ifdef USE_ION_MEM_ALLOCATOR
+		    #ifdef USE_ION_MEM_ALLOCATOR
 			ion_alloc_free((void*)mVideoBuffer.buf_vir_addr[i]);
 			mVideoBuffer.buf_phy_addr[i] = 0;
-#elif USE_SUNXI_MEM_ALLOCATOR
+		    #else USE_SUNXI_MEM_ALLOCATOR
 			sunxi_alloc_free((void*)mVideoBuffer.buf_vir_addr[i]);
-
 			mVideoBuffer.buf_phy_addr[i] = 0;
 		    #endif
 		}
 	}
 	mVideoBuffer.buf_unused = NB_BUFFER;
 	mVideoBuffer.read_id = 0;
-	mVideoBuffer.write_id = 0;
+	mVideoBuffer.read_id = 0;
 	
 	return OK;
 }
@@ -2113,7 +2125,7 @@ void V4L2CameraDevice::releasePreviewFrame(int index)
 {
 	int ret = UNKNOWN_ERROR;
 	struct v4l2_buffer buf;
-
+	
 	pthread_mutex_lock(&mCaptureMutex);
 
 	// decrease buffer reference count first, if the reference count is no more than 0, release it.
@@ -2125,9 +2137,9 @@ void V4L2CameraDevice::releasePreviewFrame(int index)
 	    buf.memory = V4L2_MEMORY_MMAP; 
 		buf.index = index;
 		
-		//LOGD("r ID: %d", buf.index);
-	  ret = ioctl(mCameraFd, VIDIOC_QBUF, &buf); 
-	  if (ret != 0) 
+		// LOGD("r ID: %d", buf.index);
+	    ret = ioctl(mCameraFd, VIDIOC_QBUF, &buf); 
+	    if (ret != 0) 
 		{
 	        LOGE("releasePreviewFrame: VIDIOC_QBUF Failed: index = %d, ret = %d, %s", 
 				buf.index, ret, strerror(errno)); 
@@ -2137,6 +2149,7 @@ void V4L2CameraDevice::releasePreviewFrame(int index)
 			mCurAvailBufferCnt++;
 		}
 	}
+
 	pthread_mutex_unlock(&mCaptureMutex);
 }
 
@@ -2186,17 +2199,25 @@ int V4L2CameraDevice::tryFmtSize(int * width, int * height)
 	int ret = -1;
 	struct v4l2_format fmt;
 
-	LOGV("Before V4L2Camera::TryFmtSize: w: %d, h: %d", *width, *height);
+	LOGV("V4L2Camera::TryFmtSize: w: %d, h: %d", *width, *height);
 
 
 	memset(&fmt, 0, sizeof(fmt));
     fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE; 
     fmt.fmt.pix.width  = *width; 
     fmt.fmt.pix.height = *height; 
-    if (mCaptureFormat == V4L2_PIX_FMT_YUYV)
+	if(mCaptureFormat == V4L2_PIX_FMT_MJPEG)
+	{
+		fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_MJPEG;
+	}
+	else if (mCaptureFormat == V4L2_PIX_FMT_YUYV)
 	{
 		fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_YUYV;
 	}
+	else if (mCaptureFormat == V4L2_PIX_FMT_H264)
+	{
+		fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_H264;
+	}
 	else
 	{
     	fmt.fmt.pix.pixelformat = mVideoFormat; 
@@ -2212,8 +2233,7 @@ int V4L2CameraDevice::tryFmtSize(int * width, int * height)
 
 	// driver surpport this size
 	*width = fmt.fmt.pix.width; 
-    	*height = fmt.fmt.pix.height; 
-	LOGV("After V4L2Camera::TryFmtSize: w: %d, h: %d", *width, *height);
+    *height = fmt.fmt.pix.height; 
 
 	return 0;
 }
@@ -2289,21 +2309,19 @@ int V4L2CameraDevice::setWhiteBalance(int wb)
 	return ret;
 }
 
-int V4L2CameraDevice::setTakePictureCtrl(enum v4l2_take_picture value)
+int V4L2CameraDevice::setTakePictureCtrl()
 {
 	struct v4l2_control ctrl;
 	int ret = -1;
 	if (mHalCameraInfo.fast_picture_mode){
-		LOGD("setTakePictureCtrl value = %d",value);
-	ctrl.id = V4L2_CID_TAKE_PICTURE;
-		ctrl.value = value;
-	ret = ioctl(mCameraFd, VIDIOC_S_CTRL, &ctrl);
-	if (ret < 0)
-		LOGV("setTakePictureCtrl failed, %s", strerror(errno));
-	else 
-		LOGV("setTakePictureCtrl ok");
+		ctrl.id = V4L2_CID_TAKE_PICTURE;
+		ret = ioctl(mCameraFd, VIDIOC_S_CTRL, &ctrl);
+		if (ret < 0)
+			LOGV("setTakePictureCtrl failed, %s", strerror(errno));
+		else 
+			LOGV("setTakePictureCtrl ok");
 
-	return ret;
+		return ret;
 	}
 	return 0;
 }
@@ -2332,7 +2350,7 @@ int V4L2CameraDevice::setExposureCompensation(int val)
 	F_LOG;
 	int ret = -1;
 	struct v4l2_control ctrl;
-	mExposureBias = val;
+
 	ctrl.id = V4L2_CID_AUTO_EXPOSURE_BIAS;
 	ctrl.value = val;
 	ret = ioctl(mCameraFd, VIDIOC_S_CTRL, &ctrl);
@@ -2345,7 +2363,7 @@ int V4L2CameraDevice::setExposureCompensation(int val)
 }
 
 // ae compensation
-#ifdef __PLATFORM_A64__
+#ifdef __PLATFORM_H64__
 int V4L2CameraDevice::setExposureWind(int num, void *wind)
 {
 	F_LOG;
@@ -2388,16 +2406,7 @@ int V4L2CameraDevice::setFlashMode(int mode)
 	F_LOG;
 	int ret = -1;
 	struct v4l2_control ctrl;
-	mFlashMode = mode;
-	
-	//scene mode must close the flash,eg: HDR,night mode
-	//it ought to do in application,it must do it again here
-	//in order to insure the status in driver. --by henrisk
-	if(mSceneMode != NULL && \
-	  (mSceneMode->GetCurrentSceneMode() == SCENE_FACTORY_MODE_HDR || \
-	   mSceneMode->GetCurrentSceneMode() == SCENE_FACTORY_MODE_NIGHT))
-		mode = V4L2_FLASH_LED_MODE_NONE;
-	
+
 	ctrl.id = V4L2_CID_FLASH_LED_MODE;
 	ctrl.value = mode;
 	ret = ioctl(mCameraFd, VIDIOC_S_CTRL, &ctrl);
@@ -2471,7 +2480,7 @@ int V4L2CameraDevice::setAutoFocusRange(int af_range)
 }
 
 // af wind
-#ifdef __PLATFORM_A64__
+#ifdef __PLATFORM_H64__
 int V4L2CameraDevice::setAutoFocusWind(int num, void *wind)
 {
 	F_LOG;
@@ -2563,33 +2572,8 @@ int V4L2CameraDevice::getAutoFocusStatus()
 	
 	return ret;
 }
-int V4L2CameraDevice::getSnrValue()
-{
-	//F_LOG;
-	int ret = -1;
-	struct v4l2_control ctrl;
-	struct v4l2_queryctrl qc_ctrl;
-
-	if (mCameraFd == NULL)
-	{
-		return 0xFF000000;
-	}
-
-	ctrl.id = V4L2_CID_GAIN;
-	qc_ctrl.id = V4L2_CID_GAIN;
-
-	if (-1 == ioctl (mCameraFd, VIDIOC_QUERYCTRL, &qc_ctrl))
-    {
-	   return 0;
-    }
-	
-	ret = ioctl(mCameraFd, VIDIOC_G_CTRL, &ctrl);
-	return ctrl.value;
-}
-
 
-
-int V4L2CameraDevice::getGainValue() //get gain (trait specially, need the last 8 bits)
+int V4L2CameraDevice::getSnrValue()
 {
 	//F_LOG;
 	int ret = -1;
@@ -2610,159 +2594,9 @@ int V4L2CameraDevice::getGainValue() //get gain (trait specially, need the last
     }
 	
 	ret = ioctl(mCameraFd, VIDIOC_G_CTRL, &ctrl);
-	ctrl.value = ctrl.value &0xff;
-	return ctrl.value;
-}
-
-int V4L2CameraDevice::getExpValue() //get gain (trait specially, need the last 8 bits)
-{
-	//F_LOG;
-	int ret = -1;
-	struct v4l2_control ctrl;
-	struct v4l2_queryctrl qc_ctrl;
-
-	if (mCameraFd == NULL)
-	{
-		return 0xFF000000;
-	}
-
-	ctrl.id = V4L2_CID_EXPOSURE;
-	qc_ctrl.id = V4L2_CID_EXPOSURE;
-
-	if (-1 == ioctl (mCameraFd, VIDIOC_QUERYCTRL, &qc_ctrl))
-    {
-	   return 0;
-    }
-	
-	ret = ioctl(mCameraFd, VIDIOC_G_CTRL, &ctrl);
-	return ctrl.value;
-}
-
-#ifdef __PLATFORM_A64__
-int V4L2CameraDevice::setHDRMode(void *hdr_setting)
-{
-	int ret = -1;
-	struct isp_hdr_ctrl hdr_ctrl;
-
-	hdr_ctrl.flag = HDR_CTRL_SET;
-	hdr_ctrl.count = 0;
-	hdr_ctrl.hdr_t = *(struct isp_hdr_setting_t*)hdr_setting;
-	if (mCameraFd == NULL)
-	{
-		return 0xFF000000;
-	}
-
-	ret = ioctl(mCameraFd, VIDIOC_HDR_CTRL, &hdr_ctrl);
 	return ret;
 }
-#else
-int V4L2CameraDevice::setHDRMode(void *hdr_setting)
-{
-	int ret = -1;
-	struct v4l2_control ctrl;
-	struct v4l2_queryctrl qc_ctrl;
-	
-	ctrl.value = 0;
-	ctrl.user_pt = (unsigned int)hdr_setting;
-	if (mCameraFd == NULL)
-	{
-		return 0xFF000000;
-	}
-	ctrl.id = V4L2_CID_HDR;
-	qc_ctrl.id = V4L2_CID_HDR;
 
-	if (-1 == ioctl (mCameraFd, VIDIOC_QUERYCTRL, &qc_ctrl))
-    {
-	   return 0;
-    }
-	ret = ioctl(mCameraFd, VIDIOC_S_CTRL, &ctrl);
-	return ret;
-}
-#endif
-
-int V4L2CameraDevice::getAeStat(struct isp_stat_buf *AeBuf)
-{
-	int ret = -1;
-	if (mCameraFd == NULL)
-	{
-		return 0xFF000000;
-	}
-	//AeBuf->buf = malloc(0xc00);
-	//memset(AeBuf->buf,0,0xc00);	
-	//LOGD("AeBuf->buf == %x\n",AeBuf->buf);
-	if(AeBuf->buf == NULL){
-		return -1;
-	}
-	ret = ioctl(mCameraFd, VIDIOC_ISP_AE_STAT_REQ, AeBuf);
-	return ret;
-}
-int V4L2CameraDevice::getGammaStat(struct isp_stat_buf *GammaBuf)
-{
-	int ret = -1;
-	#if 1
-	if (mCameraFd == NULL)
-	{
-		return 0xFF000000;
-	}
-	GammaBuf->buf = malloc(0x200);
-	memset(GammaBuf->buf,0,0x200);	
-	LOGD("GammaBuf->buf == %x\n",GammaBuf->buf);
-	if(GammaBuf->buf == NULL){
-		return -1;
-	}
-	//ret = ioctl(mCameraFd, VIDIOC_ISP_GAMMA_REQ, GammaBuf);
-	#endif
-	return ret;
-}
-
-int V4L2CameraDevice::getHistStat(struct isp_stat_buf *HistBuf)
-{
-	int ret = -1;
-	if (mCameraFd == NULL)
-	{
-		return 0xFF000000;
-	}	
-	//HistBuf->buf = malloc(0x200);
-	//memset(HistBuf->buf,0,0x200);
-	if(HistBuf->buf == NULL){
-		return -1;
-	}
-	ret = ioctl(mCameraFd, VIDIOC_ISP_HIST_STAT_REQ, HistBuf);
-	return ret;
-}
-
-int V4L2CameraDevice::setGainValue(int Gain)
-{
-	F_LOG;
-	int ret = -1;
-	struct v4l2_control ctrl;	
-
-	ctrl.id = V4L2_CID_GAIN;
-	ctrl.value = Gain;
-	ret = ioctl(mCameraFd, VIDIOC_S_CTRL, &ctrl);
-	if (ret < 0)
-		LOGE("setGain failed, %s", strerror(errno));
-	else 
-		LOGV("setGain ok");
-	return ret;
-}
-
-int V4L2CameraDevice::setExpValue(int Exp)
-{
-	F_LOG;
-	int ret = -1;
-	struct v4l2_control ctrl;
-	ctrl.id = V4L2_CID_EXPOSURE;	
-	ctrl.value = Exp;
-	
-	ret = ioctl(mCameraFd, VIDIOC_S_CTRL, &ctrl);
-	if (ret < 0)
-		LOGE("Set V4L2_CID_EXPOSURE failed, %s", strerror(errno));
-	else 
-		LOGV("Set V4L2_CID_EXPOSURE ok");
-
-	return ret;
-}
 
 int V4L2CameraDevice::set3ALock(int lock)
 {
@@ -2794,14 +2628,7 @@ int V4L2CameraDevice::v4l2setCaptureParams()
 	}
 	else
 	{
-		if(mVideoHint == true)
-		{
 		params.parm.capture.capturemode = V4L2_MODE_VIDEO;
-		}
-		else
-		{
-			params.parm.capture.capturemode = V4L2_MODE_PREVIEW;
-		}
 	}
 
 	LOGV("VIDIOC_S_PARM mFrameRate: %d, capture mode: %d", mFrameRate, params.parm.capture.capturemode);
@@ -2817,7 +2644,6 @@ int V4L2CameraDevice::v4l2setCaptureParams()
 
 int V4L2CameraDevice::enumSize(char * pSize, int len)
 {
-	F_LOG;
 	struct v4l2_frmsizeenum size_enum;
 	size_enum.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
 	size_enum.pixel_format = mCaptureFormat;
@@ -2853,7 +2679,6 @@ int V4L2CameraDevice::enumSize(char * pSize, int len)
 
 int V4L2CameraDevice::getFullSize(int * full_w, int * full_h)
 {
-	F_LOG;
 	struct v4l2_frmsizeenum size_enum;
 	size_enum.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
 	size_enum.pixel_format = mCaptureFormat;
@@ -2874,13 +2699,11 @@ int V4L2CameraDevice::getFullSize(int * full_w, int * full_h)
 
 int V4L2CameraDevice::getSuitableThumbScale(int full_w, int full_h)
 {
-	F_LOG;
 	int scale = 1;
 	if(mIsThumbUsedForVideo == true)
 	{
 		scale = 2;
 	}
-	//TODO: Get the screen size to calculate the scaler factor
 	if (full_w*full_h > 10*1024*1024)		//maybe 12m,13m,16m
 		return 2;
 	else if(full_w*full_h > 4.5*1024*1024)	//maybe 5m,8m
@@ -2938,51 +2761,6 @@ int V4L2CameraDevice::getSuitableThumbScale(int full_w, int full_h)
 	return 1;		// failed
 #endif
 }
-void V4L2CameraDevice::getThumbSize(int* sub_w, int* sub_h)
-{
-	F_LOG;
-	*sub_w= mThumbWidth;
-	*sub_h= mThumbHeight;
-}
-
-int V4L2CameraDevice::getSensorType()
-{
-	F_LOG;
-	int ret = -1;
-	struct v4l2_control ctrl;
-	struct v4l2_queryctrl qc_ctrl;
 
-	if (mCameraFd == NULL)
-	{
-		return 0xFF000000;
-	}
-
-	ctrl.id = V4L2_CID_SENSOR_TYPE;
-	qc_ctrl.id = V4L2_CID_SENSOR_TYPE;
 
-	if (-1 == ioctl (mCameraFd, VIDIOC_QUERYCTRL, &qc_ctrl))
-	{
-		LOGE("query sensor type ctrl failed");
-		return -1;
-	}
-	ret = ioctl(mCameraFd, VIDIOC_G_CTRL, &ctrl);
-	return ctrl.value;
-}
-int V4L2CameraDevice::getExifInfo(struct isp_exif_attribute *exif_attri)
-{
-	int ret = -1;
-	
-	if (mCameraFd == NULL)
-	{
-		return 0xFF000000;
-	}
-	ret = ioctl(mCameraFd, VIDIOC_ISP_EXIF_REQ, exif_attri);
-
-	if(exif_attri->focal_length < -1)
-    {
-        exif_attri->focal_length = 100;
-    }
-	
-	return ret;
-}
 }; /* namespace android */
diff --git a/hardware/camera/V4L2CameraDevice2.h b/hardware/camera/V4L2CameraDevice2.h
index 0025e3a..8f8625f 100755
--- a/hardware/camera/V4L2CameraDevice2.h
+++ b/hardware/camera/V4L2CameraDevice2.h
@@ -10,33 +10,26 @@
 #include <fcntl.h> 
 #include <utils/Thread.h>
 #include <hardware/camera.h>
+//#include <videodev2.h>
+#include<sys/stat.h>
+
 #include <type_camera.h>
 
-#include "CameraPlatform.h"
 #include "OSAL_Queue.h"
-#include "SceneFactory/SceneModeFactory.h"
+#include "Libve_Decoder2.h"
 
-#ifdef __PLATFORM_A64__
+//#include "Libve_Decoder.h"
+#include "CameraList.h"
+#include <sunxi_camera.h>
+#ifdef __PLATFORM_H64__
 #include <sunxi_camera.h>
 #else
 #include <videodev2_34.h>
 #endif
 
+#define NB_BUFFER 10
 
-
-#ifdef  __PLATFORM_A33__
-#define NB_BUFFER 7
-#elif defined __PLATFORM_A83__
-#define NB_BUFFER 8
-#elif defined __PLATFORM_A80__
-#define NB_BUFFER 8
-#elif defined __PLATFORM_A64__
-#define NB_BUFFER 8
-#endif
-
-#define	MAX_YUV_SENSOR_PICTURE_SIZE (2592*1936*3>>1)	//just for yuv sensor
 #define MAX_PICTURE_SIZE (4608*3456*3>>1)
-#define MAX_HDR_PICTURE_SIZE (4608*3456*3>>1)
 
 namespace android {
 
@@ -64,7 +57,6 @@ enum TAKE_PICTURE_STATE {
 	TAKE_PICTURE_CONTINUOUS,
 	TAKE_PICTURE_CONTINUOUS_FAST,
 	TAKE_PICTURE_SMART,		    // take smart picture
-	TAKE_PICTURE_SCENE_MODE,    // take scene mode picture
 };
 
 /* 
@@ -261,6 +253,7 @@ protected:
 			return mV4l2CameraDevice->smartPictureThread();
 		}
     };
+
 public:
 
 	bool captureThread();
@@ -275,14 +268,13 @@ public:
 	int getFrameRate();								// get v4l2 device current frame rate
 
 	int enumSize(char * pSize, int len);
-	void getThumbSize(int* sub_w, int* sub_h);
 	int getFullSize(int * full_w, int * full_h);
 	int getSuitableThumbScale(int full_w, int full_h);
 
 	int setImageEffect(int effect);
 	int setWhiteBalance(int wb);
 
-	int setTakePictureCtrl(enum v4l2_take_picture value);
+	int setTakePictureCtrl();
 
 	// exposure
 	int setExposureMode(int mode);
@@ -300,26 +292,12 @@ public:
 	int setAutoFocusStop();
 	int getAutoFocusStatus();
 	
-	int getGainValue();	
-	int getExpValue();	
-	int setGainValue(int Gain);
-	int setExpValue(int Exp);
-	int setHDRMode(void *hdr_setting);
-	int getAeStat(struct isp_stat_buf *AeBuf);	
-	int getGammaStat(struct isp_stat_buf *GammaBuf);
-    int getHistStat(struct isp_stat_buf *HistBuf);
 	int getSnrValue();
 	int set3ALock(int lock);
 	
 	void releasePreviewFrame(int index);			// Q buffer for encoder
 
-	int getCurrentFaceFrame(void* frame, int* width, int* height);
-	int getSensorType();		//get sensor type: raw or yuv
-	int getExifInfo(struct isp_exif_attribute *exif_attri);
-	int getHDRFrameCnt()
-	{
-		return mTakePictureFlag.bits.hdr_cnt;
-	}	
+	int getCurrentFaceFrame(void * frame);
 
 	void setThumbUsedForVideo(bool isThumbUsedForVideo)
 	{
@@ -359,14 +337,10 @@ public:
 	void startContinuousPicture();
 	void stopContinuousPicture();
 	void setContinuousPictureCnt(int cnt);
+
 	void startSmartPicture();
 	void stopSmartPicture();
 	
-	void startSceneModePicture(int scenemode);
-	void stopSceneModePicture();
-	status_t openSceneMode(const char* scenemode);
-	void closeSceneMode();
-	void stopPreviewThread();
 	/*
 	 * State checkers.
 	 */
@@ -402,6 +376,7 @@ private:
 	bool isContinuousPictureTime();
 	
 	bool isPreviewTime();
+	
 	void waitFaceDectectTime();
 	
 	void singalDisconnect();
@@ -412,7 +387,7 @@ public:
 	void NV21ToYV12(const void* nv21, void *yv12, int width, int height);
 
 #endif
-	void showformat(int format,char *str);
+	void  showformat(int format,char *str);
 
 private:
 	// -------------------------------------------------------------------------
@@ -460,26 +435,14 @@ private:
 		CAPTURE_STATE_EXIT,
     };
 
-	enum PreviewThreadState {
-    	/* Do not capture frame. */
-        PREVIEW_STATE_NULL,
-        /* Do not capture frame. */
-        PREVIEW_STATE_PAUSED,
-        /* Start capture frame. */
-        PREVIEW_STATE_STARTED,
-        /* exit thread*/
-		PREVIEW_STATE_EXIT,
-    };
 	/* capture thread state. */
 	CaptureThreadState				mCaptureThreadState;
-	PreviewThreadState				mPreviewThreadState;
 	
 	// v4l2 device handle
 	int								mCameraFd; 
 
 	// be usb camera or not
 	bool							mIsUsbCamera;
-	v4l2_sensor_type				mSensor_Type;
 
 	int								mFrameRate;
 
@@ -518,12 +481,11 @@ private:
 	int								mNewZoom;
 	int								mLastZoom;
 	int								mMaxZoom;
-	int 							mZoomRatio;
 
 	int								mCaptureFormat;		// the driver capture format
 	int								mVideoFormat;		// the user request format, it should convert video buffer format 
 														// if mVideoFormat is different from mCaptureFormat. 
-	int               				mExposureBias;
+	
 	typedef struct bufferManagerQ_t
 	{
 		unsigned long			buf_vir_addr[NB_BUFFER];
@@ -549,8 +511,6 @@ private:
 	sp<DoPreviewThread>				mPreviewThread;
 	pthread_mutex_t 				mPreviewMutex;
 	pthread_cond_t					mPreviewCond;
-	pthread_mutex_t					mPreviewSyncMutex;
-	pthread_cond_t					mPreviewSyncCond;
 	
 	sp<DoPictureThread>				mPictureThread;
 	pthread_mutex_t 				mPictureMutex;
@@ -572,8 +532,7 @@ private:
 	pthread_mutex_t 				mSmartPictureMutex;
 	pthread_cond_t					mSmartPictureCond;
 	bool                            mSmartPictureDone;
-	int64_t                         mStartSmartTimeMs;
-	bool                            mStartSmartTimeout;
+
 	/* Timestamp (abs. microseconds) when last frame has been pushed to the
      * preview window. */
     uint64_t                        mContinuousPictureLast;
@@ -586,21 +545,33 @@ private:
 
     uint64_t                        mPreviewLast;
     uint32_t                        mPreviewAfter;
+
 	V4L2BUF_t *						mCurrentV4l2buf;
 
 	bool							mVideoHint;
+
+	VideoDecoder *					mDecoder;
+	VConfig							mVideoConf;
+	VideoStreamInfo					mVideoInfo;
+	VideoStreamDataInfo				mDataInfo;
+    /*support of libve*/
+/*    ve_mutex_t mDecoderMutex;
+    cedarv_decoder_t * mDecoder;
+    cedarv_stream_info_t        mStream_info;
+    cedarv_stream_data_info_t   mData_info;
+*/
+	CameraList *					mCameraList;
+
 #define STATISICS_CNT	60
 	int								mCurAvailBufferCnt;
 	int								mStatisicsIndex;
 	bool							mNeedHalfFrameRate;
 	bool							mShouldPreview;
+
 	bool                            mIsThumbUsedForVideo;
 	int	                            mVideoWidth;			// for cts
 	int	                            mVideoHeight;
-	IMAGE_FLAG_t					mTakePictureFlag;
-	int								mFlashMode;
-	ISceneMode*						mSceneMode;
-	SceneModeFactory				mSceneModeFactory;
+
 };
 
 }; /* namespace android */
diff --git a/hardware/camera/libfacedetection/ApperceivePeopleApi.h b/hardware/camera/libfacedetection/ApperceivePeopleApi.h
index 83148ba..ff5a7b1 100755
--- a/hardware/camera/libfacedetection/ApperceivePeopleApi.h
+++ b/hardware/camera/libfacedetection/ApperceivePeopleApi.h
@@ -1,46 +1,46 @@
-
-#ifndef __APPERCEIVEPEOPLE_API_H___
-#define __APPERCEIVEPEOPLE_API_H___
-
-#include <utils/StrongPointer.h>
-
-namespace android {
-
-struct APPERCEIVEPEOPLE_INFO 
-{ 
-	int scree_oriention;//12 
-	int buffer_oriention; //buffer_oriention01. 
-};
-
-typedef int (*apperceive_notify_cb)(int cmd, void * data, void *user);
-
-enum APPERCEIVEPEOPLE_NOTITY_CMD{
-	APPERCEIVEPEOPLE_NOTITY_CMD_REQUEST_FRAME,
-	APPERCEIVEPEOPLE_NOTITY_CMD_RESULT,
-	APPERCEIVEPEOPLE_NOTITY_CMD_POSITION,
-	APPERCEIVEPEOPLE_NOTITY_CMD_REQUEST_ORIENTION,
-};
-
-class CApperceivePeople;
-
-enum APPERCEIVEPEOPLE_OPS_CMD
-{
-	APPERCEIVEPEOPLE_OPS_CMD_START,
-	APPERCEIVEPEOPLE_OPS_CMD_STOP,
-	APPERCEIVEPEOPLE_OPS_CMD_REGISTE_USER,
-};
-
-struct ApperceivePeopleDev
-{
-	void * user;
-	sp<CApperceivePeople> priv;
-	void (*setCallback)(ApperceivePeopleDev * dev, apperceive_notify_cb cb);
-	int (*ioctrl)(ApperceivePeopleDev * dev, int cmd, int para0, int para1,void* arg ,int mode_idx);
-};
-
-extern int CreateApperceivePeopleDev(ApperceivePeopleDev ** dev);
-extern void DestroyApperceivePeopleDev(ApperceivePeopleDev * dev);
-
-}
-
+
+#ifndef __APPERCEIVEPEOPLE_API_H___
+#define __APPERCEIVEPEOPLE_API_H___
+
+#include <utils/StrongPointer.h>
+
+namespace android {
+
+struct APPERCEIVEPEOPLE_INFO 
+{ 
+	int scree_oriention;//12 
+	int buffer_oriention; //buffer_oriention01. 
+};
+
+typedef int (*apperceive_notify_cb)(int cmd, void * data, void *user);
+
+enum APPERCEIVEPEOPLE_NOTITY_CMD{
+	APPERCEIVEPEOPLE_NOTITY_CMD_REQUEST_FRAME,
+	APPERCEIVEPEOPLE_NOTITY_CMD_RESULT,
+	APPERCEIVEPEOPLE_NOTITY_CMD_POSITION,
+	APPERCEIVEPEOPLE_NOTITY_CMD_REQUEST_ORIENTION,
+};
+
+class CApperceivePeople;
+
+enum APPERCEIVEPEOPLE_OPS_CMD
+{
+	APPERCEIVEPEOPLE_OPS_CMD_START,
+	APPERCEIVEPEOPLE_OPS_CMD_STOP,
+	APPERCEIVEPEOPLE_OPS_CMD_REGISTE_USER,
+};
+
+struct ApperceivePeopleDev
+{
+	void * user;
+	sp<CApperceivePeople> priv;
+	void (*setCallback)(ApperceivePeopleDev * dev, apperceive_notify_cb cb);
+	int (*ioctrl)(ApperceivePeopleDev * dev, int cmd, int para0, int para1,void* arg ,int mode_idx);
+};
+
+extern int CreateApperceivePeopleDev(ApperceivePeopleDev ** dev);
+extern void DestroyApperceivePeopleDev(ApperceivePeopleDev * dev);
+
+}
+
 #endif	
\ No newline at end of file
diff --git a/hardware/camera/libfacedetection/SmileEyeBlinkAPI.h b/hardware/camera/libfacedetection/SmileEyeBlinkAPI.h
index a954d76..13c5f42 100755
--- a/hardware/camera/libfacedetection/SmileEyeBlinkAPI.h
+++ b/hardware/camera/libfacedetection/SmileEyeBlinkAPI.h
@@ -1 +1 @@
-#ifndef __SMILE_DETECTION_API_H___#define __SMILE_DETECTION_API_H___#include <utils/StrongPointer.h>namespace android {/*input and output data*/typedef struct FacePosition{	int faceTopLeftX;	int faceTopLeftY;		int faceWidth;	int faceHeigth;}FacePosition;typedef struct FrameFaceData{	FacePosition *facePositions;	int faceNum;		unsigned char *frameData;	int frameWidth;	int frameHeight;		int angle;//0,90,180,270}FrameFaceData;typedef struct Status{	int num;	int *sta;}Statuss;/*Smile Detect*/typedef int (*smile_notify_cb)(int cmd, void * data, void *user);enum SMILE_NOTITY_CMD{	SMILE_NOTITY_CMD_RESULT,};class SmileDetection;enum SMILE_OPS_CMD{	SMILE_OPS_CMD_START,	SMILE_OPS_CMD_STOP,	SMILE_OPS_CMD_REGISTE_USER,};struct SmileDetectionDev{	void * user;	sp<SmileDetection> priv;	void (*setCallback)(SmileDetectionDev * dev, smile_notify_cb cb);	int (*ioctrl)(SmileDetectionDev * dev, int cmd, int para0, FrameFaceData *para1);};extern int CreateSmileDetectionDev(SmileDetectionDev ** dev);extern void DestroySmileDetectionDev(SmileDetectionDev * dev);/*eye blink detection*/typedef int (*eye_blink_notify_cb)(int cmd, void * data, void *user);enum EYE_BLINK_NOTITY_CMD{	EYE_BLINK_NOTITY_CMD_RESULT,};class EyeBlinkDetection;enum EYE_BLINK_OPS_CMD{	EYE_BLINK_OPS_CMD_START,	EYE_BLINK_OPS_CMD_STOP,	EYE_BLINK_OPS_CMD_REGISTE_USER,};struct EyeBlinkDetectionDev{	void * user;	sp<EyeBlinkDetection> priv;	void (*setCallback)(EyeBlinkDetectionDev * dev, eye_blink_notify_cb cb);	int (*ioctrl)(EyeBlinkDetectionDev * dev, int cmd, int para0, FrameFaceData *para1);};extern int CreateEyeBlinkDetectionDev(EyeBlinkDetectionDev ** dev);extern void DestroyEyeBlinkDetectionDev(EyeBlinkDetectionDev * dev);}#endif	// __FACE_DETECTION_API_H__
\ No newline at end of file
+#ifndef __SMILE_DETECTION_API_H___#define __SMILE_DETECTION_API_H___#include <utils/StrongPointer.h>namespace android {/*input and output data*/typedef struct FacePosition{	int faceTopLeftX;	int faceTopLeftY;		int faceWidth;	int faceHeigth;}FacePosition;typedef struct FrameFaceData{	FacePosition *facePositions;	int faceNum;		unsigned char *frameData;	int frameWidth;	int frameHeight;		int angle;//0,90,180,270}FrameFaceData;typedef struct Status{	int num;	int *sta;}Statuss;/*Smile Detect*/typedef int (*smile_notify_cb)(int cmd, void * data, void *user);enum SMILE_NOTITY_CMD{	SMILE_NOTITY_CMD_RESULT,};class SmileDetection;enum SMILE_OPS_CMD{	SMILE_OPS_CMD_START,	SMILE_OPS_CMD_STOP,	SMILE_OPS_CMD_REGISTE_USER,};struct SmileDetectionDev{	void * user;	sp<SmileDetection> priv;	void (*setCallback)(SmileDetectionDev * dev, smile_notify_cb cb);	int (*ioctrl)(SmileDetectionDev * dev, int cmd, int para0, FrameFaceData *para1);};extern int CreateSmileDetectionDev(SmileDetectionDev ** dev);extern void DestroySmileDetectionDev(SmileDetectionDev * dev);/*eye blink detection*/typedef int (*eye_blink_notify_cb)(int cmd, void * data, void *user);enum EYE_BLINK_NOTITY_CMD{	EYE_BLINK_NOTITY_CMD_RESULT,};class EyeBlinkDetection;enum EYE_BLINK_OPS_CMD{	EYE_BLINK_OPS_CMD_START,	EYE_BLINK_OPS_CMD_STOP,	EYE_BLINK_OPS_CMD_REGISTE_USER,};struct EyeBlinkDetectionDev{	void * user;	sp<EyeBlinkDetection> priv;	void (*setCallback)(EyeBlinkDetectionDev * dev, eye_blink_notify_cb cb);	int (*ioctrl)(EyeBlinkDetectionDev * dev, int cmd, int para0, FrameFaceData *para1);};extern int CreateEyeBlinkDetectionDev(EyeBlinkDetectionDev ** dev);extern void DestroyEyeBlinkDetectionDev(EyeBlinkDetectionDev * dev);}#endif	// __FACE_DETECTION_API_H__
\ No newline at end of file
diff --git a/hardware/camera/scaler.c b/hardware/camera/scaler.c
index e06582a..71a786b 100755
--- a/hardware/camera/scaler.c
+++ b/hardware/camera/scaler.c
@@ -1,418 +1,418 @@
-static int cubic_coeff[]={//32-taps
-	0, 256,   0,   0,
-	-3, 255,   4,   0,
-	-6, 254,  10,   0,
-	-9, 251,  16,   0,
-	-11, 247,  23,  -1,
-	-13, 242,  31,  -2,
-	-15, 236,  39,  -3,
-	-16, 229,  48,  -4,
-	-17, 222,  58,  -5,
-	-18, 214,  68,  -6,
-	-18, 205,  78,  -8,
-	-18, 196,  89,  -9,
-	-18, 186, 100, -10,
-	-17, 176, 111, -12,
-	-17, 166, 122, -13,
-	-16, 155, 133, -14,
-	-15, 144, 144, -15,
-	-14, 133, 155, -16,
-	-13, 122, 166, -17,
-	-12, 111, 176, -17,
-	-10, 100, 186, -18,
-	-9,  89, 196, -18,
-	-8,  78, 205, -18,
-	-6,  68, 214, -18,
-	-5,  58, 222, -17,
-	-4,  48, 229, -16,
-	-3,  39, 236, -15,
-	-2,  31, 242, -13,
-	-1,  23, 247, -11,
-	0,  16, 251,  -9,
-	0,  10, 254,  -6,
-	0,   4, 255,  -3,
-};
-#define  MAX(a,b)              (((a) > (b)) ? (a) : (b))
-#define  CLIP(a,i,s)           (((a) > (s)) ? (s) : MAX(a,i))
-
-
-typedef struct ISP_CTX 
-{
-	int SC_dst_format;			//0-420 1-422 2-444
-	int SC_hor_filter_type;
-	int width;
-	int	height;
-	int SC_dst_width;
-	int SC_dst_height;
-	int outpicsize;
-	int SC_luma_hor_ratio;
-	int SC_luma_ver_ratio;
-	int SC_luma_ver_init_phase;
-	int SC_luma_hor_init_phase;
-	int SC_chroma_hor_init_phase;
-	int SC_chroma_ver_init_phase;
-	int SC_HOR_FILTER_COEFF0[16][4];//4-taps
-	int SC_VER_FILTER_COEFF[32][2];//2-taps
-}ISP_CTX;
-
-
-void SC_hor_filter(ISP_CTX *ispctx,unsigned char *dst_buf,unsigned char *src_ptr,int src_width,int dst_width,int ratio,int init_phase,int filter_type,int isLuma)
-{
-	int j;
-	int base_pixel,hphase,r;
-	unsigned char x[4],*td_buf;
-	int *C;
-
-	td_buf = (unsigned char *)malloc(dst_width+4);
-
-	for(j=0;j<dst_width;j++)
-	{
-		base_pixel = (j*ratio+init_phase)>>8;
-		hphase = j*ratio+init_phase - (base_pixel<<8);
-
-		if(base_pixel-1<0)
-			x[0] = src_ptr[0];
-		else if(base_pixel-1>=src_width)
-			x[0] = src_ptr[src_width-1];
-		else
-			x[0] = src_ptr[base_pixel-1];
-
-		if(base_pixel<0)
-			x[1] = src_ptr[0];
-		else if(base_pixel>=src_width)
-			x[1] = src_ptr[src_width-1];
-		else
-			x[1] = src_ptr[base_pixel];
-
-		if(base_pixel+1<0)
-			x[2] = src_ptr[0];
-		else if(base_pixel+1>=src_width)
-			x[2] = src_ptr[src_width-1];
-		else
-			x[2] = src_ptr[base_pixel+1];
-
-		if(base_pixel+2<0)
-			x[3] = src_ptr[0];
-		else if(base_pixel+2>=src_width)
-			x[3] = src_ptr[src_width-1];
-		else
-			x[3] = src_ptr[base_pixel+2];
-
-		if(filter_type==0)
-		{//4-taps
-			C = ispctx->SC_HOR_FILTER_COEFF0[hphase>>4];
-			r = x[0]*C[0] + x[1]*C[1] + x[2]*C[2] + x[3]*C[3];
-			r += 128;
-			r >>= 8;
-		}
-		td_buf[j+2] = CLIP(r,0,255);
-	}
-	td_buf[0] = td_buf[1] = td_buf[2];
-	td_buf[2+dst_width] = td_buf[3+dst_width] = td_buf[1+dst_width];
-
-	memcpy(dst_buf,td_buf+2,dst_width);
-
-	free(td_buf);
-}
-
-void do_scaler(ISP_CTX *ispctx,unsigned char * psrc, unsigned char * pdst, int src_w, int src_h, int dst_w, int dst_h, int fmt, int align)
-{
-	int i,j,*C,r;
-	unsigned char *scline_buf[2],*lastline,*curline;
-	int line_num[2],base_line,base_linep1;
-	unsigned char *dst_ptr,*CbPtr,*CrPtr,*DstBuf;
-	int vphase,hratio,vratio,init_vphase;
-	int src_height,src_width,dst_width,dst_height;
-	int align_width,sub_num,cro_align_width,cro_sub_num;
-
-	scline_buf[0] = (unsigned char *)malloc(ispctx->SC_dst_width*2);
-	scline_buf[1] = scline_buf[0] + ispctx->SC_dst_width;
-	DstBuf = (unsigned char *)malloc(ispctx->outpicsize*3);
-	//DstBuf = (unsigned char *)VirtualAlloc(0,ispctx->outpicsize*3,MEM_COMMIT,PAGE_READWRITE);
-	dst_ptr = DstBuf;
-
-	//calculate luminance 
-	line_num[0] = line_num[1] = -1;
-	vratio = ispctx->SC_luma_ver_ratio;
-	init_vphase = (ispctx->SC_luma_ver_init_phase);
-	align_width = (src_w + align - 1) & (~(align - 1));
-	sub_num = align_width - src_w;
-	cro_align_width = ((src_w>>1) + align/2 - 1) & (~(align/2 - 1));
-	cro_sub_num = cro_align_width  - (src_w>>1);
-
-	for(i=0; i<ispctx->SC_dst_height; i++)
-	{
-		base_line = (i*vratio+init_vphase)>>8;
-		vphase = (i*vratio+init_vphase) - (base_line<<8);
-
-		{
-			if(base_line >= ispctx->height)
-				base_line = ispctx->height-1;
-
-			base_linep1 = base_line+1;
-			if(base_linep1 >= ispctx->height)
-				base_linep1 = ispctx->height-1;
-		}
-
-		if(base_line == line_num[0])
-		{
-			lastline = scline_buf[0];
-		}
-		else if(base_line == line_num[1])
-		{
-			lastline = scline_buf[1];
-		}
-		else
-		{	
-			lastline = scline_buf[0];
-			line_num[0] = base_line;
-
-			//need to fill
-			SC_hor_filter(ispctx,lastline,psrc+base_line*align_width,ispctx->width,ispctx->SC_dst_width,ispctx->SC_luma_hor_ratio,ispctx->SC_luma_hor_init_phase,0,1);
-		}
-
-		if(base_linep1 == line_num[0])
-		{
-			curline = scline_buf[0];
-		}
-		else if(base_linep1 == line_num[1])
-		{
-			curline = scline_buf[1];
-		}
-		else
-		{
-			if(base_line == line_num[0])
-			{
-				line_num[1] = base_linep1;
-				curline = scline_buf[1];
-			}
-			else
-			{
-				line_num[0] = base_linep1;
-				curline = scline_buf[0];
-			}
-
-			//need to fill
-
-			SC_hor_filter(ispctx,curline,psrc+base_linep1*align_width,ispctx->width,ispctx->SC_dst_width,ispctx->SC_luma_hor_ratio,ispctx->SC_luma_hor_init_phase,0,1);
-		}
-
-		//vertical filter
-		C = ispctx->SC_VER_FILTER_COEFF[vphase>>3];
-		for(j=0;j<ispctx->SC_dst_width;j++)
-		{
-			r = lastline[j]*C[0] + curline[j]*C[1];
-			r += 128;
-			r >>= 8;
-			*dst_ptr++ = CLIP(r,0,255);
-		}
-		dst_ptr += sub_num;
-	}
-
-	//decide the chroma aspect ratio
-	switch(fmt)
-	{//0-yuv420, 1-yuv422, 2-yvu420, 3-yvu422,4-yuyv422, 5-32x32,8-argb8888, 9-rgba8888, 10-abgr8888, 11-bgra8888
-	case 0:
-		{//src is 4:2:0, dst is 4:2:0
-			hratio = ispctx->SC_luma_hor_ratio;
-			vratio = ispctx->SC_luma_ver_ratio;
-			dst_width = ispctx->SC_dst_width>>1;
-			dst_height = ispctx->SC_dst_height>>1;
-		}
-		src_width = ispctx->width>>1;
-		src_height = ispctx->height>>1;
-		break;
-	default:
-		break;
-	}
-
-	//calculate chrominance Cb
-	CbPtr = psrc + align_width*ispctx->height;
-	line_num[0] = line_num[1] = -1;
-	vratio = ispctx->SC_luma_ver_ratio;
-	init_vphase = (ispctx->SC_chroma_ver_init_phase);
-	for(i=0;i<dst_height;i++)
-	{
-		base_line = (i*vratio+init_vphase)>>8;
-		vphase = (i*vratio+init_vphase) - (base_line<<8);
-
-		{
-			if(base_line >= src_height)
-				base_line = src_height-1;
-
-			base_linep1 = base_line+1;
-			if(base_linep1 >= src_height)
-				base_linep1 = src_height-1;
-		}
-
-		if(base_line == line_num[0])
-		{
-			lastline = scline_buf[0];
-		}
-		else if(base_line == line_num[1])
-		{
-			lastline = scline_buf[1];
-		}
-		else
-		{	
-			lastline = scline_buf[0];
-			line_num[0] = base_line;
-
-			//need to fill
-			SC_hor_filter(ispctx,lastline,CbPtr+base_line*cro_align_width,src_width,dst_width,hratio,ispctx->SC_chroma_hor_init_phase,0,0);
-		}
-
-		if(base_linep1 == line_num[0])
-		{
-			curline = scline_buf[0];
-		}
-		else if(base_linep1 == line_num[1])
-		{
-			curline = scline_buf[1];
-		}
-		else
-		{
-			if(base_line == line_num[0])
-			{
-				line_num[1] = base_linep1;
-				curline = scline_buf[1];
-			}
-			else
-			{
-				line_num[0] = base_linep1;
-				curline = scline_buf[0];
-			}
-
-			//need to fill
-			SC_hor_filter(ispctx,curline,CbPtr+base_linep1*cro_align_width,src_width,dst_width,hratio,ispctx->SC_chroma_hor_init_phase,0,0);
-		}
-
-		//vertical filter
-		C = ispctx->SC_VER_FILTER_COEFF[vphase>>3];
-		for(j=0;j<dst_width;j++)
-		{
-			r = lastline[j]*C[0] + curline[j]*C[1];
-			r += 128;
-			r >>= 8;
-			*dst_ptr++ = CLIP(r,0,255);
-		}
-		dst_ptr += cro_sub_num;
-	}
-
-	CrPtr = CbPtr + cro_align_width*src_height;
-	line_num[0] = line_num[1] = -1;
-	vratio = ispctx->SC_luma_ver_ratio;
-	init_vphase = (ispctx->SC_chroma_ver_init_phase);
-	for(i=0;i<dst_height;i++)
-	{
-		base_line = (i*vratio+init_vphase)>>8;
-		vphase = (i*vratio+init_vphase) - (base_line<<8);
-
-
-		{
-			if(base_line >= src_height)
-				base_line = src_height-1;
-
-			base_linep1 = base_line+1;
-			if(base_linep1 >= src_height)
-				base_linep1 = src_height-1;
-		}
-
-		if(base_line == line_num[0])
-		{
-			lastline = scline_buf[0];
-		}
-		else if(base_line == line_num[1])
-		{
-			lastline = scline_buf[1];
-		}
-		else
-		{	
-			lastline = scline_buf[0];
-			line_num[0] = base_line;
-
-			//need to fill
-			SC_hor_filter(ispctx,lastline,CrPtr+base_line*cro_align_width,src_width,dst_width,hratio,ispctx->SC_chroma_hor_init_phase,0,0);
-		}
-
-		if(base_linep1 == line_num[0])
-		{
-			curline = scline_buf[0];
-		}
-		else if(base_linep1 == line_num[1])
-		{
-			curline = scline_buf[1];
-		}
-		else
-		{
-			if(base_line == line_num[0])
-			{
-				line_num[1] = base_linep1;
-				curline = scline_buf[1];
-			}
-			else
-			{
-				line_num[0] = base_linep1;
-				curline = scline_buf[0];
-			}
-
-			//need to fill
-
-			SC_hor_filter(ispctx,curline,CrPtr+base_linep1*cro_align_width,src_width,dst_width,hratio,ispctx->SC_chroma_hor_init_phase,0,0);
-		}
-
-		//vertical filter
-		C = ispctx->SC_VER_FILTER_COEFF[vphase>>3];
-		for(j=0;j<dst_width;j++)
-		{
-			r = lastline[j]*C[0] + curline[j]*C[1];
-			r += 128;
-			r >>= 8;
-			*dst_ptr++ = CLIP(r,0,255);
-		}
-		dst_ptr += cro_sub_num;
-	}
-
-	memcpy(pdst,DstBuf,ispctx->outpicsize);
-
-	free(scline_buf[0]);
-	free(DstBuf);
-}
-
-// fmt: only support YV12
-int scaler(unsigned char * psrc, unsigned char * pdst, int src_w, int src_h, int dst_w, int dst_h, int fmt, int align)
-{
-	int i;
-	ISP_CTX isp_ctx,*ispctx;
-	ispctx = &isp_ctx;
-	ispctx->width = src_w;
-	ispctx->height = src_h;
-	ispctx->SC_dst_width = dst_w;
-	ispctx->SC_dst_height = dst_h;
-	ispctx->SC_luma_ver_init_phase = 0;
-	ispctx->SC_luma_hor_init_phase = 0;
-	ispctx->SC_chroma_hor_init_phase = 0;
-	ispctx->SC_chroma_ver_init_phase = 0;
-	if(fmt == 0)
-		ispctx->outpicsize = dst_w*dst_h*1.5;
-
-	for(i=0;i<16;i++)
-	{
-		ispctx->SC_HOR_FILTER_COEFF0[i][0] = cubic_coeff[i*4*2];
-		ispctx->SC_HOR_FILTER_COEFF0[i][1] = cubic_coeff[i*4*2+1];
-		ispctx->SC_HOR_FILTER_COEFF0[i][2] = cubic_coeff[i*4*2+2];
-		ispctx->SC_HOR_FILTER_COEFF0[i][3] = cubic_coeff[i*4*2+3];
-	}
-
-	for(i=0;i<32;i++)
-	{
-		ispctx->SC_VER_FILTER_COEFF[i][0] = (32-i)<<3;
-		ispctx->SC_VER_FILTER_COEFF[i][1] = i<<3;
-	}
-
-
-	ispctx->SC_luma_hor_ratio = (src_w*256 + (dst_w/2))/dst_w;
-	ispctx->SC_luma_ver_ratio = (src_h*256 + (dst_h/2))/dst_h;
-	do_scaler(ispctx,psrc,pdst,src_w,src_h,dst_w,dst_h,fmt,align);
-	return 0;
+static int cubic_coeff[]={//32-taps
+	0, 256,   0,   0,
+	-3, 255,   4,   0,
+	-6, 254,  10,   0,
+	-9, 251,  16,   0,
+	-11, 247,  23,  -1,
+	-13, 242,  31,  -2,
+	-15, 236,  39,  -3,
+	-16, 229,  48,  -4,
+	-17, 222,  58,  -5,
+	-18, 214,  68,  -6,
+	-18, 205,  78,  -8,
+	-18, 196,  89,  -9,
+	-18, 186, 100, -10,
+	-17, 176, 111, -12,
+	-17, 166, 122, -13,
+	-16, 155, 133, -14,
+	-15, 144, 144, -15,
+	-14, 133, 155, -16,
+	-13, 122, 166, -17,
+	-12, 111, 176, -17,
+	-10, 100, 186, -18,
+	-9,  89, 196, -18,
+	-8,  78, 205, -18,
+	-6,  68, 214, -18,
+	-5,  58, 222, -17,
+	-4,  48, 229, -16,
+	-3,  39, 236, -15,
+	-2,  31, 242, -13,
+	-1,  23, 247, -11,
+	0,  16, 251,  -9,
+	0,  10, 254,  -6,
+	0,   4, 255,  -3,
+};
+#define  MAX(a,b)              (((a) > (b)) ? (a) : (b))
+#define  CLIP(a,i,s)           (((a) > (s)) ? (s) : MAX(a,i))
+
+
+typedef struct ISP_CTX 
+{
+	int SC_dst_format;			//0-420 1-422 2-444
+	int SC_hor_filter_type;
+	int width;
+	int	height;
+	int SC_dst_width;
+	int SC_dst_height;
+	int outpicsize;
+	int SC_luma_hor_ratio;
+	int SC_luma_ver_ratio;
+	int SC_luma_ver_init_phase;
+	int SC_luma_hor_init_phase;
+	int SC_chroma_hor_init_phase;
+	int SC_chroma_ver_init_phase;
+	int SC_HOR_FILTER_COEFF0[16][4];//4-taps
+	int SC_VER_FILTER_COEFF[32][2];//2-taps
+}ISP_CTX;
+
+
+void SC_hor_filter(ISP_CTX *ispctx,unsigned char *dst_buf,unsigned char *src_ptr,int src_width,int dst_width,int ratio,int init_phase,int filter_type,int isLuma)
+{
+	int j;
+	int base_pixel,hphase,r;
+	unsigned char x[4],*td_buf;
+	int *C;
+
+	td_buf = (unsigned char *)malloc(dst_width+4);
+
+	for(j=0;j<dst_width;j++)
+	{
+		base_pixel = (j*ratio+init_phase)>>8;
+		hphase = j*ratio+init_phase - (base_pixel<<8);
+
+		if(base_pixel-1<0)
+			x[0] = src_ptr[0];
+		else if(base_pixel-1>=src_width)
+			x[0] = src_ptr[src_width-1];
+		else
+			x[0] = src_ptr[base_pixel-1];
+
+		if(base_pixel<0)
+			x[1] = src_ptr[0];
+		else if(base_pixel>=src_width)
+			x[1] = src_ptr[src_width-1];
+		else
+			x[1] = src_ptr[base_pixel];
+
+		if(base_pixel+1<0)
+			x[2] = src_ptr[0];
+		else if(base_pixel+1>=src_width)
+			x[2] = src_ptr[src_width-1];
+		else
+			x[2] = src_ptr[base_pixel+1];
+
+		if(base_pixel+2<0)
+			x[3] = src_ptr[0];
+		else if(base_pixel+2>=src_width)
+			x[3] = src_ptr[src_width-1];
+		else
+			x[3] = src_ptr[base_pixel+2];
+
+		if(filter_type==0)
+		{//4-taps
+			C = ispctx->SC_HOR_FILTER_COEFF0[hphase>>4];
+			r = x[0]*C[0] + x[1]*C[1] + x[2]*C[2] + x[3]*C[3];
+			r += 128;
+			r >>= 8;
+		}
+		td_buf[j+2] = CLIP(r,0,255);
+	}
+	td_buf[0] = td_buf[1] = td_buf[2];
+	td_buf[2+dst_width] = td_buf[3+dst_width] = td_buf[1+dst_width];
+
+	memcpy(dst_buf,td_buf+2,dst_width);
+
+	free(td_buf);
+}
+
+void do_scaler(ISP_CTX *ispctx,unsigned char * psrc, unsigned char * pdst, int src_w, int src_h, int dst_w, int dst_h, int fmt, int align)
+{
+	int i,j,*C,r;
+	unsigned char *scline_buf[2],*lastline,*curline;
+	int line_num[2],base_line,base_linep1;
+	unsigned char *dst_ptr,*CbPtr,*CrPtr,*DstBuf;
+	int vphase,hratio,vratio,init_vphase;
+	int src_height,src_width,dst_width,dst_height;
+	int align_width,sub_num,cro_align_width,cro_sub_num;
+
+	scline_buf[0] = (unsigned char *)malloc(ispctx->SC_dst_width*2);
+	scline_buf[1] = scline_buf[0] + ispctx->SC_dst_width;
+	DstBuf = (unsigned char *)malloc(ispctx->outpicsize*3);
+	//DstBuf = (unsigned char *)VirtualAlloc(0,ispctx->outpicsize*3,MEM_COMMIT,PAGE_READWRITE);
+	dst_ptr = DstBuf;
+
+	//calculate luminance 
+	line_num[0] = line_num[1] = -1;
+	vratio = ispctx->SC_luma_ver_ratio;
+	init_vphase = (ispctx->SC_luma_ver_init_phase);
+	align_width = (src_w + align - 1) & (~(align - 1));
+	sub_num = align_width - src_w;
+	cro_align_width = ((src_w>>1) + align/2 - 1) & (~(align/2 - 1));
+	cro_sub_num = cro_align_width  - (src_w>>1);
+
+	for(i=0; i<ispctx->SC_dst_height; i++)
+	{
+		base_line = (i*vratio+init_vphase)>>8;
+		vphase = (i*vratio+init_vphase) - (base_line<<8);
+
+		{
+			if(base_line >= ispctx->height)
+				base_line = ispctx->height-1;
+
+			base_linep1 = base_line+1;
+			if(base_linep1 >= ispctx->height)
+				base_linep1 = ispctx->height-1;
+		}
+
+		if(base_line == line_num[0])
+		{
+			lastline = scline_buf[0];
+		}
+		else if(base_line == line_num[1])
+		{
+			lastline = scline_buf[1];
+		}
+		else
+		{	
+			lastline = scline_buf[0];
+			line_num[0] = base_line;
+
+			//need to fill
+			SC_hor_filter(ispctx,lastline,psrc+base_line*align_width,ispctx->width,ispctx->SC_dst_width,ispctx->SC_luma_hor_ratio,ispctx->SC_luma_hor_init_phase,0,1);
+		}
+
+		if(base_linep1 == line_num[0])
+		{
+			curline = scline_buf[0];
+		}
+		else if(base_linep1 == line_num[1])
+		{
+			curline = scline_buf[1];
+		}
+		else
+		{
+			if(base_line == line_num[0])
+			{
+				line_num[1] = base_linep1;
+				curline = scline_buf[1];
+			}
+			else
+			{
+				line_num[0] = base_linep1;
+				curline = scline_buf[0];
+			}
+
+			//need to fill
+
+			SC_hor_filter(ispctx,curline,psrc+base_linep1*align_width,ispctx->width,ispctx->SC_dst_width,ispctx->SC_luma_hor_ratio,ispctx->SC_luma_hor_init_phase,0,1);
+		}
+
+		//vertical filter
+		C = ispctx->SC_VER_FILTER_COEFF[vphase>>3];
+		for(j=0;j<ispctx->SC_dst_width;j++)
+		{
+			r = lastline[j]*C[0] + curline[j]*C[1];
+			r += 128;
+			r >>= 8;
+			*dst_ptr++ = CLIP(r,0,255);
+		}
+		dst_ptr += sub_num;
+	}
+
+	//decide the chroma aspect ratio
+	switch(fmt)
+	{//0-yuv420, 1-yuv422, 2-yvu420, 3-yvu422,4-yuyv422, 5-32x32,8-argb8888, 9-rgba8888, 10-abgr8888, 11-bgra8888
+	case 0:
+		{//src is 4:2:0, dst is 4:2:0
+			hratio = ispctx->SC_luma_hor_ratio;
+			vratio = ispctx->SC_luma_ver_ratio;
+			dst_width = ispctx->SC_dst_width>>1;
+			dst_height = ispctx->SC_dst_height>>1;
+		}
+		src_width = ispctx->width>>1;
+		src_height = ispctx->height>>1;
+		break;
+	default:
+		break;
+	}
+
+	//calculate chrominance Cb
+	CbPtr = psrc + align_width*ispctx->height;
+	line_num[0] = line_num[1] = -1;
+	vratio = ispctx->SC_luma_ver_ratio;
+	init_vphase = (ispctx->SC_chroma_ver_init_phase);
+	for(i=0;i<dst_height;i++)
+	{
+		base_line = (i*vratio+init_vphase)>>8;
+		vphase = (i*vratio+init_vphase) - (base_line<<8);
+
+		{
+			if(base_line >= src_height)
+				base_line = src_height-1;
+
+			base_linep1 = base_line+1;
+			if(base_linep1 >= src_height)
+				base_linep1 = src_height-1;
+		}
+
+		if(base_line == line_num[0])
+		{
+			lastline = scline_buf[0];
+		}
+		else if(base_line == line_num[1])
+		{
+			lastline = scline_buf[1];
+		}
+		else
+		{	
+			lastline = scline_buf[0];
+			line_num[0] = base_line;
+
+			//need to fill
+			SC_hor_filter(ispctx,lastline,CbPtr+base_line*cro_align_width,src_width,dst_width,hratio,ispctx->SC_chroma_hor_init_phase,0,0);
+		}
+
+		if(base_linep1 == line_num[0])
+		{
+			curline = scline_buf[0];
+		}
+		else if(base_linep1 == line_num[1])
+		{
+			curline = scline_buf[1];
+		}
+		else
+		{
+			if(base_line == line_num[0])
+			{
+				line_num[1] = base_linep1;
+				curline = scline_buf[1];
+			}
+			else
+			{
+				line_num[0] = base_linep1;
+				curline = scline_buf[0];
+			}
+
+			//need to fill
+			SC_hor_filter(ispctx,curline,CbPtr+base_linep1*cro_align_width,src_width,dst_width,hratio,ispctx->SC_chroma_hor_init_phase,0,0);
+		}
+
+		//vertical filter
+		C = ispctx->SC_VER_FILTER_COEFF[vphase>>3];
+		for(j=0;j<dst_width;j++)
+		{
+			r = lastline[j]*C[0] + curline[j]*C[1];
+			r += 128;
+			r >>= 8;
+			*dst_ptr++ = CLIP(r,0,255);
+		}
+		dst_ptr += cro_sub_num;
+	}
+
+	CrPtr = CbPtr + cro_align_width*src_height;
+	line_num[0] = line_num[1] = -1;
+	vratio = ispctx->SC_luma_ver_ratio;
+	init_vphase = (ispctx->SC_chroma_ver_init_phase);
+	for(i=0;i<dst_height;i++)
+	{
+		base_line = (i*vratio+init_vphase)>>8;
+		vphase = (i*vratio+init_vphase) - (base_line<<8);
+
+
+		{
+			if(base_line >= src_height)
+				base_line = src_height-1;
+
+			base_linep1 = base_line+1;
+			if(base_linep1 >= src_height)
+				base_linep1 = src_height-1;
+		}
+
+		if(base_line == line_num[0])
+		{
+			lastline = scline_buf[0];
+		}
+		else if(base_line == line_num[1])
+		{
+			lastline = scline_buf[1];
+		}
+		else
+		{	
+			lastline = scline_buf[0];
+			line_num[0] = base_line;
+
+			//need to fill
+			SC_hor_filter(ispctx,lastline,CrPtr+base_line*cro_align_width,src_width,dst_width,hratio,ispctx->SC_chroma_hor_init_phase,0,0);
+		}
+
+		if(base_linep1 == line_num[0])
+		{
+			curline = scline_buf[0];
+		}
+		else if(base_linep1 == line_num[1])
+		{
+			curline = scline_buf[1];
+		}
+		else
+		{
+			if(base_line == line_num[0])
+			{
+				line_num[1] = base_linep1;
+				curline = scline_buf[1];
+			}
+			else
+			{
+				line_num[0] = base_linep1;
+				curline = scline_buf[0];
+			}
+
+			//need to fill
+
+			SC_hor_filter(ispctx,curline,CrPtr+base_linep1*cro_align_width,src_width,dst_width,hratio,ispctx->SC_chroma_hor_init_phase,0,0);
+		}
+
+		//vertical filter
+		C = ispctx->SC_VER_FILTER_COEFF[vphase>>3];
+		for(j=0;j<dst_width;j++)
+		{
+			r = lastline[j]*C[0] + curline[j]*C[1];
+			r += 128;
+			r >>= 8;
+			*dst_ptr++ = CLIP(r,0,255);
+		}
+		dst_ptr += cro_sub_num;
+	}
+
+	memcpy(pdst,DstBuf,ispctx->outpicsize);
+
+	free(scline_buf[0]);
+	free(DstBuf);
+}
+
+// fmt: only support YV12
+int scaler(unsigned char * psrc, unsigned char * pdst, int src_w, int src_h, int dst_w, int dst_h, int fmt, int align)
+{
+	int i;
+	ISP_CTX isp_ctx,*ispctx;
+	ispctx = &isp_ctx;
+	ispctx->width = src_w;
+	ispctx->height = src_h;
+	ispctx->SC_dst_width = dst_w;
+	ispctx->SC_dst_height = dst_h;
+	ispctx->SC_luma_ver_init_phase = 0;
+	ispctx->SC_luma_hor_init_phase = 0;
+	ispctx->SC_chroma_hor_init_phase = 0;
+	ispctx->SC_chroma_ver_init_phase = 0;
+	if(fmt == 0)
+		ispctx->outpicsize = dst_w*dst_h*1.5;
+
+	for(i=0;i<16;i++)
+	{
+		ispctx->SC_HOR_FILTER_COEFF0[i][0] = cubic_coeff[i*4*2];
+		ispctx->SC_HOR_FILTER_COEFF0[i][1] = cubic_coeff[i*4*2+1];
+		ispctx->SC_HOR_FILTER_COEFF0[i][2] = cubic_coeff[i*4*2+2];
+		ispctx->SC_HOR_FILTER_COEFF0[i][3] = cubic_coeff[i*4*2+3];
+	}
+
+	for(i=0;i<32;i++)
+	{
+		ispctx->SC_VER_FILTER_COEFF[i][0] = (32-i)<<3;
+		ispctx->SC_VER_FILTER_COEFF[i][1] = i<<3;
+	}
+
+
+	ispctx->SC_luma_hor_ratio = (src_w*256 + (dst_w/2))/dst_w;
+	ispctx->SC_luma_ver_ratio = (src_h*256 + (dst_h/2))/dst_h;
+	do_scaler(ispctx,psrc,pdst,src_w,src_h,dst_w,dst_h,fmt,align);
+	return 0;
 }
\ No newline at end of file
